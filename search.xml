<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Java容器]]></title>
    <url>%2F2020%2F03%2F27%2FJava%E5%AE%B9%E5%99%A8%2F</url>
    <content type="text"><![CDATA[说说List,Set,Map三者的区别？ List(对付顺序的好帮手)： List接口存储一组不唯一（可以有多个元素引用相同的对象），有序的对象 Set(注重独一无二的性质): 不允许重复的集合。不会有多个元素引用相同的对象。 Map(用Key来搜索的专家): 使用键值对存储。Map会维护与Key有关联的值。两个Key可以引用相同的对象，但Key不能重复，典型的Key是String类型，但也可以是任何对象。 ArraylistJava的动态数组 以无参数构造方法创建 ArrayList 时，实际上初始化赋值的是一个空数组。当真正对数组进行添加元素操作时，才真正分配容量。即向数组中添加第一个元素时，数组容量扩为10 每次扩容大概是之前容量的1.5倍左右 123 //我们知道位运算的速度远远快于整除运算，整句运算式的结果就是将新容量更新为旧容量的1.5倍， int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1);//右移一位相当于/2，是奇数的化会丢掉小数 Arraylist 与 LinkedList 区别?1. 是否保证线程安全： ArrayList 和 LinkedList 都是不同步的，也就是不保证线程安全 2. 底层数据结构： Arraylist 底层使用的是 Object 数组；LinkedList 底层使用的是 双向链表 数据结构 3. 插入和删除是否受元素位置的影响： ① ArrayList 采用数组存储，所以插入和删除元素的时间复杂度受元素位置的影响。 比如：执行add(E e)方法的时候， ArrayList 会默认在将指定的元素追加到此列表的末尾，这种情况时间复杂度就是O(1)。但是如果要在指定位置 i 插入和删除元素的话（add(int index, E element)）时间复杂度就为 O(n-i)。因为在进行上述操作的时候集合中第 i 和第 i 个元素之后的(n-i)个元素都要执行向后位/向前移一位的操作。 ② LinkedList 采用链表存储，所以对于add(�E e)方法的插入，删除元素时间复杂度不受元素位置的影响，近似 O（1），如果是要在指定位置i插入和删除元素的话（(add(int index, E element)） 时间复杂度近似为o(n))因为需要先移动到指定位置再插入。 4. 是否支持快速随机访问： LinkedList 不支持高效的随机元素访问，而 ArrayList 支持。快速随机访问就是通过元素的序号快速获取元素对象(对应于get(int index)方法)。 5. 内存空间占用： ArrayList的空 间浪费主要体现在在list列表的结尾会预留一定的容量空间，而LinkedList的空间花费则体现在它的每一个元素都需要消耗比ArrayList更多的空间（因为要存放直接后继和直接前驱以及数据）。 ArrayList 与 Vector 区别呢?为什么要用Arraylist取代Vector呢？Vector类的所有方法都是同步的。可以由两个线程安全地访问一个Vector对象、但是一个线程访问Vector的话代码要在同步操作上耗费大量的时间。 Arraylist不是同步的，所以在不需要保证线程安全时建议使用Arraylist。 HashMap 和 Hashtable 的区别 线程是否安全： HashMap 是非线程安全的，HashTable 是线程安全的；HashTable 内部的方法基本都经过synchronized 修饰。（如果你要保证线程安全的话就使用 ConcurrentHashMap 吧！）； 效率： 因为线程安全的问题，HashMap 要比 HashTable 效率高一点。另外，HashTable 基本被淘汰，不要在代码中使用它； 对Null key 和Null value的支持： HashMap 中，null 可以作为键，这样的键只有一个，可以有一个或多个键所对应的值为 null。。但是在 HashTable 中 put 进的键值只要有一个 null，直接抛出 NullPointerException。 初始容量大小和每次扩充容量大小的不同 ： ①创建时如果不指定容量初始值，Hashtable 默认的初始大小为11，之后每次扩充，容量变为原来的2n+1。HashMap 默认的初始化大小为16。之后每次扩充，容量变为原来的2倍。②创建时如果给定了容量初始值，那么 Hashtable 会直接使用你给定的大小，而 HashMap 会将其扩充为2的幂次方大小。 底层数据结构： JDK1.8 以后的 HashMap 在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为8）（将链表转换成红黑树前会判断，如果当前数组的长度小于 64，那么会选择先进行数组扩容，而不是转换为红黑树）时，将链表转化为红黑树，以减少搜索时间。Hashtable 没有这样的机制。 ConcurrentHashMap 和 Hashtable 的区别ConcurrentHashMap 和 Hashtable 的区别主要体现在实现线程安全的方式上不同。 底层数据结构： JDK1.7的 ConcurrentHashMap 底层采用 分段的数组+链表 实现，JDK1.8 采用的数据结构跟HashMap1.8的结构一样，数组+链表/红黑二叉树。Hashtable 和 JDK1.8 之前的 HashMap 的底层数据结构类似都是采用 数组+链表 的形式，数组是 HashMap 的主体，链表则是主要为了解决哈希冲突而存在的； 实现线程安全的方式（重要）： ① 在JDK1.7的时候，ConcurrentHashMap（分段锁） 对整个桶数组进行了分割分段(Segment)，每一把锁只锁容器其中一部分数据，多线程访问容器里不同数据段的数据，就不会存在锁竞争，提高并发访问率。 到了 JDK1.8 的时候已经摒弃了Segment的概念，而是直接用 Node 数组+链表+红黑树的数据结构来实现，并发控制使用 synchronized 和 CAS 来操作。（JDK1.6以后 对 synchronized锁做了很多优化） 整个看起来就像是优化过且线程安全的 HashMap，虽然在JDK1.8中还能看到 Segment 的数据结构，但是已经简化了属性，只是为了兼容旧版本；② Hashtable(同一把锁) :使用 synchronized 来保证线程安全，效率非常低下。当一个线程访问同步方法时，其他线程也访问同步方法，可能会进入阻塞或轮询状态，如使用 put 添加元素，另一个线程不能使用 put 添加元素，也不能使用 get，竞争会越来越激烈效率越低。 HashTable: JDK1.7的ConcurrentHashMap： JDK1.8的ConcurrentHashMap（TreeBin: 红黑二叉树节点 Node: 链表节点）： ConcurrentHashMap线程安全的具体实现方式/底层具体实现JDK1.7（上面有示意图）首先将数据分为一段一段的存储，然后给每一段数据配一把锁，当一个线程占用锁访问其中一个段数据时，其他段的数据也能被其他线程访问。 ConcurrentHashMap 是由 Segment 数组结构和 HashEntry 数组结构组成。 Segment 实现了 ReentrantLock,所以 Segment 是一种可重入锁，扮演锁的角色。HashEntry 用于存储键值对数据。 12static class Segment&lt;K,V&gt; extends ReentrantLock implements Serializable &#123;&#125; 一个 ConcurrentHashMap 里包含一个 Segment 数组。Segment 的结构和HashMap类似，是一种数组和链表结构，一个 Segment 包含一个 HashEntry 数组，每个 HashEntry 是一个链表结构的元素，每个 Segment 守护着一个HashEntry数组里的元素，当对 HashEntry 数组的数据进行修改时，必须首先获得对应的 Segment的锁。 JDK1.8 （上面有示意图）ConcurrentHashMap取消了Segment分段锁，采用CAS和synchronized来保证并发安全。数据结构跟HashMap1.8的结构类似，数组+链表/红黑二叉树。Java 8在链表长度超过一定阈值（8）时将链表（寻址时间复杂度为O(N)）转换为红黑树（寻址时间复杂度为O(log(N))） synchronized只锁定当前链表或红黑二叉树的首节点，这样只要hash不冲突，就不会产生并发，效率又提升N倍。 JDK 提供的并发容器总结JDK 提供的这些容器大部分在 java.util.concurrent 包中。 ConcurrentHashMap: 线程安全的 HashMap CopyOnWriteArrayList: 线程安全的 List，在读多写少的场合性能非常好，远远好于 Vector. ConcurrentLinkedQueue: 高效的并发队列，使用链表实现。可以看做一个线程安全的 LinkedList，这是一个非阻塞队列。 BlockingQueue: 这是一个接口，JDK 内部通过链表、数组等方式实现了这个接口。表示阻塞队列，非常适合用于作为数据共享的通道。 ConcurrentSkipListMap: 跳表的实现。这是一个 Map，使用跳表的数据结构进行快速查找。]]></content>
  </entry>
  <entry>
    <title><![CDATA[Java并发2]]></title>
    <url>%2F2020%2F03%2F25%2FJava%E5%B9%B6%E5%8F%912%2F</url>
    <content type="text"><![CDATA[Java中的锁乐观锁总是假设最好的情况，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号机制和CAS算法实现。乐观锁适用于多读的应用类型，这样可以提高吞吐量，像数据库提供的类似于write_condition机制，其实都是提供的乐观锁。在Java中java.util.concurrent.atomic包下面的原子变量类就是使用了乐观锁的一种实现方式CAS实现的。 悲观锁总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会阻塞直到它拿到锁（共享资源每次只给一个线程使用，其它线程阻塞，用完后再把资源转让给其它线程）。传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁。Java中synchronized和ReentrantLock等独占锁就是悲观锁思想的实现。 两种锁的使用场景各有优缺点，乐观锁适用于写比较少的情况下（多读场景），多写的场景下用悲观锁就比较合适。 乐观锁常见的两种实现方式 乐观锁一般会使用版本号机制或CAS算法实现。 1.CAS算法即compare and swap（比较与交换），是一种有名的无锁算法。无锁编程，即不使用锁的情况下实现多线程之间的变量同步，也就是在没有线程被阻塞的情况下实现变量的同步，所以也叫非阻塞同步（Non-blocking Synchronization）。CAS算法涉及到三个操作数 V表示要更新的变量 E表示预期的值 N表示新值 当且仅当 V 的值等于 E时，CAS通过原子方式用新值N来更新V的值，否则不会执行任何操作（比较和替换是一个原子操作）。一般情况下是一个自旋操作，即不断的重试。 2.版本号机制一般是在数据表中加上一个数据版本号version字段，表示数据被修改的次数，当数据被修改时，version值会加一。当线程A要更新数据值时，在读取数据的同时也会读取version值，在提交更新时，若刚才读取到的version值为当前数据库中的version值相等时才更新，否则重试更新操作，直到更新成功。 乐观锁的缺点 ABA 问题是乐观锁一个常见的问题 1 ABA 问题如果一个变量V初次读取的时候是A值，并且在准备赋值的时候检查到它仍然是A值，那我们就能说明它的值没有被其他线程修改过了吗？很明显是不能的，因为在这段时间它的值可能被改为其他值，然后又改回A，那CAS操作就会误认为它从来没有被修改过。这个问题被称为CAS操作的 “ABA”问题。你大爷还是你大爷，你大妈已经不是你大妈了 对于ABA问题，比较有效的方案是引入版本号 2 循环时间长开销大自旋CAS（也就是不成功就一直循环执行直到成功）如果长时间不成功，会给CPU带来非常大的执行开销。 设置自旋CAS的时间域值 3 只能保证一个共享变量的原子操作CAS 只对单个共享变量有效，当操作涉及跨多个共享变量时 CAS 无效。但是从 JDK 1.5开始，提供了AtomicReference类来保证引用对象之间的原子性，你可以把多个变量放在一个对象里来进行 CAS 操作.所以我们可以使用锁或者利用AtomicReference类把多个共享变量合并成一个共享变量来操作。 Atomic 原子类介绍Atomic 翻译成中文是原子的意思。在化学上，我们知道原子是构成一般物质的最小单位，在化学反应中是不可分割的。在我们这里 Atomic 是指一个操作是不可中断的。即使是在多个线程一起执行的时候，一个操作一旦开始，就不会被其他线程干扰。 所以，所谓原子类说简单点就是具有原子/原子操作特征的类。 基本数据类型原子类的优势通过一个简单例子带大家看一下基本数据类型原子类的优势 ①多线程环境不使用原子类保证线程安全（基本数据类型） 1234567891011class Test &#123; private volatile int count = 0; //若要线程安全执行执行count++，需要加锁 public synchronized void increment() &#123; count++; &#125; public int getCount() &#123; return count; &#125;&#125; ②多线程环境使用原子类保证线程安全（基本数据类型） 1234567891011class Test2 &#123; private AtomicInteger count = new AtomicInteger(); public void increment() &#123; count.incrementAndGet(); &#125; //使用AtomicInteger之后，不需要加锁，也可以实现线程安全。 public int getCount() &#123; return count.get(); &#125;&#125; AtomicInteger 线程安全原理简单分析AtomicInteger 类的部分源码： 123456789101112// setup to use Unsafe.compareAndSwapInt for updates（更新操作时提供“比较并替换”的作用）private static final Unsafe unsafe = Unsafe.getUnsafe();private static final long valueOffset;static &#123; try &#123; valueOffset = unsafe.objectFieldOffset (AtomicInteger.class.getDeclaredField("value")); &#125; catch (Exception ex) &#123; throw new Error(ex); &#125;&#125;private volatile int value; AtomicInteger 类主要利用 CAS (compare and swap) + volatile 和 native 方法来保证原子操作，从而避免 synchronized 的高开销，执行效率大为提升。 CAS的原理是拿期望的值和原本的一个值作比较，如果相同则更新成新的值。UnSafe 类的 objectFieldOffset() 方法是一个本地方法，这个方法是用来拿到“原来的值”的内存地址。另外 value 是一个volatile变量，在内存中可见，因此 JVM 可以保证任何时刻任何线程总能拿到该变量的最新值。 synchronized与LockJava中有两种加锁的方式：一种是用synchronized关键字，另一种是用Lock接口的实现类。 形象地说，synchronized关键字是自动档，可以满足一切日常驾驶需求。但是如果你想要玩漂移或者各种骚操作，就需要手动档了——各种Lock的实现类。 synchronized关键字synchronized关键字主要的三种使用方式： synchronized修饰非静态方法（普通方法）时，锁住的是对象的实例，即this对象 synchronized修饰静态方法时，也就是给当前类加锁，会作用于类的所有对象实例，因为静态成员不属于任何一个实例对象，是类成员（ static 表明这是该类的一个静态资源，不管new了多少个对象，只有一份） 所以如果一个线程 A 调用一个实例对象的非静态 synchronized 方法，而线程 B 需要调用这个实例对象所属类的静态 synchronized 方法，是允许的，不会发生互斥现象，因为访问静态 synchronized 方法占用的锁是当前类的锁，而访问非静态 synchronized 方法占用的锁是当前实例对象锁。 synchronized修饰代码块，锁住的是在括号里面的对象。 总结： synchronized 关键字加到 static 静态方法和 synchronized(class)代码块上都是是给 Class 类上锁。synchronized 关键字加到实例方法上是给对象实例上锁。尽量不要使用 synchronized(String a) 因为JVM中，字符串常量池具有缓存功能！(会带来很不好的后果，如synchronized(a)和synchronized(b)，可能a和b指向的是同一个对象。) synchronized 关键字底层原理属于 JVM 层面。 ① synchronized 同步语句块的情况 synchronized 同步语句块的实现使用的是 monitorenter 和 monitorexit 指令，其中 monitorenter 指令指向同步代码块的开始位置，monitorexit 指令则指明同步代码块的结束位置。 当执行 monitorenter 指令时，线程试图获取锁也就是获取 monitor(monitor对象存在于每个Java对象的对象头中，synchronized 锁便是通过这种方式获取锁的，也是为什么Java中任意对象可以作为锁的原因) 的持有权。当计数器为0则可以成功获取，获取后将锁计数器设为1也就是加1。相应的在执行 monitorexit 指令后，将锁计数器设为0，表明锁被释放。如果获取对象锁失败，那当前线程就要阻塞等待，直到锁被另外一个线程释放为止。 ② synchronized 修饰方法的的情况 synchronized 修饰的方法并没有 monitorenter 指令和 monitorexit 指令，取得代之的确实是 ACC_SYNCHRONIZED 标识，该标识指明了该方法是一个同步方法，JVM 通过该 ACC_SYNCHRONIZED 访问标志来辨别一个方法是否声明为同步方法，从而执行相应的同步调用。 JDK1.6 之后的synchronized 关键字底层做了哪些优化，可以详细介绍一下这些优化吗JDK1.6 对锁的实现引入了大量的优化，如偏向锁、轻量级锁、自旋锁、适应性自旋锁、锁消除、锁粗化等技术来减少锁操作的开销。 锁主要存在四种状态，依次是：无锁状态、偏向锁状态、轻量级锁状态、重量级锁状态，他们会随着竞争的激烈而逐渐升级。注意锁可以升级不可降级，这种策略是为了提高获得锁和释放锁的效率。 synchronized锁升级：偏向锁 → 轻量级锁 → 重量级锁偏向锁： 初次执行到synchronized代码块的时候，锁对象变成偏向锁（通过CAS修改对象头里的锁标志位），字面意思是“偏向于第一个获得它的线程”的锁。执行完同步代码块后，线程并不会主动释放偏向锁。当第二次到达同步代码块时，线程会判断此时持有锁的线程是否就是自己（持有锁的线程ID也在对象头里），如果是则正常往下执行。由于之前没有释放锁，这里也就不需要重新加锁。如果自始至终使用锁的线程只有一个，很明显偏向锁几乎没有额外开销，性能极高。 偏向锁，顾名思义，它会偏向于第一个访问锁的线程，如果在运行过程中，同步锁只有一个线程访问，不存在多线程争用的情况，则线程是不需要触发同步的，这种情况下，就会给线程加一个偏向锁。如果在运行过程中，遇到了其他线程抢占锁，则持有偏向锁的线程会被挂起，JVM会消除它身上的偏向锁，将锁恢复到标准的轻量级锁。 轻量级锁： 轻量级锁是由偏向所升级来的，偏向锁运行在一个线程进入同步块的情况下，当第二个线程加入锁争用的时候，偏向锁就会升级为轻量级锁。在轻量级锁状态下继续锁竞争，没有抢到锁的线程将自旋，即不停地循环判断锁是否能够被成功获取。获取锁的操作，其实就是通过CAS修改对象头里的锁标志位。先比较当前锁标志位是否为“释放”，如果是则将其设置为“锁定”，比较并设置是原子性发生的。这就算抢到锁了，然后线程将当前锁的持有者信息修改为自己。 重量级锁 如果锁竞争情况严重，某个达到最大自旋次数的线程，会将轻量级锁升级为重量级锁（依然是CAS修改锁标志位，但不修改持有锁的线程ID）。当后续线程尝试获取锁时，发现被占用的锁是重量级锁，则直接将自己挂起。 自旋锁(spin lock)与互斥量(mutex)的比较 自旋锁是一种非阻塞锁，也就是说，如果某线程需要获取自旋锁，但该锁已经被其他线程占用时，该线程不会被挂起，而是在不断的消耗CPU的时间，不停的试图获取自旋锁。 互斥量是阻塞锁，当某线程无法获取互斥量时，该线程会被直接挂起，该线程不再消耗CPU时间，当其他线程释放互斥量后，操作系统会激活那个被挂起的线程，让其投入运行。 互斥同步对性能最大的影响就是阻塞的实现，因为挂起线程/恢复线程的操作都需要转入内核态中完成（用户态转换到内核态会耗费时间）。一般线程持有锁的时间都不是太长，所以仅仅为了这一点时间去挂起线程/恢复线程是得不偿失的。在 JDK1.6 中引入了自适应的自旋锁。自适应的自旋锁带来的改进就是：自旋的时间（次数）不在固定了，而是和前一次同一个锁上的自旋时间以及锁的拥有者的状态来决定，虚拟机变得越来越“聪明”了。 锁清除 锁消除理解起来很简单，它指的就是虚拟机即使编译器在运行时，如果检测到那些共享数据不可能存在竞争，那么就执行锁消除。锁消除可以节省毫无意义的请求锁的时间（没必要就不要加锁嘛）。 锁粗化 把关联性强的锁操作合并成一个，避免频繁获取锁和释放锁，反而影响性能。 减少锁粒度 它的思想是将物理上的一个锁，拆成逻辑上的多个锁，增加并行度，从而降低锁竞争。它的思想也是用空间来换时间；java中很多数据结构都是采用这种方法提高并发操作的效率：如ConcurrentHashMap Synchronized的实现它有多个队列，当多个线程一起访问某个对象监视器的时候，对象监视器会将这些线程存储在不同的容器中。 Contention List：竞争队列，所有请求锁的线程首先被放在这个竞争队列中； Entry List：Contention List中那些有资格成为候选资源的线程被移动到Entry List中； Wait Set：哪些调用wait方法被阻塞的线程被放置在这里； OnDeck：任意时刻，最多只有一个线程正在竞争锁资源，该线程被成为OnDeck； Owner：当前已经获取到所资源的线程被称为Owner； !Owner：当前释放锁的线程。 Synchronized是非公平锁。 Synchronized在线程进入ContentionList时，等待的线程会先尝试自旋获取锁，如果获取不到就进入ContentionList，这明显对于已经进入队列的线程是不公平的，还有一个不公平的事情就是自旋获取锁的线程还可能直接抢占OnDeck线程的锁资源。 ReentrantLockReentrantLock继承了Lock接口，是一个可重入的独占锁。 需要显示获取和释放锁。 支持公平锁和非公平锁的实现（先来先服务）。 不但提供了synchronized对锁的操作功能，还提供了诸如响应中断，可轮询锁，定时锁等避免多线程死锁。 谈谈 synchronized和ReentrantLock 的区别① 两者都是可重入锁 支持一个线程对同一个资源执行多次加锁操作。 ② synchronized 依赖于 JVM 而 ReentrantLock 依赖于 API ③ ReentrantLock 比 synchronized 增加了一些高级功能 如可以实现公平锁，而synchronized是非公平锁；还可以定时锁，响应中断等。 volatile关键字并发编程的三个重要特性 原子性 : 一个的操作或者多次操作，要么所有的操作全部都得到执行并且不会收到任何因素的干扰而中断，要么所有的操作都执行，要么都不执行。synchronized和Lock可以保证代码片段的原子性。(由于synchronized和Lock能够保证任一时刻只有一个线程执行该代码块，那么自然就不存在原子性问题了，从而保证了原子性。) 可见性 ：当一个变量对共享变量进行了修改，那么另外的线程都是立即可以看到修改后的最新值。volatile 关键字可以保证共享变量的可见性。 有序性 ：代码在执行的过程中的先后顺序，Java 在编译器以及运行期间的优化，代码的执行顺序未必就是编写代码时候的顺序。volatile 关键字可以禁止指令进行重排序优化。 在Java中，对基本数据类型的变量的读取和赋值操作是原子性操作，即这些操作是不可被中断的，要么执行，要么不执行。 1234x = 10; //赋值操作，直接将数值10写入到工作内存，是原子性操作y = x; //实际上包含2个操作，它先要去读取x的值，再将x的值写入工作内存，不是原子性操作x++; //语句3x = x + 1; //语句4 包括3个操作：读取x的值，进行加1操作，写入新的值。 说说 synchronized 关键字和 volatile 关键字的区别volatile关键字能保证数据的可见性，但不能保证数据的原子性。synchronized关键字两者都能保证。 volatile关键字主要用于解决变量在多个线程之间的可见性，而 synchronized关键字解决的是多个线程之间访问资源的同步性。 多线程访问volatile关键字不会发生阻塞，而synchronized关键字可能会发生阻塞 volatile在一定程度上保证有序性：在进行指令优化时，不能将在对volatile变量访问的语句放在其后面执行，也不能把volatile变量后面的语句放到其前面执行。但前面和后面那块可能无序。 使用条件您只能在有限的一些情形下使用 volatile 变量替代锁。要使 volatile 变量提供理想的线程安全，必须同时满足下面两个条件： 对变量的写操作不依赖于当前值。 该变量没有包含在具有其他变量的不变式中。 实际上，这些条件表明，可以被写入 volatile 变量的这些有效值独立于任何程序的状态，包括变量的当前状态。 事实上，我的理解就是上面的2个条件需要保证操作是原子性操作，才能保证使用volatile关键字的程序在并发时能够正确执行。 volatile的适用场景不适用：第一个条件的限制使 volatile 变量不能用作线程安全计数器。虽然增量操作（x++）看上去类似一个单独操作，实际上它是一个由（读取－修改－写入）操作序列组成的组合操作，必须以原子方式执行，而 volatile 不能提供必须的原子特性。实现正确的操作需要使x 的值在操作期间保持不变，而 volatile 变量无法实现这点。 适用：比如实现一个布尔状态标志，用于指示发生了一个重要的一次性事件，例如完成初始化或请求停机。 ThreadLocalThreadLocal简介通常情况下，我们创建的变量是可以被任何一个线程访问并修改的。如果想实现每一个线程都有自己的专属本地变量该如何解决呢？ JDK中提供的ThreadLocal类正是为了解决这样的问题。 ThreadLocal类主要解决的就是让每个线程绑定自己的值，可以将ThreadLocal类形象的比喻成存放数据的盒子，盒子中可以存储每个线程的私有数据。 123ThreadLocal&lt;String&gt; localName = new ThreadLocal();localName.set("小狼");String name = localName.get(); 在线程1中初始化了一个ThreadLocal对象localName，并通过set方法，保存了一个值小狼，同时在线程1中通过localName.get()可以拿到之前设置的值，但是如果在线程2中，拿到的将是一个null。 如果你创建了一个ThreadLocal变量，那么访问这个变量的每个线程都会有这个变量的本地副本，这也是ThreadLocal变量名的由来。他们可以使用 get（） 和 set（） 方法来获取默认值或将其值更改为当前线程所存的副本的值，从而避免了线程安全问题。 原理：每个Thread中都具备一个ThreadLocalMap（ThreadLocalMap并没有实现Map接口，而是自己用数组”实现”了一个Map），而ThreadLocalMap可以存储以ThreadLocal对象为key ，Object 对象为 value的键值对。 内存泄露ThreadLocal可能导致内存泄漏，为什么？ 先看看Entry的实现： 12345678static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; &#123; /** The value associated with this ThreadLocal. */ Object value; Entry(ThreadLocal&lt;?&gt; k, Object v) &#123; super(k); value = v; &#125;&#125; 通过之前的分析已经知道，当使用ThreadLocal保存一个value时，会在ThreadLocalMap中的数组插入一个Entry对象，按理说key-value都应该以强引用保存在Entry对象中，但在ThreadLocalMap的实现中，key被保存到了WeakReference(弱引用)对象中。 这就导致了一个问题，ThreadLocal在没有外部强引用时，发生GC时会被回收，如果创建ThreadLocal的线程一直持续运行，那么这个Entry对象中的value就有可能一直得不到回收，发生内存泄露。 解决 既然已经发现有内存泄露的隐患，自然有应对的策略，在调用ThreadLocal的get()、set()可能会清除ThreadLocalMap中key为null的Entry对象，这样对应的value就没有GC Roots可达了，下次GC的时候就可以被回收，当然如果调用remove方法，肯定会删除对应的Entry对象。 如果使用ThreadLocal的set方法之后，没有显示的调用remove方法，就有可能发生内存泄露，所以养成良好的编程习惯十分重要，使用完ThreadLocal之后，记得调用remove方法。 1234567ThreadLocal&lt;String&gt; localName = new ThreadLocal();try &#123; localName.set("小狼"); // 其它业务逻辑&#125; finally &#123; localName.remove();&#125; AQSAbstractQueuedSynchronizer，抽象队列同步器 AQS是一个用来构建锁和同步器的框架，使用AQS能简单且高效地构造出应用广泛的大量的同步器，比如我们提到的ReentrantLock，Semaphore，其他的诸如ReentrantReadWriteLock，SynchronousQueue，FutureTask等等皆是基于AQS的。 给大家画一个图，看一下ReentrantLock和AQS之间的关系。 我们看上图，说白了，ReentrantLock内部包含了一个AQS对象，也就是AbstractQueuedSynchronizer类型的对象。这个AQS对象就是ReentrantLock可以实现加锁和释放锁的关键性的核心组件。 AQS 原理概览AQS核心思想是，如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的工作线程，并且将共享资源设置为锁定状态。如果被请求的共享资源被占用，那么就需要一套线程阻塞等待以及被唤醒时锁分配的机制，这个机制AQS是用CLH队列锁实现的，即将暂时获取不到锁的线程加入到队列中。 好了，现在如果有一个线程过来尝试用ReentrantLock的lock()方法进行加锁，会发生什么事情？ 很简单，这个AQS对象内部有一个核心的变量叫做state，是int类型的，代表了加锁的状态。 1private volatile int state;//共享变量，使用volatile修饰保证线程可见性 初始状态下，这个state的值是0。 另外，这个AQS内部还有一个关键变量，用来记录当前加锁的是哪个线程，初始化状态下，这个变量是null。 接着线程跑过来调用ReentrantLock的lock()方法尝试进行加锁，这个加锁的过程，直接就是用CAS操作将state值从0变为1。如果成功，会设置state=1，代表已加锁。 大家看明白了那个state变量之后，就知道了如何进行可重入加锁！ 其实每次线程1可重入加锁一次，会判断一下当前加锁线程就是自己，那么他自己就可以可重入多次加锁，每次加锁就是把state的值给累加1，别的没啥变化。 AQS定义两种资源共享方式 Exclusive （独占）：只有一个线程能执行，如ReentrantLock。又可分为公平锁和非公平锁： 公平锁：按照线程在队列中的排队顺序，先到者先拿到锁 非公平锁：当线程要获取锁时，无视队列顺序直接去抢锁，谁抢到就是谁的 Share（共享）：多个线程可同时执行，如Semaphore/CountDownLatch。Semaphore、CountDownLatch、 CyclicBarrier、ReadWriteLock 我们都会在后面讲到。 ReentrantReadWriteLock 可以看成是组合式，因为ReentrantReadWriteLock也就是读写锁允许多个线程同时对某一资源进行读。只有一个线程可以写。 AQS 组件总结 Semaphore(信号量)-允许多个线程同时访问： synchronized 和 ReentrantLock 都是一次只允许一个线程访问某个资源，Semaphore(信号量)可以指定多个线程同时访问某个资源。 CountDownLatch （倒计时器）： CountDownLatch是一个同步工具类，用来协调多个线程之间的同步。这个工具通常用来控制线程等待，它可以让某一个线程等待直到倒计时结束，再开始执行。]]></content>
  </entry>
  <entry>
    <title><![CDATA[Java并发1]]></title>
    <url>%2F2020%2F03%2F25%2FJava%E5%B9%B6%E5%8F%911%2F</url>
    <content type="text"><![CDATA[说说并发与并行的区别? 并发： 同一时间段，多个任务都在执行 (单位时间内不一定同时执行)； 并行： 单位时间内，多个任务同时执行。 什么是上下文切换?多线程编程中一般线程的个数都大于 CPU 核心的个数，而一个 CPU 核心在任意时刻只能被一个线程使用，为了让这些线程都能得到有效执行，CPU 采取的策略是为每个线程分配时间片并轮转的形式。当一个线程的时间片用完的时候就会重新处于就绪状态让给其他线程使用，这个过程就属于一次上下文切换。 概括来说就是：当前任务在执行完 CPU 时间片切换到另一个任务之前会先保存自己的状态，以便下次再切换回这个任务时，可以再加载这个任务的状态。任务从保存到再加载的过程就是一次上下文切换。 上下文的切换流程如下。 挂起一个进程(线程)，将这个进程在CPU中的状态(上下文信息)存储于内存的PCB(TCB)中。 在PCB中检索下一个进程的上下文并将其在CPU的寄存器中恢复。 跳转到程序计数器所指向的位置(即跳转到进程被中断时的代码行)并恢复该进程。 死锁的四个必要条件 互斥条件：该资源任意一个时刻只由一个线程占用。 请求和保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放。 不可抢占条件：线程已获得的资源在末使用完之前不能被其他线程抢占，只有自己使用完毕后才释放资源。 循环等待条件：若干进程之间形成一种头尾相接的循环等待资源关系。 如何避免线程死锁?我上面说了产生死锁的四个必要条件，为了避免死锁，我们只要破坏产生死锁的四个条件中的其中一个就可以了。现在我们来挨个分析一下： 破坏互斥条件 ：这个条件我们没有办法破坏，因为我们用锁本来就是想让他们互斥的（临界资源需要互斥访问）。 破坏请求与保持条件 ：一次性申请所有的资源。 破坏不可抢占条件 ：占用部分资源的线程进一步申请其他资源时，如果申请不到，可以主动释放它占有的资源。 破坏循环等待条件 ：靠按序申请资源来预防。按某一顺序申请资源，释放资源则反序释放。破坏循环等待条件。 线程的基本方法 线程等待：wait方法 线程睡眠：sleep方法 线程让步：yield方法 调用yield方法会使当前线程让出(释放)CPU执行时间片，与其他线程一起重新竞选CPU时间片 。 一般优先级高的线程更有可能竞选得到。 线程中断：interrupt方法 interrupt方法用于向线程发送一个终止的通知。 如果线程处于被阻塞状态,那么该线程将立即退出被阻塞状态,并且抛出一个InterrupedException异常. 如果线程处于运行状态,那么会将该线程的中断标志设置为true.被设置中断标志的线程将继续正常运行,不受影响. 所以，需要调用interrupt方法的线程配合中断，在正常运行任务时,经常检查本线程的中断标志,如果被设置了中断标志就自行停止线程。 线程加入：join方法 Thread类中的join方法的主要作用就是同步，它可以使得线程之间的并发执行变为串行执行。 即如果在A线程中调用了B线程的join()方法时，表示只有当B线程执行完毕时，A线程才能继续执行。 join方法也可以带参数。如A线程中调用B.join(10)，则表示A线程会等待B线程执行10毫秒，10毫秒过后，A、B线程并发执行。需要注意的是，jdk规定，join(0)的意思不是A线程等待B线程0秒，而是A线程等待B线程无限时间，直到B线程执行完毕，即join(0)等价于join()。 线程唤醒：notify方法 wait()、notify/notifyAll() 方法是Object的本地final方法，无法被重写。 wait()使当前线程阻塞，前提是必须先获得锁，一般配合synchronized 关键字使用，即，一般在synchronized 同步代码块里使用 wait()、notify/notifyAll() 方法。 由于 wait()、notify/notifyAll() 在synchronized 代码块执行，说明当前线程一定是获取了锁的。 notify/notifyAll() 的执行只是唤醒沉睡的线程，而不会立即释放锁 后台守护进程：setDaemon方法 setDaemon方法用于定义一个守护进程，也叫做“服务进程”，该线程时后台进程，有一个特性，即为用户线程提供公共服务，在没有用户线程时会自动离开。如垃圾回收线程。 说说 sleep() 方法和 wait() 方法区别和共同点? 两者最主要的区别在于：sleep 方法没有释放锁，而 wait 方法释放了锁 。 sleep方法属于Thread类，wait方法属于Object类； sleep方法暂停指定的时间，让出CPU给其它线程，但其监控状态依然保持，在指定的时候过后又会自动恢复运行状态。 调用sleep方法，线程不会释放对象锁；wait() 方法被调用后，会释放锁，线程不会自动苏醒，需要别的线程调用同一个对象上的 notify() 或者 notifyAll() 方法。 为什么我们调用 start() 方法时会执行 run() 方法，为什么我们不能直接调用 run() 方法？new 一个 Thread，线程进入了新建状态;调用 start() 方法，会启动一个线程并使线程进入了就绪状态，当分配到时间片后就可以开始运行了。 start() 会执行线程的相应准备工作，然后自动执行 run() 方法的内容，这是真正的多线程工作。 而直接执行 run() 方法，会把 run 方法当成一个 main 线程下的普通方法去执行，并不会在某个线程中执行它，所以这并不是多线程工作。 总结： 调用 start 方法方可启动线程并使线程进入就绪状态，而 run 方法只是 thread 的一个普通方法调用，还是在主线程里执行。所以run方法不可以手动调用，不然就是普通方法了 终止线程的四种方式1.正常运行结束 指线程体执行完成，线程自动结束。 2.使用退出标志退出线程 可以用volatile关键字定义一个变量，当满足某种条件时，触发关闭线程。 12345678public class ThreadSafe extends Thread&#123; public volatile boolean exit = false; public void run()&#123; while(!exit)&#123; //执行业务逻辑代码 &#125; &#125;&#125; volatile关键字：这个关键字可以使exit线程同步安全，也就是说在同一时间只能有一个线程修改exit的值。 3.使用interrupt方法终止线程 线程处于运行状态时，通过修改中断标志为True，线程配合结束。 线程处于阻塞状态时，捕获InterrupedException异常来结束。 4.使用stop方法终止线程：不安全 已被弃用。不安全，可能会导致数据不一致等问题。 Java线程的创建方式1.继承Thread类 123456public class MyThread extends Thread&#123; private int i=0; @Override public void run()&#123; &#125;&#125; 2.实现Runnable接口 其实Thread类也是实现Runnable接口来的。所以我们可以直接实现Runnable接口，可以避免单继承局限。 123456public class ChildrenClassThread extends SuperClass inplements Runnable&#123; private int i=0; @Override public void run()&#123; &#125;&#125; 3.实现Callable接口 实现Callable接口，并重写call方法。可以实现有返回值的线程。 12345public class CallableThreadTest implements Callable&lt;Integer&gt; &#123; @Override public Integer call() throws Exception &#123; &#125; &#125; 4.基于线程池 线程池为什么要用线程池？ 池化技术相比大家已经屡见不鲜了，线程池、数据库连接池、Http 连接池等等都是对这个思想的应用。池化技术的思想主要是为了减少每次获取资源的消耗，提高对资源的利用率。 降低资源消耗。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。 提高响应速度。当任务到达时，任务可以不需要的等到线程创建就能立即执行。 提高线程的可管理性。线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控。 执行execute()方法和submit()方法的区别是什么呢？ execute()方法用于提交不需要返回值的任务，所以无法判断任务是否被线程池执行成功与否； submit()方法用于提交需要返回值的任务。线程池会返回一个 Future 类型的对象，通过这个 Future 对象可以判断任务是否执行成功， 如何创建线程池《阿里巴巴Java开发手册》中强制线程池不允许使用 Executors 去创建，而是通过 ThreadPoolExecutor 的方式，这样的处理方式让写的同学更加明确线程池的运行规则，规避资源耗尽的风险 Executors 返回线程池对象的弊端如下： FixedThreadPool 和 SingleThreadExecutor ： 允许请求的队列长度为 Integer.MAX_VALUE ，可能堆积大量的请求，从而导致OOM(out of memory)。 CachedThreadPool 和 ScheduledThreadPool ： 允许创建的线程数量为 Integer.MAX_VALUE ，可能会创建大量线程，从而导致OOM。 方式一：通过构造方法实现 方法二：通过Executor 框架的工具类Executors来实现 略 ThreadPoolExecutor 类分析ThreadPoolExecutor 类中提供的四个构造方法。我们来看最长的那个，其余三个都是在这个构造方法的基础上产生 ThreadPoolExecutor构造函数重要参数分析ThreadPoolExecutor 3 个最重要的参数： corePoolSize : 核心线程数线程数定义了最小可以同时运行的线程数量。 maximumPoolSize : 当队列中存放的任务达到队列容量的时候，当前可以同时运行的线程数量变为最大线程数。 workQueue: 当新任务来的时候会先判断当前运行的线程数量是否达到核心线程数，如果达到的话，新任务就会被存放在队列中。 ThreadPoolExecutor其他常见参数: keepAliveTime:当线程池中的线程数量大于 corePoolSize 的时候，如果这时没有新的任务提交，核心线程外的线程不会立即销毁，而是会等待，直到等待的时间超过了 keepAliveTime才会被回收销毁； unit : keepAliveTime 参数的时间单位。 threadFactory :executor 创建新线程的时候会用到。 handler :饱和策略。关于饱和策略下面单独介绍一下。 ThreadPoolExecutor 饱和策略（拒绝策略）定义：如果当前同时运行的线程数量达到最大线程数量并且队列也已经被放满了任时，ThreadPoolTaskExecutor 定义一些策略: ThreadPoolExecutor.AbortPolicy：抛出 RejectedExecutionException来拒绝新任务的处理。 ThreadPoolExecutor.CallerRunsPolicy：调用执行自己的线程运行任务。但是这种策略会降低对于新任务提交速度，影响程序的整体性能。另外，这个策略喜欢增加队列容量。如果您的应用程序可以承受此延迟并且你不能任务丢弃任何一个任务请求的话，你可以选择这个策略。 ThreadPoolExecutor.DiscardPolicy： 不处理新任务，直接丢弃掉。 ThreadPoolExecutor.DiscardOldestPolicy： 此策略将丢弃队列中最早的未处理的任务请求，并尝试提交当前任务。 注意：默认拒绝策略是直接抛出异常。 线程池原理分析]]></content>
  </entry>
  <entry>
    <title><![CDATA[HashMap和HashSet]]></title>
    <url>%2F2020%2F03%2F23%2FHashMap%E5%92%8CHashSet%2F</url>
    <content type="text"><![CDATA[HashMap HashMap结构 1hashmap.put("1","2") // entry---&gt;key---&gt;---&gt;hash---&gt;index 会把key, value包装成一个entry对象，entry里面还需next属性。 为什么HashMap里数组的容量必须是2的幂次方 求数组下标： hashcode 与数组length-1 与操作 eg： length=16 0000 1111 与hashcode与操作后，得到的值会从0-15,符合我们的要求。 但如果数组容量是17 0001 0000 与hashcode与操作后，得到的值要么是0，要么是16，其它空间都浪费了。 JDK1.8为什么不用链表了 链表查询（get）效率太低 其实还是用的，当链表长度增加大于等于8时，将采用红黑树。 当链表长度（删除） 小于6时，改回链表。 为什么用红黑树，不用完全平衡二叉树 AVL树是更加严格的平衡，因此可以提供更快的查找速度，一般读取查找密集型任务，适用AVL树。 但平衡AVL树可能需要O（log n）旋转，而红黑树将需要最多两次旋转使其达到平衡(所以AVL插入复杂度更高) JDK1.7是头插法，1.8是尾插法 主要原因在于并发下发生扩容时，可能会造成元素之间会形成一个循环链表。不过，jdk 1.8 后解决了这个问题，但是还是不建议在多线程下使用 HashMap,因为多线程下使用 HashMap 还是会存在其他问题比如数据丢失。并发环境下推荐使用 ConcurrentHashMap 。 HashSetHashSet 底层就是基于 HashMap 实现的. HashMap HashSet 实现了Map接口 实现Set接口 存储键值对 仅存储对象 调用 put（）向map中添加元素 调用 add（）方法向Set中添加元素 HashMap使用键（Key）计算Hashcode HashSet使用成员对象来计算hashcode值，对于两个对象来说hashcode可能相同，所以equals()方法用来判断对象的相等性， HashSet如何检查重复当你把对象加入HashSet时，HashSet会先计算对象的hashcode值来判断对象加入的位置，同时也会与其他加入的对象的hashcode值作比较，如果没有相符的hashcode，HashSet会假设对象没有重复出现。但是如果发现有相同hashcode值的对象，这时会调用equals（）方法来检查hashcode相等的对象是否真的相同。如果两者相同，HashSet就不会让加入操作成功。 hashCode（）与equals（）的相关规定： 如果两个对象相等，则hashcode一定也是相同的 两个对象相等,对两个equals方法返回true 两个对象有相同的hashcode值，它们也不一定是相等的 综上，equals方法被覆盖过，则hashCode方法也必须被覆盖 hashCode()的默认行为是对堆上的对象产生独特值。如果没有重写hashCode()，则该class的两个对象无论如何都不会相等（即使这两个对象指向相同的数据）。 自己理解：equls返回为true,则两者的hashcode一定相等，意即相等的对象必须具有相等的哈希码。每当equals方法被覆写，通常需要重写hashCode方法。 1234567891011121314151617181920212223242526public V put(K key, V value) &#123; if (table == EMPTY_TABLE) &#123; inflateTable(threshold); &#125; if (key == null) return putForNullKey(value); int hash = hash(key); int i = indexFor(hash, table.length); for (Entry&lt;K,V&gt; e = table[i]; e != null; e = e.next) &#123; Object k; //hashcode如果不同，短路，就会直接加入到hashset,hashmap /*如果没有重写Person类的hashcode方法，那么 Set&lt;Person&gt; set = new HashSet&lt;&gt;();可能会出现同一个Person */ if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) &#123; V oldValue = e.value; e.value = value; e.recordAccess(this); return oldValue; &#125; &#125; modCount++; addEntry(hash, key, value, i); return null; &#125; ==与equals ==既可以比较基本类型(比较值是否相等)， 也可以比较引用类型(比较地址是否相等) equals本身是object类的方法，如果没有被重写，比较的是地址；被重写后，有可能比较的是值(String) 为什么HashSet里value不是null?value是一个final修饰的、值为null的Object对象。 private static final Object PRESENT = new Object(); 如果value是null,而HashSet的remove是使用HashMap实现,则是map.remove 而map的移除会返回value,如果底层value都是存null,显然将无法分辨是否移除成功.因为没找到也返回null TreeMap &amp;&amp; LinkedHashMap 红黑树,继承自map,有序 名称 HashMap LinkedHashMap TreeMap 共同点 线程不安全 线程不安全 线程不安全 不同点 数据无序 数据有序（存储顺序） 数据有序还可以对数据进行排序 数据结构 数组+链表+红黑树 双向链表+HashMap 红黑树 HashTable是线程安全的，HashTable 内部的方法基本都经过synchronized 修饰。（如果你要保证线程安全的话就使用 ConcurrentHashMap 吧！）另外，HashTable 基本被淘汰，不要在代码中使用它。]]></content>
  </entry>
  <entry>
    <title><![CDATA[将mask显示在原图]]></title>
    <url>%2F2020%2F03%2F22%2F%E5%B0%86mask%E6%98%BE%E7%A4%BA%E5%9C%A8%E5%8E%9F%E5%9B%BE%2F</url>
    <content type="text"><![CDATA[在深度学习中，如Unet等图像分割生成的mask经常是一个二值化的图像。 为直观表示，可以用如下代码将mask画在原图。 123456789101112131415161718192021222324def draw_mask(img_path,mask_path): # 原图路径,mask路径 image = cv2.imread(img_path) # 原图 mask_2d = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE) # mask灰度图 cv2.imshow("2d", mask_2d) cv2.imshow("iamge",image) cv2.waitKey() # mask_resize = np.ones((h, w), dtype='uint8') * 255 # 如果mask与原图大小有差，需resize # mask_resize[mask_2d[:, :] == 255] = 0 #如果白色是背景，黑色是分割物体，需反转黑白色 # cv2.imshow("mask_resize", mask_resize) # 利用cv2.findContours()函数找到连通域 ret, thresh = cv2.threshold(mask_2d, 128, 255, 0) contours, hier = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE) # 利用cv2.drawContours()画连通域边界 for cnt in contours: cv2.drawContours(image, [cnt], 0, (0, 255, 0), 1) # 打开画了轮廓之后的图像 cv2.imshow('image+mask', image) cv2.waitKey(0) # 保存图像 # cv2.imwrite("show/" + os.path.basename(img_path), image) 原图 mask图 效果]]></content>
  </entry>
  <entry>
    <title><![CDATA[Redis]]></title>
    <url>%2F2020%2F03%2F21%2FRedis%2F</url>
    <content type="text"><![CDATA[Redis简介 Redis 是完全开源免费的，遵守BSD协议，是一个高性能的key-value数据库。 Redis 与其他 key - value 缓存产品有以下三个特点： Redis支持数据的持久化，可以将内存中的数据保存在磁盘中，重启的时候可以再次加载进行使用。 Redis不仅仅支持简单的key-value类型的数据，同时还提供list，set，zset，hash等数据结构的存储。 Redis支持数据的备份，即master-slave模式的数据备份。 Redis与其他key-value存储有什么不同？ Redis有着更为复杂的数据结构并且提供对他们的原子性操作，这是一个不同于其他数据库的进化路径。Redis的数据类型都是基于基本数据结构的同时对程序员透明，无需进行额外的抽象。 Redis运行在内存中但是可以持久化到磁盘，所以在对不同数据集进行高速读写时需要权衡内存，因为数据量不能大于硬件内存。在内存数据库方面的另一个优点是，相比在磁盘上相同的复杂的数据结构，在内存中操作起来非常简单，这样Redis可以做很多内部复杂性很强的事情。同时，在磁盘格式方面他们是紧凑的以追加的方式产生的，因为他们并不需要进行随机访问。 redis 和 memcached 的区别对于 redis 和 memcached 我总结了下面四点。现在公司一般都是用 redis 来实现缓存，而且 redis 自身也越来越强大了！ redis支持更丰富的数据类型（支持更复杂的应用场景）：Redis不仅仅支持简单的k/v类型的数据，同时还提供list，set，zset，hash等数据结构的存储。memcache支持简单的数据类型，String。 Redis支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用,而Memecache把数据全部存在内存之中。 集群模式：memcached没有原生的集群模式，需要依靠客户端来实现往集群中分片写入数据；但是 redis 目前是原生支持 cluster 模式的. Memcached是多线程，非阻塞IO复用的网络模型；Redis使用单线程的多路 IO 复用模型。 数据类型 String, Hash, List, Set, Zset, Bitmap, HyperLogLog, Geospatial 理解：redis 都是数据结构外面再套一个key, 所以String 就是我们常见的key -val普通形式 redis 过期策略 redis 过期策略是：定期删除+惰性删除。所谓定期删除，指的是 redis 默认是每隔 100ms 就随机抽取一些设置了过期时间的 key，检查其是否过期，如果过期就删除。 假设 redis 里放了 10w 个 key，都设置了过期时间，你每隔几百毫秒，就检查 10w 个 key，那 redis 基本上就死了，cpu 负载会很高的，消耗在你的检查过期 key 上了。注意，这里可不是每隔 100ms 就遍历所有的设置过期时间的 key，那样就是一场性能上的灾难。实际上 redis 是每隔 100ms 随机抽取一些 key 来检查和删除的。 但是问题是，定期删除可能会导致很多过期 key 到了时间并没有被删除掉，那咋整呢？所以就是惰性删除了。这就是说，在你获取某个 key 的时候，redis 会检查一下 ，这个 key 如果设置了过期时间那么是否过期了？如果过期了此时就会删除，不会给你返回任何东西。 获取 key 的时候，如果此时 key 已经过期，就删除，不会返回任何东西。 但是实际上这还是有问题的，如果定期删除漏掉了很多过期 key，然后你也没及时去查，也就没走惰性删除，此时会怎么样？如果大量过期 key 堆积在内存里，导致 redis 内存块耗尽了，咋整？答案是：走内存淘汰机制。 no-eviction：禁止驱逐数据，也就是说当内存不足以容纳新写入数据时，新写入操作会报错。这个应该没人使用吧 allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的key（这个是最常用的） volatile-lru：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰 volatile-ttl：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰 volatile-random：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰 allkeys-random：从数据集（server.db[i].dict）中任意选择数据淘汰 4.0版本后增加以下两种： volatile-lfu：从已设置过期时间的数据集(server.db[i].expires)中挑选最不经常使用的数据淘汰 allkeys-lfu：当内存不足以容纳新写入数据时，在键空间中，移除最不经常使用的key 12A~~A~~A~~A~~A~~A~~A~~A~~A~~A~~~|B~~~~~B~~~~~B~~~~~B~~~~~~~~~~~B| 考虑上面的情况，如果在|处删除，那么A距离的时间最久，但实际上A的使用频率要比B频繁，所以合理的淘汰策略应该是淘汰B。LFU就是为应对这种情况而生的。 redis 持久化机制(怎么保证 redis 挂掉之后再重启数据可以进行恢复) 很多时候我们需要持久化数据也就是将内存中的数据写入到硬盘里面，大部分原因是为了之后重用数据（比如重启机器、机器故障之后恢复数据），或者是为了防止系统故障而将数据备份到一个远程位置。 Redis不同于Memcached的很重一点就是，Redis支持持久化，而且支持两种不同的持久化操作。Redis的一种持久化方式叫快照（snapshotting，RDB），另一种方式是只追加文件（append-only file,AOF）。这两种方法各有千秋，下面我会详细这两种持久化方法是什么，怎么用，如何选择适合自己的持久化方法。 快照（snapshotting）持久化（RDB） Redis可以通过创建快照来获得存储在内存里面的数据在某个时间点上的副本。Redis创建快照之后，可以对快照进行备份，可以将快照复制到其他服务器从而创建具有相同数据的服务器副本（Redis主从结构，主要用来提高Redis性能），还可以将快照留在原地以便重启服务器的时候使用。与AOF相比，在恢复大的数据集时会更快。 快照持久化是Redis默认采用的持久化方式，在redis.conf配置文件中默认有此下配置： 12345save 900 1 #在900秒(15分钟)之后，如果至少有1个key发生变化，Redis就会自动触发BGSAVE命令创建快照。save 300 10 #在300秒(5分钟)之后，如果至少有10个key发生变化，Redis就会自动触发BGSAVE命令创建快照。save 60 10000#在60秒(1分钟)之后，如果至少有10000个key发生变化，Redis就会自动触发BGSAVE命令创建快照。 AOF（append-only file）持久化 以日志的形式记录写操作。 与快照持久化相比，AOF持久化 的实时性更好，因此已成为主流的持久化方案。默认情况下Redis没有开启AOF（append only file）方式的持久化，可以通过appendonly参数开启： 1appendonly yes 开启AOF持久化后每执行一条会更改Redis中的数据的命令，Redis就会将该命令写入硬盘中的AOF文件。AOF文件的保存位置和RDB文件的位置相同，都是通过dir参数设置的，默认的文件名是appendonly.aof。 在Redis的配置文件中存在三种不同的 AOF 持久化方式，它们分别是： 123appendfsync always #每次有数据修改发生时都会写入AOF文件,这样会严重降低Redis的速度appendfsync everysec #每秒钟同步一次，显示地将多个写命令同步到硬盘appendfsync no #让操作系统决定何时进行同步 为了兼顾数据和写入性能，用户可以考虑 appendfsync everysec选项 ，让Redis每秒同步一次AOF文件，Redis性能几乎没受到任何影响。而且这样即使出现系统崩溃，用户最多只会丢失一秒之内产生的数据。当硬盘忙于执行写入操作的时候，Redis还会优雅的放慢自己的速度以便适应硬盘的最大写入速度。 开启了RDB时，也可以同时开启AOF，但是恢复的时候会从AOF恢复。 优缺点对比： 1.对于同一份数据来说，AOF日志文件通常比RDB数据快照文件更大，恢复速度慢； 2.RDB与AOF相比，在恢复大的数据集时会更快。 3.AOF可以更好的保护数据不丢失。RDB可能会丢失崩溃到上一次快照的数据。 4.RDB在保存的时候需要复制一个副本。如果比较大的话，占内存。 Redis 4.0 对于持久化机制的优化 Redis 4.0 开始支持 RDB 和 AOF 的混合持久化（默认关闭，可以通过配置项 aof-use-rdb-preamble 开启）。 如果把混合持久化打开，AOF 重写的时候就直接把 RDB 的内容写到 AOF 文件开头。这样做的好处是可以结合 RDB 和 AOF 的优点, 快速加载同时避免丢失过多的数据。当然缺点也是有的， AOF 里面的 RDB 部分是压缩格式不再是 AOF 格式，可读性较差。 补充内容：AOF 重写 显然，.aof文件会越来越大，文件大小当达到某个值的时候，触发AOF重写。从Redis数据库遍历数据，得到set命令。重写得到新的aof文件。 AOF重写可以产生一个新的AOF文件，这个新的AOF文件和原有的AOF文件所保存的数据库状态一样，但体积更小。 AOF重写是一个有歧义的名字，该功能是通过读取数据库中的键值对来实现的，程序无须对现有AOF文件进行任何读入、分析或者写入操作。 Redis事务 DISCARD 取消事务，放弃执行事务块内的所有命令。EXEC 执行所有事务块内的命令。MULTI 标记一个事务块的开始。UNWATCH 取消 WATCH 命令对所有 key 的监视。WATCH key [key …]监视一个(或多个) key ，如果在事务执行之前这个(或这些) key 被其他命令所改动，那么事务将被打断。 在redis中，对于一个存在问题的命令，如果在入队的时候就已经出错，整个事务内的命令将都不会被执行（其后续的命令依然可以入队），如果这个错误命令在入队的时候并没有报错，而是在执行的时候出错了，那么redis默认跳过这个命令执行后续命令，不会回滚（没有原子性）。 Redis的集群模式 主从模式 所有的写请求都被发送到主数据库。在由主数据库将数据同步到从数据库上。从数据库主要用于执行读操作缓解系统的读压力。 哨兵模式 哨兵模式是一种特殊的模式，首先Redis提供了哨兵的命令，哨兵是一个独立的进程，作为进程，它会独立运行。其原理是哨兵通过发送命令，等待Redis服务器响应，从而监控运行的多个Redis实例。 这里的哨兵有两个作用 通过发送命令，让Redis服务器返回监控其运行状态，包括主服务器和从服务器。 当哨兵监测到master宕机，会自动将slave切换成master，然后通过发布订阅模式通知其他的从服务器，修改配置文件，让它们切换主机。 然而一个哨兵进程对Redis服务器进行监控，可能会出现问题，为此，我们可以使用多个哨兵进行监控。各个哨兵之间还会进行监控，这样就形成了多哨兵模式。 集群模式 哨兵模式基本可以满足一般生产的需求，具备高可用性。但是当数据量过大到一台服务器存放不下的情况时，主从模式或哨兵模式就不能满足需求了，这个时候需要对存储的数据进行分片，将数据存储到多个Redis实例中。cluster模式的出现就是为了解决单机Redis容量有限的问题，将Redis的数据根据一定的规则分配到多台机器。 cluster可以说是sentinel和主从模式的结合体，通过cluster可以实现主从和master重选功能，所以如果配置两个副本三个分片的话，就需要六个Redis实例。因为Redis的数据是根据一定规则分配到cluster的不同机器的，当数据量过大时，可以新增机器进行扩容。 集群模式特点： 所有的节点都是一主一从（也可以是一主多从），其中从不提供服务，仅作为备用 不支持同时处理多个key（如MSET/MGET），因为redis需要把key均匀分布在各个节点上，并发量很高的情况下同时创建key-value会降低性能并导致不可预测的行为 支持在线增加、删除节点 客户端可以连接任何一个主节点进行读写执行之前这个(或这些) key 被其他命令所改动，那么事务将被打断。 缓存雪崩和缓存穿透问题解决方案 什么是缓存雪崩？ 简介：缓存同一时间大面积的失效，所以，后面的请求都会落到数据库上，造成数据库短时间内承受大量请求而崩掉。 eg:对于系统 A，假设每天高峰期每秒 5000 个请求，本来缓存在高峰期可以扛住每秒 4000 个请求，但是缓存机器意外发生了全盘宕机。缓存挂了，此时 1 秒 5000 个请求全部落数据库，数据库必然扛不住，它会报一下警，然后就挂了。此时，如果没有采用什么特别的方案来处理这个故障，DBA 很着急，重启数据库，但是数据库立马又被新的流量给打死了。这就是缓存雪崩。 有哪些解决办法？ 事前：尽量保证整个 redis 集群的高可用性，发现机器宕机尽快补上。选择合适的内存淘汰策略。 事中：本地ehcache缓存 + hystrix限流&amp;降级，避免MySQL崩掉 事后：利用 redis 持久化机制保存的数据尽快恢复缓存 什么是缓存穿透？ 缓存穿透说简单点就是大量请求的 key 根本不存在于缓存中，导致请求直接到了数据库上，根本没有经过缓存这一层。举个例子：某个黑客故意制造我们缓存中不存在的 key 发起大量请求，导致大量请求落到数据库。 对于系统A，假设一秒 5000 个请求，结果其中 4000 个请求是黑客发出的恶意攻击。 黑客发出的那 4000 个攻击，缓存中查不到，每次你去数据库里查，也查不到。 举个栗子。数据库 id 是从 1 开始的，结果黑客发过来的请求 id 全部都是负数。这样的话，缓存中不会有，请求每次都“视缓存于无物”，直接查询数据库。这种恶意攻击场景的缓存穿透就会直接把数据库给打死。 有哪些解决办法？ 最基本的就是首先做好参数校验，一些不合法的参数请求直接抛出异常信息返回给客户端。比如查询的数据库 id 不能小于 0、传入的邮箱格式不对的时候直接返回错误消息给客户端等等。 缓存无效 key : 如果缓存和数据库都查不到某个 key 的数据就写一个到 redis 中(可设置为空值)去并设置过期时间，具体命令如下：SET key value EX 10086。这种方式可以解决请求的 key 变化不频繁的情况，如果黑客恶意攻击，每次构建不同的请求key，会导致 redis 中缓存大量无效的 key 。很明显，这种方案并不能从根本上解决此问题。如果非要用这种方式来解决穿透问题的话，尽量将无效的 key 的过期时间设置短一点比如 1 分钟。 布隆过滤器 布隆过滤器是一个非常神奇的数据结构，通过它我们可以非常方便地判断一个给定数据是否存在与海量数据中。我们需要的就是判断 key 是否合法，有没有感觉布隆过滤器就是我们想要找的那个“人”。具体是这样做的：把所有可能存在的请求的值都存放在布隆过滤器中，当用户请求过来，我会先判断用户发来的请求的值是否存在于布隆过滤器中。不存在的话，直接返回请求参数错误信息给客户端，存在的话才会走redis流程。 缓存击穿 缓存击穿，就是说某个 key 非常热点，访问非常频繁，处于集中式高并发访问的情况，当这个 key 在失效的瞬间，大量的请求就击穿了缓存，直接请求数据库，就像是在一道屏障上凿开了一个洞。 解决方式也很简单，可以将热点数据设置为永远不过期；或者基于 redis or zookeeper 实现互斥锁，等待第一个请求构建完缓存之后，再释放锁，进而其它请求才能通过该 key 访问数据（走redis）。 如何解决 Redis 的并发竞争 Key 问题所谓 Redis 的并发竞争 Key 的问题也就是多个系统同时对一个 key 进行操作，但是最后执行的顺序和我们期望的顺序不同，这样也就导致了结果的不同！ 推荐一种方案：分布式锁（zookeeper 和 redis 都可以实现分布式锁）。（如果不存在 Redis 的并发竞争 Key 问题，不要使用分布式锁，这样会影响性能） 缓存淘汰策略 在缓存数据过多时需要使用某种淘汰算法决定淘汰哪些数据。常用的有以下几种。 FIFO(First In First Out) : 判断被存储的时间，离目前最远的数据优先被淘汰。 LRU(Least Recently Used) : 判断缓存最近被使用的时间，距离当前时间最远的数据优先被淘汰。 LFU(Least Frequently Used) : 在一段时间内，被使用次数最少的缓存优先被淘汰。]]></content>
  </entry>
  <entry>
    <title><![CDATA[JVM垃圾回收]]></title>
    <url>%2F2020%2F03%2F20%2FJVM%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%2F</url>
    <content type="text"><![CDATA[揭开 JVM 内存分配与回收的神秘面纱Java 的自动内存管理主要是针对对象内存的回收和对象内存的分配。同时，Java 自动内存管理最核心的功能是 堆 内存中对象的分配与回收。 Java 堆是垃圾收集器管理的主要区域，因此也被称作GC 堆（Garbage Collected Heap）.从垃圾回收的角度，由于现在收集器基本都采用分代垃圾收集算法，所以 Java 堆还可以细分为：新生代和老年代：再细致一点有：Eden 空间、From Survivor、To Survivor 空间等。进一步划分的目的是更好地回收内存，或者更快地分配内存。 堆空间的基本结构 上图所示的 eden 区、s0(“From”) 区、s1(“To”) 区都属于新生代，tentired 区属于老年代。大部分情况，对象都会首先在 Eden 区域分配，在一次新生代垃圾回收后，如果对象还存活，则会进入 s1(“To”)，并且对象的年龄还会加 1(Eden 区-&gt;Survivor 区后对象的初始年龄变为 1)，当它的年龄增加到一定程度（默认为 15 岁），就会被晋升到老年代中。对象晋升到老年代的年龄阈值，可以通过参数 -XX:MaxTenuringThreshold 来设置。经过这次GC后，Eden区和”From”区已经被清空。这个时候，”From”和”To”会交换他们的角色，也就是新的”To”就是上次GC前的“From”，新的”From”就是上次GC前的”To”。不管怎样，都会保证名为To的Survivor区域是空的。Minor GC会一直重复这样的过程，直到“To”区被填满，”To”区被填满之后，会将所有对象移动到老年代中。 对象优先在 eden 区分配 目前主流的垃圾收集器都会采用分代回收算法，因此需要将堆内存分为新生代和老年代，这样我们就可以根据各个年代的特点选择合适的垃圾收集算法。 大多数情况下，对象在新生代中 eden 区分配。当 eden 区没有足够空间进行分配时，虚拟机将发起一次 Minor GC.下面我们来进行实际测试以下。 在测试之前我们先来看看 Minor GC 和 Full GC 有什么不同呢？ 新生代 GC（Minor GC）:指发生新生代的的垃圾收集动作，Minor GC 非常频繁，回收速度一般也比较快。 老年代 GC（Major GC/Full GC）:指发生在老年代的 GC，出现了 Major GC 经常会伴随至少一次的 Minor GC（并非绝对），Major GC 的速度一般会比 Minor GC 的慢 10 倍以上。 大对象直接进入老年代 大对象就是需要大量连续内存空间的对象（比如：字符串、数组）。 为什么要这样呢？ 为了避免为大对象分配内存时由于分配担保机制（Eden不够，提前把新生代的对象转移到老年代中去）带来的复制而降低效率。 长期存活的对象将进入老年代 既然虚拟机采用了分代收集的思想来管理内存，那么内存回收时就必须能识别哪些对象应放在新生代，哪些对象应放在老年代中。为了做到这一点，虚拟机给每个对象一个对象年龄（Age）计数器。 如果对象在 Eden 出生并经过第一次 Minor GC 后仍然能够存活，并且能被 Survivor 容纳的话，将被移动到 Survivor 空间中，并将对象年龄设为 1.对象在 Survivor 中每熬过一次 MinorGC,年龄就增加 1 岁，当它的年龄增加到一定程度（默认为 15 岁），就会被晋升到老年代中。对象晋升到老年代的年龄阈值，可以通过参数 -XX:MaxTenuringThreshold 来设置。 大部分情况，对象都会首先在 Eden 区域分配，在一次新生代垃圾回收后，如果对象还存活，则会进入 s0 或者 s1，并且对象的年龄还会加 1(Eden 区-&gt;Survivor 区后对象的初始年龄变为 1)，当它的年龄增加到一定程度（默认为 15 岁），就会被晋升到老年代中。对象晋升到老年代的年龄阈值，可以通过参数 -XX:MaxTenuringThreshold 来设置。 修正：“Hotspot遍历所有对象时，按照年龄从小到大对其所占用的大小进行累积，当累积的某个年龄大小超过了survivor区的一半时，取这个年龄和MaxTenuringThreshold中更小的一个值，作为新的晋升年龄阈值”。 对象已经死亡？ 堆中几乎放着所有的对象实例，对堆垃圾回收前的第一步就是要判断那些对象已经死亡（即不能再被任何途径使用的对象）。 引用计数法 给对象中添加一个引用计数器，每当有一个地方引用它，计数器就加 1；当引用失效，计数器就减 1；任何时候计数器为 0 的对象就是不可能再被使用的。 这个方法实现简单，效率高，但是目前主流的虚拟机中并没有选择这个算法来管理内存，其最主要的原因是它很难解决对象之间相互循环引用的问题。 所谓对象之间的相互引用问题，如下面代码所示：除了对象 objA 和 objB 相互引用着对方之外，这两个对象之间再无任何引用。但是他们因为互相引用对方，导致它们的引用计数器都不为 0，于是引用计数算法无法通知 GC 回收器回收他们。 123456789101112public class ReferenceCountingGc &#123; Object instance = null; public static void main(String[] args) &#123; ReferenceCountingGc objA = new ReferenceCountingGc(); ReferenceCountingGc objB = new ReferenceCountingGc(); objA.instance = objB; objB.instance = objA; objA = null; objB = null; &#125;&#125; 可达性分析算法 这个算法的基本思想就是通过一系列的称为 “GC Roots” 的对象作为起点，从这些节点开始向下搜索，节点所走过的路径称为引用链，当一个对象到 GC Roots 没有任何引用链相连的话，则证明此对象是不可用的。 再谈引用 略 不可达的对象并非“非死不可” 即使在可达性分析法中不可达的对象，也并非是“非死不可”的，这时候它们暂时处于“缓刑阶段”，要真正宣告一个对象死亡，至少要经历两次标记过程；可达性分析法中不可达的对象被第一次标记并且进行一次筛选，筛选的条件是此对象是否有必要执行 finalize 方法。当对象没有覆盖 finalize 方法，或 finalize 方法已经被虚拟机调用过时，虚拟机将这两种情况视为没有必要执行。 被判定为需要执行的对象将会被放在一个队列中进行第二次标记，除非这个对象与引用链上的任何一个对象建立关联，否则就会被真的回收。 如何判断一个常量是废弃常量 运行时常量池主要回收的是废弃的常量。那么，我们如何判断一个常量是废弃常量呢？ 假如在常量池中存在字符串 “abc”，如果当前没有任何 String 对象引用该字符串常量的话，就说明常量 “abc” 就是废弃常量，如果这时发生内存回收的话而且有必要的话，”abc” 就会被系统清理出常量池。 如何判断一个类是无用的类 方法区主要回收的是无用的类，那么如何判断一个类是无用的类的呢？ 判定一个常量是否是“废弃常量”比较简单，而要判定一个类是否是“无用的类”的条件则相对苛刻许多。类需要同时满足下面 3 个条件才能算是 “无用的类” ： 该类所有的实例都已经被回收，也就是 Java 堆中不存在该类的任何实例。 加载该类的 ClassLoader 已经被回收。 该类对应的 java.lang.Class 对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。 虚拟机可以对满足上述 3 个条件的无用类进行回收，这里说的仅仅是“可以”，而并不是和对象一样不使用了就会必然被回收。 垃圾收集算法 标记-清除算法 该算法分为“标记”和“清除”阶段：首先标记出所有需要回收的对象，在标记完成后统一回收所有被标记的对象。它是最基础的收集算法，后续的算法都是对其不足进行改进得到。这种垃圾收集算法会带来两个明显的问题： 效率问题 空间问题（标记清除后会产生大量不连续的碎片） 复制算法 为了解决效率问题，“复制”收集算法出现了。它可以将内存分为大小相同的两块，每次使用其中的一块。当这一块的内存使用完后，就将还存活的对象复制到另一块去，然后再把使用的空间一次清理掉。这样就使每次的内存回收都是对内存区间的一半进行回收。 标记-整理算法 根据老年代的特点提出的一种标记算法，标记过程仍然与“标记-清除”算法一样，但后续步骤不是直接对可回收对象回收，而是让所有存活的对象向一端移动，然后直接清理掉端边界以外的内存。 分代收集算法 当前虚拟机的垃圾收集都采用分代收集算法，这种算法没有什么新的思想，只是根据对象存活周期的不同将内存分为几块。一般将 java 堆分为新生代和老年代，这样我们就可以根据各个年代的特点选择合适的垃圾收集算法。 比如在新生代中，每次收集都会有大量对象死去，所以可以选择复制算法，只需要付出少量对象的复制成本就可以完成每次垃圾收集。而老年代的对象存活几率是比较高的，而且没有额外的空间对它进行分配担保，所以我们必须选择“标记-清除”或“标记-整理”算法进行垃圾收集。 延伸面试问题： HotSpot 为什么要分为新生代和老年代？ 根据上面的对分代收集算法的介绍回答。 垃圾收集器 如果说收集算法是内存回收的方法论，那么垃圾收集器就是内存回收的具体实现。 虽然我们对各个收集器进行比较，但并非要挑选出一个最好的收集器。因为直到现在为止还没有最好的垃圾收集器出现，更加没有万能的垃圾收集器，我们能做的就是根据具体应用场景选择适合自己的垃圾收集器。试想一下：如果有一种四海之内、任何场景下都适用的完美收集器存在，那么我们的 HotSpot 虚拟机就不会实现那么多不同的垃圾收集器了。 Serial 收集器 Serial（串行）收集器收集器是最基本、历史最悠久的垃圾收集器了。大家看名字就知道这个收集器是一个单线程收集器了。它的 “单线程” 的意义不仅仅意味着它只会使用一条垃圾收集线程去完成垃圾收集工作，更重要的是它在进行垃圾收集工作的时候必须暂停其他所有的工作线程（ “Stop The World” ），直到它收集结束。 虚拟机的设计者们当然知道 Stop The World 带来的不良用户体验，所以在后续的垃圾收集器设计中停顿时间在不断缩短（仍然还有停顿，寻找最优秀的垃圾收集器的过程仍然在继续）。 但是 Serial 收集器有没有优于其他垃圾收集器的地方呢？当然有，它简单而高效（与其他收集器的单线程相比）。Serial 收集器由于没有线程交互的开销，自然可以获得很高的单线程收集效率。Serial 收集器对于运行在 Client 模式下的虚拟机来说是个不错的选择。 ParNew 收集器 ParNew 收集器其实就是 Serial 收集器的多线程版本，除了使用多线程进行垃圾收集外，其余行为（控制参数、收集算法、回收策略等等）和 Serial 收集器完全一样。 它是许多运行在 Server 模式下的虚拟机的首要选择，除了 Serial 收集器外，只有它能与 CMS 收集器（真正意义上的并发收集器，后面会介绍到）配合工作。 并行和并发概念补充： 并行（Parallel） ：指多条垃圾收集线程并行工作，但此时用户线程仍然处于等待状态。 并发（Concurrent）：指用户线程与垃圾收集线程同时执行（但不一定是并行，可能会交替执行），用户程序在继续运行，而垃圾收集器运行在另一个 CPU 上。 Parallel Scavenge 收集器 Parallel Scavenge 收集器也是使用复制算法的多线程收集器，它看上去几乎和ParNew都一样。 那么它有什么特别之处呢？ 1234567-XX:+UseParallelGC 使用 Parallel 收集器+ 老年代串行-XX:+UseParallelOldGC 使用 Parallel 收集器+ 老年代并行 Parallel Scavenge 收集器关注点是吞吐量（高效率的利用 CPU）。CMS 等垃圾收集器的关注点更多的是用户线程的停顿时间（提高用户体验）。所谓吞吐量就是 CPU 中用于运行用户代码的时间与 CPU 总消耗时间的比值。 Parallel Scavenge 收集器提供了很多参数供用户找到最合适的停顿时间或最大吞吐量，如果对于收集器运作不太了解的话，手工优化存在困难的话可以选择把内存管理优化交给虚拟机去完成也是一个不错的选择。 CMS 收集器 CMS（Concurrent Mark Sweep）收集器是一种以获取最短回收停顿时间为目标的收集器。它非常符合在注重用户体验的应用上使用。 CMS（Concurrent Mark Sweep）收集器是 HotSpot 虚拟机第一款真正意义上的并发收集器，它第一次实现了让垃圾收集线程与用户线程（基本上）同时工作。 从名字中的Mark Sweep这两个词可以看出，CMS 收集器是一种 “标记-清除”算法实现的，它的运作过程相比于前面几种垃圾收集器来说更加复杂一些。整个过程分为四个步骤： 初始标记： 暂停所有的其他线程，并记录下直接与 root 相连的对象，速度很快 ； 并发标记： 同时开启 GC 和用户线程，用一个闭包结构去记录可达对象。但在这个阶段结束，这个闭包结构并不能保证包含当前所有的可达对象。因为用户线程可能会不断的更新引用域，所以 GC 线程无法保证可达性分析的实时性。所以这个算法里会跟踪记录这些发生引用更新的地方。 重新标记： 重新标记阶段就是为了修正并发标记期间因为用户程序继续运行而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段的时间稍长，远远比并发标记阶段时间短 并发清除： 开启用户线程，同时 GC 线程开始对为标记的区域做清扫。 从它的名字就可以看出它是一款优秀的垃圾收集器，主要优点：并发收集、低停顿。但是它有下面三个明显的缺点： 对 CPU 资源敏感； 无法处理浮动垃圾； 它使用的回收算法-“标记-清除”算法会导致收集结束时会有大量空间碎片产生。 G1 收集器 G1 (Garbage-First) 是一款面向服务器的垃圾收集器,主要针对配备多颗处理器及大容量内存的机器. 以极高概率满足 GC 停顿时间要求的同时,还具备高吞吐量性能特征. 被视为 JDK1.7 中 HotSpot 虚拟机的一个重要进化特征。它具备一下特点： 并行与并发：G1 能充分利用 CPU、多核环境下的硬件优势，使用多个 CPU（CPU 或者 CPU 核心）来缩短 Stop-The-World 停顿时间。部分其他收集器原本需要停顿 Java 线程执行的 GC 动作，G1 收集器仍然可以通过并发的方式让 java 程序继续执行。 分代收集：虽然 G1 可以不需要其他收集器配合就能独立管理整个 GC 堆，但是还是保留了分代的概念。 空间整合：与 CMS 的“标记–清理”算法不同，G1 从整体来看是基于“标记整理”算法实现的收集器；从局部上来看是基于“复制”算法实现的。 可预测的停顿：这是 G1 相对于 CMS 的另一个大优势，降低停顿时间是 G1 和 CMS 共同的关注点，但 G1 除了追求低停顿外，还能建立可预测的停顿时间模型，能让使用者明确指定在一个长度为 M 毫秒的时间片段内。 G1 收集器的运作大致分为以下几个步骤： 初始标记 并发标记 最终标记 筛选回收 G1 收集器在后台维护了一个优先列表，每次根据允许的收集时间，优先选择回收价值最大的 Region(这也就是它的名字 Garbage-First 的由来)。这种使用 Region 划分内存空间以及有优先级的区域回收方式，保证了 G1 收集器在有限时间内可以尽可能高的收集效率（把内存化整为零）。 参考javaguide]]></content>
  </entry>
  <entry>
    <title><![CDATA[JVM]]></title>
    <url>%2F2020%2F03%2F19%2FJVM%2F</url>
    <content type="text"><![CDATA[JVM(java virtual machine) JVM的类加载机制 &amp;&amp; 类加载过程 Class 文件需要加载到虚拟机中之后才能运行和使用，那么虚拟机是如何加载这些 Class 文件呢？ 加载 通过全类名获取定义此类的二进制字节流(如硬盘——&gt;内存) 将字节流所代表的静态存储结构转换为方法区的运行时数据结构 在内存中生成一个代表该类的Class 对象,作为方法区这些数据的访问入口 连接（Linking） 验证 主要用于确保Class文件的字节流中包含信息符合JVM要求 准备 主要工作实在方法区中为类变量分配内存空间，并设置该类变量的初始默认值，即零值。如int : 0, float: 0.0f 注意：声明为final类型的变量，在准备阶段会为该变量赋值。 如： public static final int value=100; 准备阶段将为value赋值为100. 解析 JVM会将常量池中的符号引用替换为直接引用。解析动作主要针对类或接口、字段、类方法、接口方法、方法类型、方法句柄和调用限定符7类符号引用进行。 符号引用就是一组符号来描述目标，可以是任何字面量。直接引用就是直接指向目标的指针、相对偏移量或一个间接定位到目标的句柄。 初始化 初始化阶段就是执行类构造器方法( ) 的过程（不同于类的构造器） 此方法不需定义，是javac编译器自动收集类中静态代码块和类静态变量的赋值操作组成的。 如果没有上述两个。则不会有( )方法调用 JVM规定，只有父类的方法都执行成功后，子类中的该方法才可以被执行。 对于方法的调用，虚拟机会自己确保其在多线程环境中的安全性。因为方法是带锁线程安全，所以在多线程环境下进行类初始化的话可能会引起死锁，并且这种死锁很难被发现。 卸载 JVM的运行时内存 程序计数器 内存空间小，线程私有。用于存储当前运行线程所执行的字节码的行号指示器。 如果正在执行的是 Native 方法，这个计数器的值则为 (Undefined)。此内存区域是唯一一个在 Java 虚拟机规范中没有规定任何 OutOfMemoryError 情况的区域。 方法区（永久代） 属于线程共享内存区域，存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。 方法区和永久代的关系很像 Java 中接口和类的关系，类实现了接口，而永久代就是 HotSpot 虚拟机对虚拟机规范中方法区的一种实现方式。 也就是说，永久代是 HotSpot 的概念，方法区是 Java 虚拟机规范中的定义，是一种规范，而永久代是一种实现，一个是标准一个是实现。 JDK 1.8 的时候，方法区（HotSpot 的永久代）被彻底移除了（JDK1.7 就已经开始了），取而代之是元空间，元空间使用的是直接内存。 元空间的优点：整个永久代有一个 JVM 本身设置固定大小上限，无法进行调整，而元空间使用的是直接内存，受本机可用内存的限制，虽然元空间仍旧可能溢出，但是比原来出现的几率会更小。 运行时常量池运行时常量池是方法区的一部分，用于存放编译期生成的各种字面量和符号引用。 字面量：文本字符串，被声明为final的常量值，基本数据类型的值，其它。 符号应用：类和结构的完全限定名，字段名称和描述符，方法名称和描述符。 既然运行时常量池是方法区的一部分，自然受到方法区内存的限制，当常量池无法再申请到内存时会抛出 OutOfMemoryError 错误。 JDK1.7 及之后版本的 JVM 已经将运行时常量池从方法区中移了出来，在 Java 堆（Heap）中开辟了一块区域存放运行时常量池。 虚拟机栈 线程私有，生命周期和线程一致。描述的是 Java 方法执行的内存模型：每个方法在执行时都会床创建一个栈帧(Stack Frame)用于存储局部变量表、操作数栈、动态链接、方法出口等信息。每一个方法从调用直至执行结束，就对应着一个栈帧从虚拟机栈中入栈到出栈的过程。 局部变量表：存放了编译期可知的各种基本类型(boolean、byte、char、short、int、float、long、double)、对象引用(reference 类型)和 returnAddress 类型(指向了一条字节码指令的地址) StackOverFlowError： 若 Java 虚拟机栈的内存大小不允许动态扩展，那么当线程请求栈的深度超过当前 Java 虚拟机栈的最大深度的时候，就抛出 StackOverFlowError 错误。 OutOfMemoryError： 若 Java 虚拟机栈的内存大小允许动态扩展，且当线程请求栈时内存用完了，无法再动态扩展了，此时抛出 OutOfMemoryError 错误。 堆 Java 虚拟机所管理的内存中最大的一块，Java 堆是所有线程共享的一块内存区域，在虚拟机启动时创建。此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例以及数组都在这里分配内存。 Java 堆是垃圾收集器管理的主要区域，因此也被称作GC 堆（Garbage Collected Heap） 本地方法栈 和虚拟机栈所发挥的作用非常相似，区别是： 虚拟机栈为虚拟机执行 Java 方法 （也就是字节码）服务，而本地方法栈则为虚拟机使用到的 Native 方法服务。 在 HotSpot 虚拟机中和 Java 虚拟机栈合二为一。 本地方法被执行的时候，在本地方法栈也会创建一个栈帧，用于存放该本地方法的局部变量表、操作数栈、动态链接、出口信息。 方法执行完毕后相应的栈帧也会出栈并释放内存空间，也会出现 StackOverFlowError 和 OutOfMemoryError 两种错误。 类加载器 JVM 中内置了三个重要的 ClassLoader，除了 BootstrapClassLoader 其他类加载器均由 Java 实现且全部继承自java.lang.ClassLoader： BootstrapClassLoader(启动类加载器) ：最顶层的加载类，由C++实现，负责加载 JAVA_HOME/lib目录下的jar包和类或者或被 -Xbootclasspath参数指定的路径中的所有类。（String类等java核心类库都是使用引导类加载器） ExtensionClassLoader(扩展类加载器) ：主要负责加载目录 JRE_HOME/lib/ext 目录下的jar包和类，或被 java.ext.dirs 系统变量所指定的路径下的jar包。 AppClassLoader(应用程序类加载器) :面向我们用户的加载器，负责加载当前应用classpath下的所有jar包和类。（用户自定义类：默认使用系统类加载器） 除了上述3种类加载器，我们也可以通过继承java.lang.ClassLoader实现自定义类加载器。 为什么要自定义类加载器？ 答：隔离加载类（不同中间件用不同加载器，避免冲突）；修改类加载方式； 扩展加载源；防止源码泄露。 双亲委派机制 双亲委派机制的核心是保障类的唯一性和安全性。 优点： 1.避免类的重复加载。 2.保护程序安全，防止核心API被篡改。（如，自定义类java.lang.String ,他并不会加载这个。因为他会向上委托到引导类加载器，然后加载那个String。自定义java.lang.Str321 也会报错。禁止的包名，防止其破坏引导类加载器） 对象创建过程 类加载检查 虚拟机遇到一条 new 指令时，首先将去检查这个指令的参数是否能在常量池中定位到这个类的符号引用，并且检查这个符号引用代表的类是否已被加载过、解析和初始化过。如果没有，那必须先执行相应的类加载过程。 分配内存 在类加载检查通过后，接下来虚拟机将为新生对象分配内存。对象所需的内存大小在类加载完成后便可确定，为对象分配空间的任务等同于把一块确定大小的内存从 Java 堆中划分出来。分配方式有 “指针碰撞” 和 “空闲列表” 两种，选择那种分配方式由 Java 堆是否规整决定，而 Java 堆是否规整又由所采用的垃圾收集器是否带有压缩整理功能决定。 选择以上两种方式中的哪一种，取决于 Java 堆内存是否规整。而 Java 堆内存是否规整，取决于 GC 收集器的算法是”标记-清除”，还是”标记-整理”（也称作”标记-压缩”），值得注意的是，复制算法内存也是规整的 内存分配并发问题（补充内容，需要掌握） 在创建对象的时候有一个很重要的问题，就是线程安全，因为在实际开发过程中，创建对象是很频繁的事情，作为虚拟机来说，必须要保证线程是安全的，通常来讲，虚拟机采用两种方式来保证线程安全： CAS+失败重试： CAS 是乐观锁的一种实现方式。所谓乐观锁就是，每次不加锁而是假设没有冲突而去完成某项操作，如果因为冲突失败就重试，直到成功为止。虚拟机采用 CAS 配上失败重试的方式保证更新操作的原子性。 TLAB： 为每一个线程预先在 Eden 区分配一块儿内存，JVM 在给线程中的对象分配内存时，首先在 TLAB 分配，当对象大于 TLAB 中的剩余内存或 TLAB 的内存已用尽时，再采用上述的 CAS 进行内存分配 初始化零值 内存分配完成后，虚拟机需要将分配到的内存空间都初始化为零值（不包括对象头），这一步操作保证了对象的实例字段在 Java 代码中可以不赋初始值就直接使用，程序能访问到这些字段的数据类型所对应的零值。 设置对象头 初始化零值完成之后，虚拟机要对对象进行必要的设置，例如这个对象是那个类的实例、如何才能找到类的元数据信息、对象的哈希码、对象的 GC 分代年龄等信息。 这些信息存放在对象头中。 另外，根据虚拟机当前运行状态的不同，如是否启用偏向锁等，对象头会有不同的设置方式。 执行init方法 在上面工作都完成之后，从虚拟机的视角来看，一个新的对象已经产生了，但从 Java 程序的视角来看，对象创建才刚开始，&lt;init&gt; 方法还没有执行，所有的字段都还为零。所以一般来说，执行 new 指令之后会接着执行 &lt;init&gt; 方法，把对象按照程序员的意愿进行初始化，这样一个真正可用的对象才算完全产生出来。 对象的访问定位 建立对象就是为了使用对象，我们的 Java 程序通过栈上的 reference 数据来操作堆上的具体对象。对象的访问方式由虚拟机实现而定，目前主流的访问方式有①使用句柄和②直接指针两种： 句柄： 如果使用句柄的话，那么 Java 堆中将会划分出一块内存来作为句柄池，reference 中存储的就是对象的句柄地址，而句柄中包含了对象实例数据与类型数据各自的具体地址信息； 直接指针： 如果使用直接指针访问，那么 Java 堆对象的布局中就必须考虑如何放置访问类型数据的相关信息，而 reference 中存储的直接就是对象的地址 这两种对象访问方式各有优势。使用句柄来访问的最大好处是 reference 中存储的是稳定的句柄地址，在对象被移动时只会改变句柄中的实例数据指针，而 reference 本身不需要修改。使用直接指针访问方式最大的好处就是速度快，它节省了一次指针定位的时间开销。 String 对象的两种创建方式 12345String str1 = &quot;abcd&quot;;//先检查字符串常量池中有没有&quot;abcd&quot;，如果字符串常量池中没有，则创建一个，然后 str1 指向字符串常量池中的对象，如果有，则直接将 str1 指向&quot;abcd&quot;&quot;；String str2 = new String(&quot;abcd&quot;);//堆中创建一个新的对象String str3 = new String(&quot;abcd&quot;);//堆中创建一个新的对象System.out.println(str1==str2);//falseSystem.out.println(str2==str3);//false 这两种不同的创建方法是有差别的。 第一种方式是在常量池中拿对象； 第二种方式是直接在堆内存空间创建一个新的对象。 记住一点：只要使用 new 方法，便需要创建新的对象。]]></content>
  </entry>
  <entry>
    <title><![CDATA[Mysql回顾]]></title>
    <url>%2F2020%2F03%2F13%2FMysql%E5%9B%9E%E9%A1%BE%2F</url>
    <content type="text"><![CDATA[事务：指的是满足 ACID 特性的一组操作，可以通过 Commit 提交一个事务，也可以使用 Rollback 进行回滚。 ACID 1.原子性（Atomicity）要么都成功，要么都失败,即事务是最小单位，不允许切割 eg: A账户给B账户转账，A扣100元钱，B增加100元钱 2.一致性（Consistency） 数据库在事务执行前后都保持一致性状态。在一致性状态下，所有事务对同一个数据的读取结果都是相同的。 3.隔离性（Isolation） 一个事务所做的修改在最终提交以前，对其它事务是不可见的。 4.持久性（Durability） 一旦事务提交，则其所做的修改将会永远保存到数据库中。即使系统发生崩溃，事务执行的结果也不能丢失。 并发事务带来的问题： 1.脏读 T1 修改一个数据，T2 随后读取这个数据。如果 T1 撤销了这次修改，那么 T2 读取的数据是脏数据。 2.丢失修改 T1，T2,读取到某数据20，T1修改20-1，T2修改20-1，最终19，T1修改被丢失。 3.不可重复读 T2 读取一个数据，T1 对该数据做了修改。如果 T2 再次读取这个数据，此时读取的结果和第一次读取的结果不同。 4.幻读 同不可重复读一样，T2可能增加了几行，T1蒙蔽了，出现了幻觉。 事务的隔离级别 1.READ-UNCOMMITTED(读取未提交)： 最低的隔离级别，允许读取尚未提交的数据变更，可能会导致脏读、幻读或不可重复读。 2.READ-COMMITTED(读取已提交)： 允许读取并发事务已经提交的数据，可以阻止脏读，但是幻读或不可重复读仍有可能发生。** 3.REPEATABLE-READ(可重复读)： 对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，可以阻止脏读和不可重复读，但幻读仍有可能发生。 explain:在可重复读中，该sql第一次读取到数据后，就将这些数据加锁（悲观锁），其它事务无法修改这些数据，就可以实现可重复读了。但这种方法却无法锁住insert的数据，所以当事务A先前读取了数据，或者修改了全部数据，事务B还是可以insert数据提交，这时事务A就会发现莫名其妙多了一条之前没有的数据，这就是幻读，不能通过行锁来避免。需要Serializable隔离级别 ，读用读锁，写用写锁，读锁和写锁互斥，这么做可以有效的避免幻读、不可重复读、脏读等问题，但会极大的降低数据库的并发能力。 4.SERIALIZABLE(可串行化)： 最高的隔离级别，完全服从ACID的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，该级别可以防止脏读、不可重复读以及幻读。 MySQL InnoDB 存储引擎的默认支持的隔离级别是 REPEATABLE-READ（可重读） 锁机制与InnoDB锁算法MyISAM和InnoDB存储引擎使用的锁： MyISAM采用表级锁(table-level locking)。 InnoDB支持行级锁(row-level locking)和表级锁,默认为行级锁 表级锁和行级锁对比： 表级锁： MySQL中锁定 粒度最大 的一种锁，对当前操作的整张表加锁，实现简单，资源消耗也比较少，加锁快，不会出现死锁。其锁定粒度最大，触发锁冲突的概率最高，并发度最低，MyISAM和 InnoDB引擎都支持表级锁。 行级锁： MySQL中锁定 粒度最小 的一种锁，只针对当前操作的行进行加锁。 行级锁能大大减少数据库操作的冲突。其加锁粒度最小，并发度高，但加锁的开销也最大，加锁慢，会出现死锁（why?，如图所示）。 表锁不会发生这种情况，因为表锁是一次性获取所有表的锁，才开始事务。 大表优化当MySQL单表记录数过大时，数据库的CRUD性能会明显下降，一些常见的优化措施如下： 1. 限定数据的范围务必禁止不带任何限制数据范围条件的查询语句。比如：我们当用户在查询订单历史的时候，我们可以控制在一个月的范围内； 2. 读/写分离经典的数据库拆分方案，主库负责写，从库负责读； 3. 垂直分区根据数据库里面数据表的相关性进行拆分。 例如，用户表中既有用户的登录信息又有用户的基本信息，可以将用户表拆分成两个单独的表，甚至放到单独的库做分库。 简单来说垂直拆分是指数据表列的拆分，把一张列比较多的表拆分为多张表。 如下图所示，这样来说大家应该就更容易理解了。 垂直拆分的优点： 可以使得列数据变小，在查询时减少读取的Block数，减少I/O次数。此外，垂直分区可以简化表的结构，易于维护。 垂直拆分的缺点： 主键会出现冗余，需要管理冗余列，并会引起Join操作，可以通过在应用层进行Join来解决。此外，垂直分区会让事务变得更加复杂； [ 4. 水平分区保持数据表结构不变，通过某种策略存储数据分片。这样每一片数据分散到不同的表或者库中，达到了分布式的目的。 水平拆分可以支撑非常大的数据量。 水平拆分是指数据表行的拆分，表的行数超过200万行时，就会变慢，这时可以把一张的表的数据拆成多张表来存放。举个例子：我们可以将用户信息表拆分成多个用户信息表，这样就可以避免单一表数据量过大对性能造成影响。 水平拆分可以支持非常大的数据量。需要注意的一点是：分表仅仅是解决了单一表数据过大的问题，但由于表的数据还是在同一台机器上，其实对于提升MySQL并发能力没有什么意义，所以 水平拆分最好分库 。 索引Mysql索引主要使用的两种数据结构 哈希索引 O(1) 不适合范围查询。如SELECT * FROM tb1 WHERE id &lt; 500，查500次？ InnoDB不支持哈希索引 对于哈希索引来说，底层的数据结构就是哈希表，因此在绝大多数需求为单条记录查询的时候，可以选择哈希索引，查询性能最快；其余大部分场景，建议选择BTree索引。 BTree索引 和 B+Tree索引 1.B树的所有节点既存放 键(key) 也存放 数据(data);而B+树只有叶子节点存放 key 和 data，其他内节点只存放key。 2.B树的叶子节点都是独立的;B+树的叶子节点有一条引用链指向与它相邻的叶子节点。 3.B树的检索的过程相当于对范围内的每个节点的关键字做二分查找，可能还没有到达叶子节点，检索就结束了。而B+树的检索效率就很稳定了，任何查找都是从根节点到叶子节点的过程，叶子节点的顺序检索很明显（大大提升范围查询的效率）。 B+树]]></content>
  </entry>
  <entry>
    <title><![CDATA[相册更新]]></title>
    <url>%2F2019%2F12%2F01%2F%E7%9B%B8%E5%86%8C%E6%9B%B4%E6%96%B0%2F</url>
    <content type="text"><![CDATA[将图片放入photos文件夹下 运行tool.py将相册上传至七牛云photov1 hexo clean hexo d -g 注意：每30天需要将photov1备份到一个新的存储空间，获得30天域名后，修改source/js/src/photo.js的域名]]></content>
  </entry>
  <entry>
    <title><![CDATA[Unet]]></title>
    <url>%2F2019%2F09%2F25%2FUnet%2F</url>
    <content type="text"><![CDATA[论文题目：U-Net: Convolutional Networks for Biomedical Image Segmentation 下载：点击下载 Introduction: 作者提出一个基于FCN改进的U型结构的网络（U-net）和一个依赖strong use of data augmentation的训练策略，可以更充分利用训练样本。 相较于FCN的改进： 1.可以在更少的图片上训练 2.有更精确的分割 与FCN逐点相加不同，U-Net采用将特征在channel维度拼接在一起，形成更“厚”的特征 注：直接复制过来再裁剪到与上采样图片一样大小 该方法允许任意大图片的无缝分割通过一个overlap-tile策略。为了预测框中图像，缺失区域通过镜像输入图像扩张。这种tiling方法对于应用网络到大图像很重要，因为否则结果会被gpu内存限制。为了预测黄色区域的分割，需要蓝色区域作为输入。 数据增强：elastic deformations (弹性形变) 数据增强在训练样本比较少的时候,能够让神经网络学习一些不变性，弹性变换是本文使用的方法。（因为弹性形变是实际细胞中比较常见的一种形变，如果我们能采取数据增强的算法去使网络学习这种形变的不变性，就可以在分割数据集很小的情况下，使网络具有遇见弹性形变还是可以准确的检测出，相当于就是把原图，做了下弹性变形，然后，就相当于扩大了数据集嘛，自然网络就能适应这种弹性变化了，在遇见弹性变形的时候一样可以正确的分类分割） 增加touching cell之间border的权重， 参考： https://blog.csdn.net/jianyuchen23/article/details/79349694]]></content>
  </entry>
  <entry>
    <title><![CDATA[全卷积网络]]></title>
    <url>%2F2019%2F09%2F23%2F%E5%85%A8%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C%2F</url>
    <content type="text"><![CDATA[论文题目：Fully Convolutional Networks for Semantic Segmentation论文下载: 点击下载 Intorduction: FCN毫无疑问是语义分割领域的经典之作，在FCN出现之前，传统的CNN分割是将像素周围一个小区域作为CNN输入，做训练和预测，这样低效且不准确（忽略整体信息）。FCN主要有三点创新： 卷积化：即将传统CNN结构（文中提到的Alexnet、VGG）最后的全连接层改成卷积层，以便进行直接分割，这是十分有创造性的。这样，使得网络可以接受任意大小的图片，并输出和原图一样大小的分割图。只有这样，才能为每个像素做分类。(像素分类使用图像分类模型（如AlexNet VGGNet等pre-trained model）做迁移学习。) 上采样 or 反卷积：由于网络过程中进行了一系列下采样，使得特征层大小减小，了最后得到的预测层和原图一致，需要采用上采样。 并联跳跃结构：想法类似于resnet和inception，在进行分类预测时利用多层信息。 下图是传统分类CNN和FCN的对比，简单的说，FCN与CNN的区别在于FCN把CNN最后的全连接层换成卷积层，输出一张已经label好的图。 框架如如下，采用了skip connection 上图不够清晰，可以看下图 不同层次对比，其中FCN-8s效果最好 不足：对细节不敏感，没有充分考虑像素之间的关系，缺乏空间一致性。]]></content>
  </entry>
  <entry>
    <title><![CDATA[yolo改进]]></title>
    <url>%2F2019%2F09%2F17%2Fyolo%E6%94%B9%E8%BF%9B%2F</url>
    <content type="text"><![CDATA[论文题目：Assisted Excitation of Activations: A Learning Technique to Improve Object Detectors（CVPR2019）论文下载: 点击下载 摘要：在训练过程中，加入定位信息。可是提升yolov2 map 3.8个点， yolov3 map 2.2个点。这个方法适用于大多数single-stage 目标检测器。只改变了训练过程，推断过程没有任何改变。 Introduction:yolo难以解决得两个痛点：a. difficulty in localization原因：因为yolo同时做分类和定位，最后一层卷积层，更多语义信息，对分类有益。但是spatially course for localization.b. 训练时，前景与背景类别不平衡原因：不同于two-stage 检测器，没有预先减少候选框搜索空间到一个受限制的数目。大多数是简单的负样本。 Related Work: 加入辅助信息到CNN，主要分类两类： 1.同时做检测和分割，提升两个任务的表现。 2.只加入segmentation features来提高检测的精度。 本文提出的方法，在训练检测器时加入weak segmentation ground-truth(即bounding box，从而避免单独引入分割标注，更加简单),并没有增加额外的损失函数。 如上图所示，只在训练时增加了一个Assisted Excitation层。 具体过程： 最终期望的生成特征如下，其中alpha是关于时间的函数用于控制训练中的强度衰减，l+1代表第l+1层，式中c为通道数，e是增强特征： bbox内的像素位置为1，生成一个0-1mask。可见只在bbox内的区域做增强： 增强是按照通道去平均等量加上去的（作者的实验证明该效果最好）： 实验结果： ​ 从上左边的图可以看到，AE强化过的网络有全面的提升，其中在大尺度上的提升更加明显，推测原因是：大物体上加了分割强化后能够获得更强的辨认度，小物体由于本身尺度不大所以增加后也不明显。结果而言印证了这种强化的有效性，但是也完全地陷入了小目标检测的弊端了–像素内容少而被忽视。 ​ 右图的信息不太好辨认。先看yolov2的曲线来说，低iou阈值能够得到更高的改进的精度，说明其召回更好了，但是精度一高就趋于重合，改进失效，说明这种增强提高了低质量bbox的精度。再看yolov3，全IoU都有少量的提高，但是不特别大且没有明显的趋势，说明其采用的多尺度预测能一定程度地解决问题，并在其基础上能对全部精度都有增益。]]></content>
  </entry>
  <entry>
    <title><![CDATA[xml转txt]]></title>
    <url>%2F2019%2F05%2F29%2Fxml%E8%BD%ACtxt%2F</url>
    <content type="text"><![CDATA[先操作一波123456789path = &quot;images/&quot;for filenames in os.walk(pathh): filenames = list(filenames) filenames = filenames[2] for filename in filenames: print(filename) with open (&quot;class_train1.txt&quot;,&apos;a&apos;) as f: f.write(path+filename+&apos;\n&apos;) 再操作一波1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677# -*- coding: utf-8 -*-import xml.etree.ElementTree as ETimport pickleimport osfrom os import listdir, getcwdfrom os.path import joinsets = []classes = [&quot;dog&quot;, &quot;person&quot;, &quot;cat&quot;]# 原样保留。size为图片大小# 将ROI的坐标转换为yolo需要的坐标# size是图片的w和h# box里保存的是ROI的坐标（x，y的最大值和最小值）# 返回值为ROI中心点相对于图片大小的比例坐标，和ROI的w、h相对于图片大小的比例def convert(size, box): dw = 1. / (size[0]) dh = 1. / (size[1]) x = (box[0] + box[1]) / 2.0 - 1 y = (box[2] + box[3]) / 2.0 - 1 w = box[1] - box[0] h = box[3] - box[2] x = x * dw w = w * dw y = y * dh h = h * dh return (x, y, w, h)def convert_annotation(image_add): # image_add进来的是带地址的.jpg image_add = os.path.split(image_add)[1] # 截取文件名带后缀 image_add = image_add[0:image_add.find(&apos;.&apos;, 1)] # 删除后缀，现在只有文件名没有后缀 print(image_add) # 现在传进来的只有图片名没有后缀 in_file = open(&apos;xml/&apos; + image_add + &apos;.xml&apos;,encoding=&apos;utf-8&apos;) out_file = open(&apos;hebing2/labels/%s.txt&apos; % (image_add), &apos;w&apos;) tree = ET.parse(in_file) root = tree.getroot() size = root.find(&apos;size&apos;) w = int(size.find(&apos;width&apos;).text) h = int(size.find(&apos;height&apos;).text) # 在一个XML中每个Object的迭代 for obj in root.iter(&apos;object&apos;): # iter()方法可以递归遍历元素/树的所有子元素 # 找到所有的椅子 cls = obj.find(&apos;name&apos;).text # 如果训练标签中的品种不在程序预定品种，或者difficult = 1，跳过此object # cls_id 只等于1 cls_id = 0 xmlbox = obj.find(&apos;bndbox&apos;) # b是每个Object中，一个bndbox上下左右像素的元组 b = (float(xmlbox.find(&apos;xmin&apos;).text), float(xmlbox.find(&apos;xmax&apos;).text), float(xmlbox.find(&apos;ymin&apos;).text), float(xmlbox.find(&apos;ymax&apos;).text)) bb = convert((w, h), b) out_file.write(str(cls_id) + &quot; &quot; + &quot; &quot;.join([str(a) for a in bb]) + &apos;\n&apos;)if not os.path.exists(&apos;hebing2/labels/&apos;): os.makedirs(&apos;hebing2/labels/&apos;)image_adds = open(&quot;class_train1.txt&quot;)for image_add in image_adds: # print(image_add) image_add = image_add.strip() # print (image_add) convert_annotation(image_add) copy from here]]></content>
      <categories>
        <category>code</category>
      </categories>
      <tags>
        <tag>code</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[内镜去黑边]]></title>
    <url>%2F2019%2F05%2F09%2F%E5%86%85%E9%95%9C%E5%8E%BB%E9%BB%91%E8%BE%B9%2F</url>
    <content type="text"><![CDATA[对内境图片裁剪，去除黑边，效果如下图所示原图标出矩形框结果123456789101112131415161718192021222324252627282930313233343536373839404142import cv2import osdef main01(): root = &quot;C:\\Users\\liuminggui\\Desktop\\rename\\all\\&quot; # 图片来源路径 save_path = &quot;C:\\Users\\liuminggui\\Desktop\\rename\\save\\&quot; # 图片修改后的保存路径 images = os.listdir(root) for i in images: path = root + i print(i) x,y,w,h=rect_crop(path) # 得到要裁剪的，左上角坐标(x,y)和宽度w,高度h image=cv2.imread(root+i) cv2.imwrite(save_path+i, image[y:y+h+1,x:x+w+1]) # 保存裁剪图片def rect_crop(root=r&apos;F:\Project\DenseBox\data\000001.jpg&apos;): img = cv2.imread(root) # img = cv2.pyrDown(img) gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) # 得到灰度图 x_,y_ = gray.shape ret,thresh = cv2.threshold(gray,50,255,cv2.THRESH_BINARY) # 测试得到50比较好 # 注意opencv2和3这个函数可能有2个或者三个返回值 img111,contours,hier = cv2.findContours(thresh,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE) for c in contours: # 遍历所有轮廓 print(c) x,y,w,h = cv2.boundingRect(c) if w * h &gt; x_ * y_ * 0.33: # 轮廓大于整个面积的1/3，应该就是我们要找的 cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),2) print(x,y,w,h) cv2.imshow(&apos;img+rectangle&apos;,img) cv2.imshow(&apos;thresh&apos;, thresh) cv2.waitKey(0) return (x,y,w,h) return (0,0,0,0) # 找不到大矩形轮廓，则返回默认值0if __name__ == &apos;__main__&apos;: # main1() # liuminggui() main01() cover from YSH and sloan]]></content>
      <categories>
        <category>code</category>
      </categories>
      <tags>
        <tag>code</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[日本胃癌论文总结2]]></title>
    <url>%2F2019%2F05%2F07%2F%E6%97%A5%E6%9C%AC%E8%83%83%E7%99%8C%E8%AE%BA%E6%96%87%E6%80%BB%E7%BB%932%2F</url>
    <content type="text"><![CDATA[论文题目：Automatic detection of early gastric cancer in endoscopic images using a transferring convolutional neural network 摘要： Accuracy :87.6% heat map accuracy: 82.8%网络：GoogLeNet, 22 conv layers, pretrained on ImageNet 方法： 数据集处理 CNN迁移学习 judge normal vs cancer visualization – heat map 数据集处理（most important）总共有926张分辨率为1000*870的图片其中228包含胃癌 训练数据：从228张选出100张，然后对这100张，每张随机裁剪出100张左右224224的胃癌图片，每张都要包含80%病变区域，得到9587张224224的胃癌图片从包含胃癌和不包含胃癌的图片中随机裁剪出9800张224*224不包含胃癌的正常图片 测试数据：在训练数据裁剪未使用的包含和不包含胃癌的图片中，裁剪出4653胃癌图片和4997正常图片 结果]]></content>
  </entry>
  <entry>
    <title><![CDATA[日本胃癌论文总结1]]></title>
    <url>%2F2019%2F05%2F05%2F%E6%97%A5%E6%9C%AC%E8%83%83%E7%99%8C%E8%AE%BA%E6%96%87%E6%80%BB%E7%BB%931%2F</url>
    <content type="text"><![CDATA[论文题目：Application of artificial intelligence using a convolutional neural network for detecting gastric cancer in endoscopic images论文下载: 点击下载 测试集：13584张胃癌图片，包含2639个胃癌病变（经组织学验证）测试集： 2296张胃癌图片，包含69个病人，77个胃癌病变(62 cases had 1 gastric cancer lesion, 6 had 2 lesions, and 1 had 3 lesions)，每个病人18~69张图片。速度： 共用49s 检测2296张图片overall sensitivity： 92.2% （71/77） 71个胃癌病变成功被检测出来positive predictive value： 30.6%=71/（71+161） 161个非癌性病变误检测，过半误检测为胃炎 结果：实验：将训练集resize到300*300,送入网络fine-tune参数，然后检测测试集，检测胃癌病变区域。将其用矩形框框出。 714张图片被诊断出胃癌 714/2639=31.1% 测试集中52个（67.5%）是早期胃癌T1, 25个(32.5%)是advanced cancer T2,T3,T4 平均肿瘤大小是24mm(3到170mm) 思考：准确率该如何计算，如果单看被检测所有的测试集图片，只有不到1/3的图片被检测出有胃癌。但是如果按照检测的胃癌病变，一共有71/77个病变被检测出来！我想了下，主要是因为一个病变包含多张图片，作者认为只要某个病变的一张图片被正确诊断，就认为该病变被成功检测出来。类似于多示例学习。但是这样的话，误诊的也很高，这个161个非癌性病变被误诊是怎么算出来的？？？医生对误诊的区域进行手动分类统计？？？]]></content>
  </entry>
  <entry>
    <title><![CDATA[ObjectDetection]]></title>
    <url>%2F2019%2F04%2F17%2FObjectDetection%2F</url>
    <content type="text"><![CDATA[1.Huang_SpeedAccuracy_Trade-Offs_for_CVPR_2017_paper.pdf点击下载2.Johnson_DenseCap_Fully_Convolutional_CVPR_2016_paper.pdf点击下载3.yolov3点击下载]]></content>
      <categories>
        <category>论文</category>
      </categories>
      <tags>
        <tag>paper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pytorch]]></title>
    <url>%2F2019%2F04%2F11%2Fpytorch%2F</url>
    <content type="text"><![CDATA[损失函数1. CrossEntropylossa.交叉熵损失函数，常用于分类b.用这个loss前面不需要加 softmax层c.该函数限制了target的类型为torch.LongTensor1234567891011import torch as tfrom torch import nnfrom torch.autograd import Variable as V# batch_size=4, 计算每个类别分数（二分类）output = V(t.randn(4,2)) # batch_size * C=(batch_size, C)# target必须是LongTensor!target =V(t.Tensor([1,0,1,1])).long()criterion = nn.CrossEntropyLoss()loss = criterion(output, target)print(&apos;loss&apos;, loss) output: loss tensor(1.0643) 2. toch.nn.MSELoss均方损失函数，类似于nn.L1Loss函数：1234567import torchloss_fn = torch.nn.MSELoss(reduce=False, size_average=False)input = torch.autograd.Variable(torch.randn(3,4))target = torch.autograd.Variable(torch.randn(3,4))loss = loss_fn(input, target)print(input); print(target); print(loss)print(input.size(), target.size(), loss.size()) output:]]></content>
      <categories>
        <category>Pytorch</category>
      </categories>
      <tags>
        <tag>pytorch</tag>
        <tag>summary</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常用总结]]></title>
    <url>%2F2019%2F04%2F10%2F%E5%B8%B8%E7%94%A8%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[ROC曲线根据机器学习中分类器的预测得分对样例(每个样例的阳性概率)进行排序，按照顺序逐个把样本的概率作为阈值thresholds进行预测，计算出FPR和TPR。分别以FPR、TPR为横纵坐标作图即可得到ROC曲线。所以作ROC曲线时，需要先求出FPR和TPR。这两个变量的定义：FPR = TP/(TP+FN) TPR = TP/(TP+FP) 将样本输入分类器，每个样本将得到一个预测得分。我们通过设置不同的截断点，即可截取不同的信息。对应此示例图中，每个阈值的识别结果对应一个点(FPR，TPR)。当阈值取最大时，所有样本都被识别成负样本，对应于坐下角的点(0,0); 当阈值取最小时，所有样本都被识别成正样本，对应于右上角的点(1,1)，随着阈值从最大变化到最小，TP和FP都逐渐大；python中调用ROC12345678910111213141516171819import numpy as npfrom sklearn import metricsimport matplotlib.pyplot as pltfrom sklearn.metrics import auc# 真实标签y_true = np.array([0,0,1,1])print(&apos;y_true: &apos;, y_true)# y_score为预测为阳性的得分（说概率不大准确，因为这个score可以大于1）y_score = np.array([0.1, 0.35, 0.3, 0.8])print(&apos;y_score:&apos;, y_score)fpr, tpr, thresholds = metrics.roc_curve(y_true, y_score, pos_label=1)print(&apos;fpr&apos;, fpr)print(&apos;tpr&apos;, tpr)print(&apos;thresholds&apos;, thresholds)plt.plot(fpr,tpr,marker = &apos;o&apos;)plt.show()AUC = auc(fpr, tpr)print(&apos;AUC&apos;, AUC) 输出：阈值[0]表示没有被预测的实例，并且被任意设置为max(y_score) + 1 极大似然估计]]></content>
      <categories>
        <category>一些总结</category>
      </categories>
      <tags>
        <tag>summary</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[yolo 理论总结]]></title>
    <url>%2F2019%2F04%2F06%2Fyolo%E7%90%86%E8%AE%BA%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[对象识别和定位，可以看成两个任务：找到图片中某个存在对象的区域，然后识别出该区域中具体是哪个对象。 对象识别这件事（一张图片仅包含一个对象，且基本占据图片的整个范围），最近几年基于CNN卷积神经网络的各种方法已经能达到不错的效果了。所以主要需要解决的问题是，对象在哪里。 最简单的想法，就是遍历图片中所有可能的位置，地毯式搜索不同大小，不同宽高比，不同位置的每个区域，逐一检测其中是否存在某个对象，挑选其中概率最大的结果作为输出。显然这种方法效率太低。 RCNN提出候选区(Region Proposals)的方法，先从图片中搜索出一些可能存在对象的候选区（Selective Search），然后对每个候选区进行对象识别。大幅提升了对象识别和定位的效率。总体来说，RCNN系列依然是两阶段处理模式：先提出候选区，再识别候选区中的对象。 yolov1 yolov1详解(非常详细，推荐) 补充：边框回归：对于窗口一般使用四维向量(x,y,w,h)来表示， 分别表示窗口的中心点坐标和宽高。 对于图 2, 红色的框 P 代表原始的Proposal, 绿色的框 G 代表目标的 Ground Truth， 我们的目标是寻找一种关系使得输入原始的窗口 P 经过映射得到一个跟真实窗口 G 更接近的回归窗口G^。 YOLOV1的bounding box并不是Faster RCNN的AnchorFaster RCNN等一些算法采用每个grid中手工设置n个Anchor（先验框，预先设置好位置的bounding box）的设计，每个Anchor有不同的大小和宽高比。YOLO的bounding box看起来很像一个grid中2个Anchor，但它们不是。YOLO并没有预先设置2个bounding box的大小和形状，也没有对每个bounding box分别输出一个对象的预测。它的意思仅仅是对一个对象预测出2个bounding box，选择预测得相对比较准的那个。 Yolov2 yolov2改变：batch normalization,采用了anchor,借鉴Faster RCNN的做法，YOLO2也尝试采用先验框（anchor）。在每个grid预先设定一组不同大小和宽高比的边框，来覆盖整个图像的不同位置和多种尺度，这些先验框作为预定义的候选区在神经网络中将检测其中是否存在对象，以及微调边框的位置。]]></content>
      <categories>
        <category>yolo</category>
      </categories>
      <tags>
        <tag>summary</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[斯坦福皮肤癌论文总结]]></title>
    <url>%2F2019%2F03%2F15%2F%E6%96%AF%E5%9D%A6%E7%A6%8F%E7%9A%AE%E8%82%A4%E7%99%8C%E8%AE%BA%E6%96%87%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[Dermatologist-level classification of skin cancer with deep neural networks背景 以往的皮肤癌分类器往往缺乏好的泛化能力，由于缺少数据和focus on 标准任务，如只对专用医学设备产生的图片进行分类。无法对如手机拍摄的等因为缩放，角度，光线问题的照片进行分类。该文提出一种端对端的CNN，对皮肤癌进行分类。可以达到专家水平甚至更好。 数据 用了129450张图像（比以往的数据集大两个数量级）包含2032种不同的疾病。测试数据是由21位皮肤科专家标注的。 将数据划分： 127,463用于训练和validation 1,942 biopsy-labelled（活检）用于测试 模型GoogLeNet Inception V3 (用2014ImageNet预训练，1.28 million images) 结果蓝色的是CNN,红色的点代表皮肤病专家，绿色的是皮肤病专家的平均水平，可以看出，CNN胜出 在first level nodes（benign lesions, malignant lesions and non-neoplastic lesions)3 class partision 任务中可以达到72.1%的平均准确率，两个皮肤科专家分别达到65.56%和66.0%其次，在second level nodes（9分类）中CNN可以达到55.4%，两个专家分别是53.3和55.0可以看出，用更好的疾病划分方法可以提高准确率 亮点1.一种给疾病分类的算法充分利用如下疾病的树状图分类，好像这个Partition Algorithm 挺好使的看以上结果的时候可以发现，有PA和没有PA，可以提升好几个点，下图是PA具体算法2.本文的训练数据比以往大了两个数量级，数据为王。3.不仅用了专业医学设备产生的图片4.展望手机app端，提升逼格]]></content>
  </entry>
  <entry>
    <title><![CDATA[组会ppt]]></title>
    <url>%2F2019%2F03%2F14%2F%E7%BB%84%E4%BC%9Appt%2F</url>
    <content type="text"><![CDATA[1.2018.3.8 early gastric cancer.ppt点击下载 论文题目：Automatic detection of early gastric cancer in endoscopic images点击下载]]></content>
      <categories>
        <category>PPT</category>
      </categories>
      <tags>
        <tag>PPT</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MIApaper]]></title>
    <url>%2F2018%2F12%2F10%2FMIApaper%2F</url>
    <content type="text"><![CDATA[1.一种基于原型学习的多示例卷积神经网络点击下载2.Deep Multi-instance Networks with Sparse Label Assignment for Whole Mammogram Classification点击下载3.2018.12.12小组会PPT点击下载4.自然语言处理paper reading点击下载5.Prototypical Networks for Few-shot Learning点击下载6.Automatic detection of early gastric cancer in endoscopic images点击下载7.what is this点击下载8.Matching Network点击下载9.斯坦福皮肤癌点击下载10.PathologicalEvidenceExplorationinDeepRetinalImageDiagnosis点击下载11.胃癌+AI整理点击下载]]></content>
      <categories>
        <category>论文</category>
      </categories>
      <tags>
        <tag>paper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[paper]]></title>
    <url>%2F2018%2F11%2F30%2Fpaper%2F</url>
    <content type="text"><![CDATA[paper reading论文下载]]></content>
      <categories>
        <category>论文</category>
      </categories>
      <tags>
        <tag>paper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[test]]></title>
    <url>%2F2018%2F11%2F30%2Ftest%2F</url>
    <content type="text"><![CDATA[this is fucking crazy 你好 今天是周五 明天放假了 还有好多作业 this is a test今天是个好日子]]></content>
  </entry>
</search>
