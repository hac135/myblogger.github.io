<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[CPP2勿在浮沙筑高台]]></title>
    <url>%2F2021%2F07%2F05%2FCPP2%E5%8B%BF%E5%9C%A8%E6%B5%AE%E6%B2%99%E7%AD%91%E9%AB%98%E5%8F%B0%2F</url>
    <content type="text"><![CDATA[1.conversion funciton 转换函数 eg:分数转为double 2.non-explicit-one-argument ctor 别的东西转换为分数 Fraction(int num, int den=1) 3.pointer like class 4.function like class 5.namespace 经验谈 6.class template 类模板 7.函数模板 8.成员模板 reference ps: 引用其实是一个指针，是四个字节，但是为了符合我们的逻辑：sizeof(r)==sizeof(x) &amp;x==&amp;r 我们会让引用的大小和x类型的大小一致。（全都是假象）]]></content>
  </entry>
  <entry>
    <title><![CDATA[CPP入门]]></title>
    <url>%2F2021%2F05%2F25%2FCPP%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[数组的定义和初始化静态 int array[100]; //定义了数组，但是未进行初始化 静态 int array[100]={1,2}; //定义并初始化了数组，除前两个其余为默认值0 动态 int* array = new int[100]; 分配了长度为100的数组 动态 int* array = new int[100](1,2); 为长度为100的数组array初始化前两个元素 字符串C风格字符串C 风格的字符串起源于 C 语言，并在 C++ 中继续得到支持。字符串实际上是使用 null 字符 \0 终止的一维字符数组。因此，一个以 null 结尾的字符串，包含了组成字符串的字符。 下面的声明和初始化创建了一个 RUNOOB 字符串。由于在数组的末尾存储了空字符，所以字符数组的大小比单词 RUNOOB 的字符数多一个。 1char site[7] = &#123;'R', 'U', 'N', 'O', 'O', 'B', '\0'&#125;; 依据数组初始化规则，您可以把上面的语句写成以下语句： 1char site[] = "RUNOOB"; C++ 中的 String 类12#include &lt;string&gt;string str = "runoob"; 指针&amp;var 表示取var的地址 *var 访问指针中地址的值 123456789101112131415161718192021222324#include &lt;iostream&gt; using namespace std; int main ()&#123; int var = 20; // 实际变量的声明 int *ip; // 指针变量的声明 ip = &amp;var; // 在指针变量中存储 var 的地址 cout &lt;&lt; "Value of var variable: "; cout &lt;&lt; var &lt;&lt; endl; // 输出在指针变量中存储的地址 cout &lt;&lt; "Address stored in ip variable: "; cout &lt;&lt; ip &lt;&lt; endl; // 访问指针中地址的值 cout &lt;&lt; "Value of *ip variable: "; cout &lt;&lt; *ip &lt;&lt; endl; return 0;&#125; 当上面的代码被编译和执行时，它会产生下列结果： 123Value of var variable: 20Address stored in ip variable: 0xbfc601acValue of *ip variable: 20 指针和引用引用：为对象起了另外一个名字。必须初始化。引用只能绑定在对象上，而不能与字面值或某个表达式的计算结果绑定在一起。引用不是对象，没有实际地址，所以不能定义指向引用的指针。 指针：与引用一样，可以实现对其他对象的间接访问。不同点：a.指针本身是一个对象，允许对指针赋值和拷贝，指针在其生命周期内可以先后指向不同的对象。b.指针无须再定义时赋初值。 Const顶层const：表示指针本身是一个常量，更一般的，顶层const可以表示任意的对象是常量（不限于指针） 底层const：表示指针所指对象是一个常量（限指针和引用等复合类型） int *const p1 = &i; //从右往左看，p是一个常量，指向一个整型，可称为常量指针，是一个顶层const const int p2 = &ci; //从右往左看，p2是一个指针，指向一个const int也即常量，可称为指针常量（同int const p2）是一个低层const const int ci = 42; //顶层const const成员函数(P231)默认情况下，this的类型非常量的常量指针，如：Sales_data * const this 但是，我们不能将this绑定到一个常量对象上： 即 this = &amp;常量对象 是不行的，因为常量对象的值不能够更改，而this指向对象的值是可修改的，这样会出大问题。 因此，要在一个常量对象上调用普通的成员函数是不行的，我们使用常量成员函数。func(…) const{。。。}类型，const用来表明this的类型是const Sales_data * const this this是一个指向常量对象的常量指针，所指对象的值及this本身的值（地址）都不能修改。 总结：常量成员函数 (const member function)， 可读取类中的数据成员，但不能修改。 ​ 问题1. 1234567891011121314151617181920212223242526272829int main()&#123; int i=0; const int cp = i; cout&lt;&lt;cp&lt;&lt;endl; i=1; cout&lt;&lt;cp&lt;&lt;endl; return 0;&#125;//输出 0 0 因为用i的值来初始化了常量cp，后续i的值改变对cp没有影响int main()&#123; int i=0; const int * cp = &amp;i; cout&lt;&lt;*cp&lt;&lt;endl; i=1; cout&lt;&lt;*cp&lt;&lt;endl; return 0;&#125;//输出 0 1 指针的话，cp指向i的地址，i的值改变会引起cp的值改变int main()&#123; int i=0; const int &amp;cp = i; cout&lt;&lt;cp&lt;&lt;endl; i=1; cout&lt;&lt;cp&lt;&lt;endl; return 0;&#125;//输出 0 1 cp是i的别名 2.数组作为函数形参 1234567891011121314151617void func1(const int is[10])&#123; for(int i=0;i!=10;i++)&#123; cout&lt;&lt;is[i]&lt;&lt;endl; &#125;&#125;void func2(const int (&amp;is)[10])&#123; for(int i=0;i!=10;i++)&#123; cout&lt;&lt;is[i]&lt;&lt;endl; &#125;&#125;int main()&#123; int a[] = &#123;1,1,1,1,1,1,1,1,1,1,3&#125;; func1(a);//正确， func2(a);//错误，类型不匹配，只能接收长度为10的数组 return 0;&#125; 3.返回]]></content>
  </entry>
  <entry>
    <title><![CDATA[排序算法]]></title>
    <url>%2F2021%2F03%2F22%2F%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[排序算法说明排序的定义对一序列对象根据某个关键字进行排序。术语说明稳定 ：如果a原本在b前面，而a=b，排序之后a仍然在b的前面；不稳定 ：如果a原本在b的前面，而a=b，排序之后a可能会出现在b的后面；内排序 ：所有排序操作都在内存中完成；外排序 ：由于数据太大，因此把数据放在磁盘中，而排序通过磁盘和内存的数据传输才能进行；时间复杂度 ： 一个算法执行所耗费的时间。空间复杂度 ：运行完一个程序所需内存的大小。算法总结 图片名词解释： n: 数据规模 k: “桶”的个数 In-place: 占用常数内存，不占用额外内存 Out-place: 占用额外内存 冒泡排序（Bubble Sort） 冒泡排序 是一种简单的排序算法。它重复地走访过要排序的数列，一次比较两个元素，如果它们的顺序错误就把它们交换过来。走访数列的工作是重复地进行直到没有再需要交换，也就是说该数列已经排序完成。这个算法的名字由来是因为越小的元素会经由交换慢慢“浮”到数列的顶端。 选择排序 选择排序 是表现最稳定的排序算法之一 ，因为无论什么数据进去都是O(n2)的时间复杂度 ，所以用到它的时候，数据规模越小越好。唯一的好处可能就是不占用额外的内存空间了吧。理论上讲，选择排序可能也是平时排序一般人想到的最多的排序方法了吧。 选择排序(Selection-sort) 是一种简单直观的排序算法。它的工作原理：首先在未排序序列中找到最小（大）元素，存放到排序序列的起始位置，然后，再从剩余未排序元素中继续寻找最小（大）元素，然后放到已排序序列的末尾。以此类推，直到所有元素均排序完毕。 插入排序插入排序（Insertion-Sort） 的算法描述是一种简单直观的排序算法。它的工作原理是通过构建有序序列，对于未排序数据，在已排序序列中从后向前扫描，找到相应位置并插入。插入排序在实现上，通常采用in-place排序（即只需用到O(1)的额外空间的排序），因而在从后向前扫描过程中，需要反复把已排序元素逐步向后挪位，为最新元素提供插入空间。 归并排序和选择排序一样，归并排序的性能不受输入数据的影响，但表现比选择排序好的多，因为始终都是O(n log n）的时间复杂度。代价是需要额外的内存空间。 归并排序 是建立在归并操作上的一种有效的排序算法。该算法是采用分治法（Divide and Conquer）的一个非常典型的应用。归并排序是一种稳定的排序方法。将已有序的子序列合并，得到完全有序的序列；即先使每个子序列有序，再使子序列段间有序。若将两个有序表合并成一个有序表，称为2-路归并。 123456789101112131415161718192021222324252627282930313233/** * 归并排序 * * @param array * @return */ public static int[] MergeSort(int[] array) &#123; if (array.length &lt; 2) return array; int mid = array.length / 2; int[] left = Arrays.copyOfRange(array, 0, mid); int[] right = Arrays.copyOfRange(array, mid, array.length); return merge(MergeSort(left), MergeSort(right)); &#125; /** * 归并排序——将两段排序好的数组结合成一个排序数组 * * @param left * @param right * @return */ public static int[] merge(int[] left, int[] right) &#123; int[] result = new int[left.length + right.length]; for (int index = 0, i = 0, j = 0; index &lt; result.length; index++) &#123; if (i &gt;= left.length) result[index] = right[j++]; else if (j &gt;= right.length) result[index] = left[i++]; else if (left[i] &gt; right[j]) result[index] = right[j++]; else result[index] = left[i++]; &#125; return result; 快速排序123456789101112131415161718192021222324252627282930313233class Solution &#123; public int[] sortArray(int[] nums) &#123; quicksort(nums,0,nums.length-1); return nums; &#125; private void quicksort(int[] arr, int left, int right) &#123; int high=right; int low=left; if(low&gt;=high) &#123; return; &#125; int key=arr[low]; while(low&lt;high) &#123;//左右两边交替扫描，直到两边相等，从大到小排序 while(low&lt;high&amp;&amp;arr[high]&gt;=key) &#123;//从右往左扫描，找比基准key小的数 high--; &#125; arr[low]=arr[high];//比基准值小，就放在左边 while(low&lt;high&amp;&amp;arr[low]&lt;=key) &#123;//从左往右扫描，找比基准key大的数 low++; &#125; arr[high]=arr[low];//比基准值大，就放在右边 &#125; arr[low]=key;//low high是一样的，array[low]==array[high]==key已经归位 quicksort(arr,left,low-1);//递归，循环实现排序 quicksort(arr,high+1,right);//注意分区的左右“界点” &#125;&#125; 堆排序堆排序：堆排序（Heapsort）是指利用堆这种数据结构所设计的一种排序算法。堆积是一个近似完全二叉树的结构，并同时满足堆积的性质：即子结点的键值或索引总是小于（或者大于）它的父节点。 堆是具有以下性质的完全二叉树：每个结点的值都大于或等于其左右孩子结点的值，称为大顶堆；或者每个结点的值都小于或等于其左右孩子结点的值，称为小顶堆。如下图： 同时，我们对堆中的结点按层进行编号，将这种逻辑结构映射到数组中就是下面这个样子： 堆排序2 该数组从逻辑上讲就是一个堆结构，我们用简单的公式来描述一下堆的定义就是： 大顶堆：arr[i] &gt;= arr[2i+1] &amp;&amp; arr[i] &gt;= arr[2i+2] 小顶堆：arr[i] &lt;= arr[2i+1] &amp;&amp; arr[i] &lt;= arr[2i+2] ok，了解了这些定义。接下来，我们来看看堆排序的基本思想及基本步骤： 堆排序的基本思想是：将待排序序列构造成一个大顶堆，此时，整个序列的最大值就是堆顶的根节点。将其与末尾元素进行交换，此时末尾就为最大值。然后将剩余n-1个元素重新构造成一个堆，这样会得到n个元素的次小值。如此反复执行，便能得到一个有序序列了 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253//声明全局变量，用于记录数组array的长度； static int len; /** * 堆排序算法 * * @param array * @return */ public static int[] HeapSort(int[] array) &#123; len = array.length; if (len &lt; 1) return array; //1.构建一个最大堆 buildMaxHeap(array); //2.循环将堆首位（最大值）与末位交换，然后在重新调整最大堆 while (len &gt; 0) &#123; swap(array, 0, len - 1); len--; adjustHeap(array, 0); &#125; return array; &#125; /** * 建立最大堆 * * @param array */ public static void buildMaxHeap(int[] array) &#123; //从最后一个非叶子节点开始向上构造最大堆 //for循环这样写会更好一点：i的左子树和右子树分别2i+1和2(i+1) for (int i = (len/2- 1); i &gt;= 0; i--) &#123; adjustHeap(array, i); &#125; &#125; /** * 调整使之成为最大堆 * * @param array * @param i */ public static void adjustHeap(int[] array, int i) &#123; int maxIndex = i; //如果有左子树，且左子树大于父节点，则将最大指针指向左子树 if (i * 2 &lt; len &amp;&amp; array[i * 2] &gt; array[maxIndex]) maxIndex = i * 2 + 1; //如果有右子树，且右子树大于父节点，则将最大指针指向右子树 if (i * 2 + 1 &lt; len &amp;&amp; array[i * 2 + 1] &gt; array[maxIndex]) maxIndex = i * 2 + 2; //如果父节点不是最大值，则将父节点与最大值交换，并且递归调整与父节点交换的位置。 if (maxIndex != i) &#123; swap(array, maxIndex, i); adjustHeap(array, maxIndex); &#125; &#125;]]></content>
  </entry>
  <entry>
    <title><![CDATA[数据结构]]></title>
    <url>%2F2021%2F03%2F20%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"><![CDATA[二叉查找树二叉查找树，相信大家都接触过，二叉查找树的特点就是左子树的节点值比父亲节点小，而右子树的节点值比父亲节点大，如图 基于二叉查找树的这种特点，我们在查找某个节点的时候，可以采取类似于二分查找的思想，快速找到某个节点。n 个节点的二叉查找树，正常的情况下，查找的时间复杂度为 O（logn）。 之所以说是正常情况下，是因为二叉查找树有可能出现一种极端的情况，例如 这种情况也是满足二叉查找树的条件，然而，此时的二叉查找树已经近似退化为一条链表，这样的二叉查找树的查找时间复杂度顿时变成了 O(n)，可想而知，我们必须不能让这种情况发生，为了解决这个问题，于是我们引申出了平衡二叉树。 于是，通过平衡树，我们解决了二叉查找树的缺点。对于有 n 个节点的平衡树，最坏的查找时间复杂度也为 O(logn)。 平衡二叉树平衡二叉树就是为了解决二叉查找树退化成一颗链表而诞生了，平衡树具有如下特点 1、具有二叉查找树的全部特性。 2、每个节点的左子树和右子树的高度差至多等于1。 例如：图一就是一颗平衡树了，而图二则不是(节点右边标的是这个节点的高度) 红黑树虽然平衡树解决了二叉查找树退化为近似链表的缺点，能够把查找时间控制在 O(logn)，不过却不是最佳的，因为平衡树要求每个节点的左子树和右子树的高度差至多等于1，这个要求实在是太严了，导致每次进行插入/删除节点的时候，几乎都会破坏平衡树的第二个规则，进而我们都需要通过左旋和右旋来进行调整，使之再次成为一颗符合要求的平衡树。时间复杂度为O(log n) 而红黑树在插入或删除节点得时候，最多需要两次旋转和若干次变色即可以达到平衡。 定义 红黑树是一种含有红黑结点并能自平衡的二叉查找树。它必须满足下面性质： 性质1：每个节点要么是黑色，要么是红色。 性质2：根节点是黑色。 性质3：每个叶子节点（NIL）是黑色。 性质4：每个红色结点的两个子结点一定都是黑色。 性质5：任意一结点到每个叶子结点的路径都包含数量相同的黑结点。 B树B树和平衡二叉树稍有不同的是B树属于多叉树又名平衡多路查找树（查找路径不只两个），数据库索引技术里大量使用者B树和B+树的数据结构，让我们来看看他有什么特点; B+树B+树是B树的一个升级版，相对于B树来说B+树更充分的利用了节点的空间，让查询速度更加稳定，其速度完全接近于二分法查找。为什么说B+树查找的效率要比B树更高、更稳定； 面试官：为什么MySQL的索引要使用B+树，而不是其它树？比如B树？1、B+树的层级更少：相较于B树B+每个非叶子节点存储的关键字数更多，树的层级更少所以查询数据更快； 2、B+树查询速度更稳定：B+所有关键字数据地址都存在叶子节点上，所以每次查找的次数都相同所以查询速度要比B树更稳定; 3、B+树天然具备排序功能：B+树所有的叶子节点数据构成了一个有序链表，在查询大小区间的数据时候更方便，数据紧密性很高，缓存的命中率也会比B树高。 4、B+树全节点遍历更快：B+树遍历整棵树只需要遍历所有的叶子节点即可，，而不需要像B树一样需要对每一层进行遍历，这有利于数据库做全表扫描。 B树相对于B+树的优点是，如果经常访问的数据离根节点很近，而B树的非叶子节点本身存有关键字其数据的地址，所以这种数据检索的时候会要比B+树快。]]></content>
  </entry>
  <entry>
    <title><![CDATA[RabbitMQ消息队列]]></title>
    <url>%2F2021%2F03%2F16%2FRabbitMQ%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%2F</url>
    <content type="text"><![CDATA[为什么要使用消息队列？（优点）我觉得使用消息队列主要有三点好处： 通过异步处理提高系统性能（减少响应所需时间）。 削峰/限流 降低系统耦合性。 通过异步处理提高系统性能（减少响应所需时间） 将用户的请求数据存储到消息队列之后就立即返回结果。随后，系统再对消息进行消费。 因为用户请求数据写入消息队列之后就立即返回给用户了，比如注册用户信息可以放到消息队列中，直接给用户返回注册成功。秒杀订单也是如此，放到消息队列后，返回秒杀成功，等待落库后，返回给用户真正的订单信息。 削峰/限流 先将短时间高并发产生的事务消息存储在消息队列中，然后后端服务再慢慢根据自己的能力去消费这些消息，这样就避免直接把后端服务打垮掉。 举例：在电子商务一些秒杀、促销活动中，合理使用消息队列可以有效抵御促销活动刚开始大量订单涌入对系统的冲击。 降低系统耦合性使用消息队列还可以降低系统耦合性。我们知道如果模块之间不存在直接调用，那么新增模块或者修改模块就对其他模块影响较小，这样系统的可扩展性无疑更好一些。还是直接上图吧： 生产者（客户端）发送消息到消息队列中去，接受者（服务端）处理消息，需要消费的系统直接去消息队列取消息进行消费即可而不需要和其他系统有耦合， 这显然也提高了系统的扩展性。 消息队列使利用发布-订阅模式工作，消息发送者（生产者）发布消息，一个或多个消息接受者（消费者）订阅消息。 从上图可以看到消息发送者（生产者）和消息接受者（消费者）之间没有直接耦合，消息发送者将消息发送至分布式消息队列即结束对消息的处理，消息接受者从分布式消息队列获取该消息后进行后续处理，并不需要知道该消息从何而来。对新增业务，只要对该类消息感兴趣，即可订阅该消息，对原有系统和业务没有任何影响，从而实现网站业务的可扩展性设计。 消息接受者对消息进行过滤、处理、包装后，构造成一个新的消息类型，将消息继续发送出去，等待其他消息接受者订阅该消息。因此基于事件（消息对象）驱动的业务架构可以是一系列流程。 另外为了避免消息队列服务器宕机造成消息丢失，会将成功发送到消息队列的消息存储在消息生产者服务器上，等消息真正被消费者服务器处理后才删除消息。在消息队列服务器宕机后，生产者服务器会选择分布式消息队列服务器集群中的其他服务器发布消息。 备注： 不要认为消息队列只能利用发布-订阅模式工作，只不过在解耦这个特定业务环境下是使用发布-订阅模式的。除了发布-订阅模式，还有点对点订阅模式（一个消息只有一个消费者），我们比较常用的是发布-订阅模式。 另外，这两种消息模型是 JMS 提供的，AMQP 协议还提供了 5 种消息模型。 使用消息队列带来的一些问题 系统可用性降低： 系统可用性在某种程度上降低，为什么这样说呢？在加入MQ之前，你不用考虑消息丢失或者说MQ挂掉等等的情况，但是，引入MQ之后你就需要去考虑了！ 系统复杂性提高： 加入MQ之后，你需要保证消息没有被重复消费、处理消息丢失的情况、保证消息传递的顺序性等等问题！ 一致性问题： 我上面讲了消息队列可以实现异步，消息队列带来的异步确实可以提高系统响应速度。但是，万一消息的真正消费者并没有正确消费消息怎么办？这样就会导致数据不一致的情况了! RabbitMQ结构 Broker：简单来说就是消息队列服务器实体。 Exchange：消息交换机，它指定消息按什么规则，路由到哪个队列。 Queue：消息队列载体，每个消息都会被投⼊到⼀个或多个队列。 Binding：绑定，它的作⽤就是把exchange和queue按照路由规则绑定起来。 Routing Key：路由关键字，exchange根据这个关键字进⾏消息投递。 producer：消息⽣产者，就是投递消息的程序。 consumer：消息消费者，就是接受消息的程序。 channel：消息通道，在客户端的每个连接⾥，可建⽴多个channel，每个channel代表⼀个会话任务。 exchange作用类似于路由器，根据路由键将消息从exchange路由到队列上 exchange有多个种类：direct，fanout，topic fanoutfanout类型的Exchange路由规则非常简单，它会把所有发送到该Exchange的消息路由到所有与它绑定的Queue中。 上图所示，生产者（P）生产消息1将消息1推送到Exchange，由于Exchange Type=fanout这时候会遵循fanout的规则将消息推送到所有与它绑定Queue，也就是图上的两个Queue最后两个消费者消费。 directdirect类型的Exchange路由规则也很简单，它会把消息路由到那些binding key与routing key完全匹配的Queue中 direct图 当生产者（P）发送消息时Rotuing key=booking时，这时候将消息传送给Exchange，Exchange获取到生产者发送过来消息后，会根据自身的规则进行与匹配相应的Queue，这时发现Queue1和Queue2都符合，就会将消息传送给这两个队列；如果我们以Rotuing key=create和Rotuing key=confirm发送消息时，这时消息只会被推送到Queue2队列中，其他Routing Key的消息将会被丢弃。 topic前面提到的direct规则是严格意义上的匹配，换言之Routing Key必须与Binding Key相匹配的时候才将消息传送给Queue，那么topic这个规则就是模糊匹配，可以通过通配符满足一部分规则就可以传送 面试题1.RabbitMQ怎么防止消息丢失？消息持久化RabbitMQ 的消息默认存放在内存上面，如果不特别声明设置，消息不会持久化保存到硬盘上面的，如果节点重启或者意外crash掉，消息就会丢失。 所以就要对消息进行持久化处理。如何持久化，下面具体说明下： 要想做到消息持久化，必须满足以下三个条件，缺一不可。 1） Exchange 设置持久化 2）Queue 设置持久化 3）Message持久化发送：发送消息设置发送模式deliveryMode=2，代表持久化消息 注意，哪怕是你给 RabbitMQ 开启了持久化机制，也有一种可能，就是这个消息写到了 RabbitMQ 中，但是还没来得及持久化到磁盘上，结果不巧，此时 RabbitMQ 挂了，就会导致内存里的一点点数据丢失。 所以，持久化可以跟生产者那边的 confirm 机制配合起来，只有消息被持久化到磁盘之后，才会通知生产者 ack 了，所以哪怕是在持久化到磁盘之前，RabbitMQ 挂了，数据丢了，生产者收不到 ack，你也是可以自己重发的。 ACK确认 生产阶段，Producer 新建消息，然后通过网络将消息投递给 MQ Broker 存储阶段，消息将会存储在 Broker 端磁盘中 消息阶段， Consumer 将会从 Broker 拉取消息 生产阶段 生产者（Producer） 通过网络发送消息给 Broker，当 Broker 收到之后，将会返回确认响应信息给 Producer。所以生产者只要接收到返回的确认响应，就代表消息在生产阶段未丢失。 存储阶段 默认情况下，消息只要到了 Broker 端，将会优先保存到内存中，然后立刻返回确认响应给生产者。随后 Broker 定期批量的将一组消息从内存异步刷入磁盘。 这种方式减少 I/O 次数，可以取得更好的性能，但是如果发生机器掉电，异常宕机等情况，消息还未及时刷入磁盘，就会出现丢失消息的情况。 若想保证 Broker 端不丢消息，保证消息的可靠性，我们需要将消息保存机制修改为同步刷盘方式，即消息存储磁盘成功，才会返回响应。 修改 Broker 端配置如下： 1## 默认情况为 ASYNC_FLUSH flushDiskType = SYNC_FLUSH 若 Broker 未在同步刷盘时间内（默认为 5s）完成刷盘，将会返回 SendStatus.FLUSH_DISK_TIMEOUT 状态给生产者。 集群部署时 为了保证可用性，Broker 通常采用一主（master）多从（slave）部署方式。为了保证消息不丢失，消息还需要复制到 slave 节点。 默认方式下，消息写入 master 成功，就可以返回确认响应给生产者，接着消息将会异步复制到 slave 节点。 注：master 配置：flushDiskType = SYNC_FLUSH 此时若 master 突然宕机且不可恢复，那么还未复制到 slave 的消息将会丢失。 为了进一步提高消息的可靠性，我们可以采用同步的复制方式，master 节点将会同步等待 slave 节点复制完成，才会返回确认响应。 Broker master 节点 同步复制配置如下： 1## 默认为 ASYNC_MASTER brokerRole=SYNC_MASTER 如果 slave 节点未在指定时间内同步返回响应，生产者将会收到 SendStatus.FLUSH_SLAVE_TIMEOUT 返回状态。 消费阶段 消费者从 broker 拉取消息，然后执行相应的业务逻辑。一旦执行成功，将会返回 ConsumeConcurrentlyStatus.CONSUME_SUCCESS 状态给 Broker。 如果 Broker 未收到消费确认响应或收到其他状态，消费者下次还会再次拉取到该条消息，进行重试。这样的方式有效避免了消费者消费过程发生异常，或者消息在网络传输中丢失的情况。 2.防止消息重复消费以redis为例，给消息分配一个全局id，只要消费过该消息，将&lt;id,message&gt;以K-V形式写入redis。那消费者开始消费前，先去redis中查询有没消费记录即可。]]></content>
  </entry>
  <entry>
    <title><![CDATA[场景题]]></title>
    <url>%2F2020%2F08%2F28%2F%E5%9C%BA%E6%99%AF%E9%A2%98%2F</url>
    <content type="text"><![CDATA[1. 如何从大量的 URL 中找出相同的 URL？题目描述给定 a、b 两个文件，各存放 50 亿个 URL，每个 URL 各占 64B，内存限制是 4G。请找出 a、b 两个文件共同的 URL 解答思路每个 URL 占 64B，那么 50 亿个 URL占用的空间大小约为 320GB。 5,000,000,000 64B ≈ 5GB 64 = 320GB 由于内存大小只有 4G，因此，我们不可能一次性把所有 URL 加载到内存中处理。对于这种类型的题目，一般采用分治策略，即：把一个文件中的 URL 按照某个特征划分为多个小文件，使得每个小文件大小不超过 4G，这样就可以把这个小文件读到内存中进行处理了。 思路如下： 首先遍历文件 a，对遍历到的 URL 求 hash(URL) % 1000，根据计算结果把遍历到的 URL 存储到 a0, a1, a2, …, a999，这样每个大小约为 300MB。使用同样的方法遍历文件 b，把文件 b 中的 URL 分别存储到文件 b0, b1, b2, …, b999 中。这样处理过后，所有可能相同的 URL 都在对应的小文件中，即 a0 对应 b0, …, a999 对应 b999，不对应的小文件不可能有相同的 URL。那么接下来，我们只需要求出这 1000 对小文件中相同的 URL 就好了。 接着遍历 ai( i∈[0,999])，把 URL 存储到一个 HashSet 集合中。然后遍历 bi 中每个 URL，看在 HashSet 集合中是否存在，若存在，说明这就是共同的 URL，可以把这个 URL 保存到一个单独的文件中。 方法总结 分而治之，进行哈希取余； 对每个子文件进行 HashSet 统计。 2. 如何从大量数据中找出高频词？题目描述有一个 1GB 大小的文件，文件里每一行是一个词，每个词的大小不超过 16B，内存大小限制是 1MB，要求返回频数最高的 100 个词(Top 100)。 解答思路由于内存限制，我们依然无法直接将大文件的所有词一次读到内存中。因此，同样可以采用分治策略，把一个大文件分解成多个小文件，保证每个文件的大小小于 1MB，进而直接将单个小文件读取到内存中进行处理。 思路如下： 首先遍历大文件，对遍历到的每个词x，执行 hash(x) % 5000，将结果为 i 的词存放到文件 ai 中。遍历结束后，我们可以得到 5000 个小文件。每个小文件的大小为 200KB 左右。如果有的小文件大小仍然超过 1MB，则采用同样的方式继续进行分解。 接着统计每个小文件中出现频数最高的 100 个词。最简单的方式是使用 HashMap 来实现。其中 key 为词，value 为该词出现的频率。具体方法是：对于遍历到的词 x，如果在 map 中不存在，则执行 map.put(x, 1)；若存在，则执行 map.put(x, map.get(x)+1)，将该词频数加 1。 上面我们统计了每个小文件单词出现的频数。接下来，我们可以通过维护一个小顶堆来找出所有词中出现频数最高的 100 个。具体方法是：依次遍历每个小文件，构建一个小顶堆，堆大小为 100。如果遍历到的词的出现次数大于堆顶词的出现次数，则用新词替换堆顶的词，然后重新调整为小顶堆，遍历结束后，小顶堆上的词就是出现频数最高的 100 个词。 方法总结 分而治之，进行哈希取余； 使用 HashMap 统计频数； 求解最大的 TopN 个，用小顶堆；求解最小的 TopN 个，用大顶堆。 3. 如何找出某一天访问百度网站最多的 IP？题目描述现有海量日志数据保存在一个超大文件中，该文件无法直接读入内存，要求从中提取某天访问百度次数最多的那个 IP。 解答思路这道题只关心某一天访问百度最多的 IP，因此，可以首先对文件进行一次遍历，把这一天访问百度 IP 的相关信息记录到一个单独的大文件中。接下来采用的方法与上一题一样，大致就是先对 IP 进行哈希映射，接着使用 HashMap 统计重复 IP 的次数，最后计算出重复次数最多的 IP。 注：这里只需要找出出现次数最多的 IP，可以不必使用堆，直接用一个变量 max 即可。 方法总结 分而治之，进行哈希取余； 使用 HashMap 统计频数； 求解最大的 TopN 个，用小顶堆；求解最小的 TopN 个，用大顶堆。 4. 如何在大量的数据中找出不重复的整数？题目描述在 2.5 亿个整数中找出不重复的整数。注意：内存不足以容纳这 2.5 亿个整数。 解答思路方法一：分治法与前面的题目方法类似，先将 2.5 亿个数划分到多个小文件，用 HashSet/HashMap 找出每个小文件中不重复的整数，再合并每个子结果，即为最终结果。 方法二：位图法第i位代表i是否出现。但是要判断没有出现，只出现一次，重复出现，需要两位。 那么对于这道题，我们用 2 个 bit 来表示各个数字的状态： 00 表示这个数字没出现过； 01 表示这个数字出现过一次（即为题目所找的不重复整数）； 10 表示这个数字出现了多次。 那么这 232 个整数，总共所需内存为 2^32*2b=1GB。因此，当可用内存超过 1GB 时，可以采用位图法。假设内存满足位图法需求，进行下面的操作： 遍历 2.5 亿个整数，查看位图中对应的位，如果是 00，则变为 01，如果是 01 则变为 10，如果是 10 则保持不变。遍历结束后，查看位图，把对应位是 01 的整数输出即可。 方法总结判断数字是否重复的问题，位图法是一种非常高效的方法。当然位图法也可以用来快速查找，排序。 5. 如何在大量的数据中判断一个数是否存在？题目描述给定 40 亿个不重复的没排过序的 unsigned int 型整数，然后再给定一个数，如何快速判断这个数是否在这 40 亿个整数当中？ 解答思路方法一：分治法依然可以用分治法解决，方法与前面类似，就不再次赘述了。 方法二：位图法40 亿个不重复整数，我们用 40 亿个 bit 来表示，初始位均为 0，那么总共需要内存：4,000,000,000b≈512M。 我们读取这 40 亿个整数，将对应的 bit 设置为 1。接着读取要查询的数，查看相应位是否为 1，如果为 1 表示存在，如果为 0 表示不存在。 方法总结判断数字是否存在、判断数字是否重复的问题，位图法是一种非常高效的方法。 6. 如何查询最热门的查询串？题目描述搜索引擎会通过日志文件把用户每次检索使用的所有查询串都记录下来，每个查询床的长度不超过 255 字节。 假设目前有 1000w 个记录（这些查询串的重复度比较高，虽然总数是 1000w，但如果除去重复后，则不超过 300w 个）。请统计最热门的 10 个查询串，要求使用的内存不能超过 1G。（一个查询串的重复度越高，说明查询它的用户越多，也就越热门。） 解答思路每个查询串最长为 255B，1000w 个串需要占用 约 2.55G 内存，因此，我们无法将所有字符串全部读入到内存中处理。 方法一：分治法分治法依然是一个非常实用的方法。 划分为多个小文件，保证单个小文件中的字符串能被直接加载到内存中处理，然后求出每个文件中出现次数最多的 10 个字符串；最后通过一个小顶堆统计出所有文件中出现最多的 10 个字符串。 方法可行，但不是最好，下面介绍其他方法。 方法二：HashMap 法虽然字符串总数比较多，但去重后不超过 300w，因此，可以考虑把所有字符串及出现次数保存在一个 HashMap 中，所占用的空间为 300w*(255+4)≈777M（其中，4表示整数占用的4个字节）。由此可见，1G 的内存空间完全够用。 思路如下： 首先，遍历字符串，若不在 map 中，直接存入 map，value 记为 1；若在 map 中，则把对应的 value 加 1，这一步时间复杂度 O(N)。 接着遍历 map，构建一个 10 个元素的小顶堆，若遍历到的字符串的出现次数大于堆顶字符串的出现次数，则进行替换，并将堆调整为小顶堆。 遍历结束后，堆中 10 个字符串就是出现次数最多的字符串。这一步时间复杂度 O(Nlog10)。 7. 如何统计不同电话号码的个数？题目描述已知某个文件内包含一些电话号码，每个号码为 8 位数字，统计不同号码的个数。 解答思路这道题本质还是求解数据重复的问题，对于这类问题，一般首先考虑位图法。 对于本题，8 位电话号码可以表示的号码个数为 108 个，即 1 亿个。我们每个号码用一个 bit 来表示，则总共需要 1 亿个 bit，内存占用约 100M。 思路如下： 申请一个位图数组，长度为 1 亿，初始化为 0。然后遍历所有电话号码，把号码对应的位图中的位置置为 1。遍历完成后，如果 bit 为 1，则表示这个电话号码在文件中存在，否则不存在。bit 值为 1 的数量即为 不同电话号码的个数。 方法总结求解数据重复问题，记得考虑位图法。 8. 如何从 5 亿个数中找出中位数？题目描述从 5 亿个数中找出中位数。数据排序后，位置在最中间的数就是中位数。当样本数为奇数时，中位数为 第 (N+1)/2 个数；当样本数为偶数时，中位数为 第 N/2 个数与第 1+N/2 个数的均值。 解答思路如果这道题没有内存大小限制，则可以把所有数读到内存中排序后找出中位数。但是最好的排序算法的时间复杂度都为 O(NlogN)。这里使用其他方法。 方法一：双堆法维护两个堆，一个大顶堆，一个小顶堆。大顶堆中最大的数小于等于小顶堆中最小的数；保证这两个堆中的元素个数的差不超过 1。 若数据总数为偶数，当这两个堆建好之后，中位数就是这两个堆顶元素的平均值。当数据总数为奇数时，根据两个堆的大小，中位数一定在数据多的堆的堆顶。 以上这种方法，需要把所有数据都加载到内存中。当数据量很大时，就不能这样了，因此，这种方法适用于数据量较小的情况。5 亿个数，每个数字占用 4B，总共需要 2G 内存。如果可用内存不足 2G，就不能使用这种方法了，下面介绍另一种方法。 方法二：分治法分治法的思想是把一个大的问题逐渐转换为规模较小的问题来求解。 对于这道题，顺序读取这 5 亿个数字，对于读取到的数字 num，如果它对应的二进制中最高位为1，则把这个数字写到 f1 中，否则写入 f0 中。通过这一步，可以把这 5 亿个数划分为两部分，而且 f0 中的数都大于 f1 中的数（最高位是符号位）。 划分之后，可以非常容易地知道中位数是在 f0 还是 f1 中。假设 f1 中有 1 亿个数，那么中位数一定在 f0 中，且是在 f0 中，从小到大排列的第 1.5 亿个数与它后面的一个数的平均值。 提示，5 亿数的中位数是第 2.5 亿与右边相邻一个数求平均值。若 f1 有一亿个数，那么中位数就是 f0 中从第 1.5 亿个数开始的两个数求得的平均值。 对于 f0 可以用次高位的二进制继续将文件一分为二，如此划分下去，直到划分后的文件可以被加载到内存中，把数据加载到内存中以后直接排序，找出中位数。 注意，当数据总数为偶数，如果划分后两个文件中的数据有相同个数，那么中位数就是数据较小的文件中的最大值与数据较大的文件中的最小值的平均值。 方法总结分治法，真香！ 9. 如何找出排名前 500 的数？题目描述有 20 个数组，每个数组有 500 个元素，并且有序排列。如何在这 20*500 个数中找出前 500 的数？ 解答思路对于 TopK 问题，最常用的方法是使用堆排序。对本题而言，假设数组降序排列，可以采用以下方法： 首先建立大顶堆，堆的大小为数组的个数，即为 20，把每个数组最大的值存到堆中。 接着删除堆顶元素，保存到另一个大小为 500 的数组中，然后向大顶堆插入删除的元素所在数组的下一个元素。 重复上面的步骤，直到删除完第 500 个元素，也即找出了最大的前 500 个数。 为了在堆中取出一个数据后，能知道它是从哪个数组中取出的，从而可以从这个数组中取下一个值，可以把数组的指针存放到堆中，对这个指针提供比较大小的方法。 方法总结求 TopK，不妨考虑一下堆排序？ 以上，完。]]></content>
  </entry>
  <entry>
    <title><![CDATA[商城项目]]></title>
    <url>%2F2020%2F08%2F03%2F%E5%95%86%E5%9F%8E%E9%A1%B9%E7%9B%AE%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[操作系统]]></title>
    <url>%2F2020%2F08%2F01%2F%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[死锁1.产生死锁的四个必要条件 互斥条件：进程要求对所分配的资源进行排它性控制，即在一段时间内某资源仅为一进程所占用。 请求和保持条件：当进程因请求资源而阻塞时，对已获得的资源保持不放。 不可抢占：进程已获得的资源在未使用完之前，不能被抢占，只能在使用完时由自己释放。 循环等待：循环等待环形链。 2.预防(避免)死锁我上面说了产生死锁的四个必要条件，为了避免死锁，我们只要破坏产生死锁的四个条件中的其中一个就可以了。现在我们来挨个分析一下： 破坏互斥条件 ：这个条件我们没有办法破坏，因为我们用锁本来就是想让他们互斥的（临界资源需要互斥访问）。 破坏请求与保持条件 ：一次性申请所有的资源。 破坏不可抢占条件 ：占用部分资源的线程进一步申请其他资源时，如果申请不到，可以主动释放它占有的资源。 破坏循环等待条件 ：靠按序申请资源来预防。按某一顺序申请资源，释放资源则反序释放。破坏循环等待条件。 内存管理内存管理主要是做什么？主要负责内存的分配与回收(malloc函数：申请内存，free函数：释放内存)，另外地址转换也就是将逻辑地址转换成相应的物理地址也是内存管理做的事情。 常见的几种内存管理机制连续分配管理方式：分配一个连续的内存空间，如块式管理。 非连续~：允许分配离散或则不相邻的内存空间，如页式管理和段式管理。 块式管理：远古时代的计算机操系统的内存管理方式。将内存分为几个固定大小的块，每个块中只包含一个进程。如果程序运行需要内存的话，操作系统就分配给它一块，如果程序运行只需要很小的空间的话，分配的这块内存很大一部分几乎被浪费了。这些在每个块中未被利用的空间，我们称之为碎片。 页式管理：将 程序的逻辑地址空间划分为固定大小的页(page)，而物理内存划分为同样大小的页框(pageframe)。程序加载时，可将任意一页放人内存中任意一 个页框，这些页框不必连续，从而实现了离散分配。提高了内存利用率，减少了碎片。页式管理通过页表对应逻辑地址和物理地址。 段式管理：页式管理虽然提高了内存利用率，但是页式管理其中的页并没有实际含义。段式存储管理要求每个作业的地址空间按照程序自身的逻辑划分为若干段，如代码段、数据段、共享段。每个段都有一个唯一的内部段号。以段为单位进行分配，每个段在内存中占连续空间，但各段之间可以不相邻 段页式管理：段页式管理机制结合了段式管理和页式管理的优点。简单来说段页式管理机制就是把主存先分成若干段，每个段又分成若干页。 快表和多级页表在分页内存管理中，很重要的两点是： 虚拟地址到物理地址的转换要快。——-快表 解决虚拟地址空间大，页表也会很大的问题。——–多级页表 快表 为了解决虚拟地址到物理地址的转换速度，操作系统在 页表方案 基础之上引入了 快表（存放在单独的寄存器中） 来加速虚拟地址到物理地址的转换。我们可以把块表理解为一种特殊的高速缓冲存储器（Cache），其中的内容是页表的一部分或者全部内容。作为页表的 Cache，它的作用与页表相似，但是提高了访问速率。由于采用页表做地址转换，读写内存数据时 CPU 要访问两次主存。有了快表，有时只要访问一次高速缓冲存储器，一次主存，这样可加速查找并提高指令执行速度。 使用快表之后的地址转换流程是这样的： 根据虚拟地址中的页号查快表； 如果该页在快表中，直接从快表中读取相应的物理地址； 如果该页不在快表中，就访问内存中的页表，再从页表中得到物理地址，同时将页表中的该映射表项添加到快表中； 当快表填满后，又要登记新页时，就按照一定的淘汰策略淘汰掉快表中的一个页。 多级页表 引入多级页表的主要目的是为了避免把全部页表一直放在内存中占用过多空间，特别是那些根本就不需要的页表就不需要保留在内存中。多级页表属于时间换空间的典型场景。（局部性原理） 页式管理和段式管理的共同点和区别 共同点： 分页机制和分段机制都是为了提高内存利用率，较少内存碎片。 页和段都是离散存储的，所以两者都是离散分配内存的方式。但是，每个页和段中的内存是连续的。 区别： 页的大小是固定的，由操作系统决定；而段的大小不固定，取决于我们当前运行的程序。 分页仅仅是为了满足操作系统内存管理的需求，而段是逻辑信息的单位，在程序中可以体现为代码段，数据段，能够更好满足用户的需要。 虚拟内存1.什么是虚拟内存？ 虚拟内存使得应用程序认为它拥有连续的可用的内存（一个连续完整的地址空间），而实际上，它通常是被分隔成多个物理内存碎片，还有部分暂时存储在外部磁盘存储器上，在需要时进行数据交换。与没有使用虚拟内存技术的系统相比，使用这种技术的系统使得大型程序的编写变得更容易，对真正的物理内存（例如RAM）的使用也更有效率。目前，大多数系统都使用了虚拟内存，如Windows家族的“虚拟内存”；Linux的“交换空间”等。 不要单纯的认为虚拟内存只是“使用硬盘空间来拓展内存”的技术，这只是其中之一。虚拟内存的重要意义是它定义了一个连续的虚拟地址空间，而且把内存拓展到硬盘空间。 2.局部性原理程序在执行的时候往往呈现局部性规律，也就是说在某个较短的时间段内，程序执行局限于某一小部分，程序访问的存储空间也局限于某个区域。 时间局部性：如果程序中的某条指令一旦执行，不久以后该指令可能再次执行；如果某数据被访问过，不久之后该数据可能再次被访问。产生局部性的典型原因，是由于在程序中存在着大量的循环操作。 空间局部性：一旦程序访问了某个存储单元，不久以后其附近的存储单元可能也被访问。因为指令通常顺序存放，顺序执行。数据也一般以向量，数组，表等形式聚簇存储的。 3.虚拟存储器基于局部性原理，在程序装入时，可以将程序的一部分装入内存，其余部分留在外存，就可以启动程序执行。执行过程中，如果访问的信息不在内存，则将所需部分调入内存，继续执行。另一方面，操作系统将暂时不用的内容换到外存上。由于外存往往比内存大很多，计算机好像为用户提供了一个比实际内存大得多的存储器–虚拟存储器。 实际上，这是一种时间换空间的策略。用CPU的计算时间和页的调入调出时间，换来了一个虚拟的更大的空间来支持程序的运行。 4.虚拟内存的技术实现 虚拟内存的实现需要建立在离散分配的内存管理方式的基础上。 请求分页存储管理 请求分段存储管理 请求段页式存储管理 （请求分页和分页存储管理的区别：请求分页存储管理建立在分页管理之上。他们的根本区别是是否将程序全部所需的地址空间都装入主存。） 不管是上面三种哪种实现方式，我们都需要 一定容量的内存和外存。 缺页中断：如果需执行的指令或访问的数据未在内存（称为缺页或缺段），则由处理器通知操作系统将相应的页面调入内存，继续执行。 虚拟地址空间：逻辑地址到物理地址的变换。 4.页面置换算法当发生缺页中断时，操作系统需要在内存选择一个页面将其移出内存，以便为即将调入的页面让出空间。以下是几种淘汰规则。 OPT页面置换算法（最佳页面置换算法）：淘汰以后永不使用的，或是最长时间内不被访问的。无法实现。因为无法预知未来。 FIFO (first in first out)：先进先出页面置换算法。 LRU:最近最久未使用。 LFU:最少使用。使用频率最少。 常见面试题1.用户态和内核态的区别两种不同的CPU状态 内核态（Kernel Mode）：运行操作系统程序，操作硬件。 用户态（User Mode）：运行用户程序。 处于用户态执行时，进程所能访问的内存空间和对象受到限制，其所处于占有的处理器是可被抢占的 处于内核态执行时，则能访问所有的内存空间和对象，且所占有的处理器是不允许被抢占的。 用户态切换到内核态的三种情况 系统调用 这是用户态进程主动要求切换到内核态的一种方式，用户态进程通过系统调用申请使用操作系统提供的服务程序完成工作。如fork()实际上就是执行了一个创建新进程的系统调用。 异常 当CPU在执行运行在用户态下的程序时，发生了某些事先不可知的异常，这时会触发由当前运行进程切换到处理此异常的内核相关程序中，也就转到了内核态 外围设备的中断 当外围设备完成用户请求的操作后，会向CPU发出相应的中断信号，这时CPU会暂停执行下一条即将要执行的指令转而去执行与中断信号对应的处理程序。比如硬盘读写操作完成，系统会切换到硬盘读写的中断处理程序中执行后续操作等。 2.内核简单来说，内核是一个操作系统的核心。它负责管理系统的进程、内存、设备驱动程序、文件和网络系统等等，决定着系统的性能和稳定性。是连接应用程序和硬件的桥梁。内核就是操作系统背后黑盒的核心。 Shell 是指一种应用程序(命令语言)，这个应用程序提供了一个界面，用户通过这个界面访问操作系统内核的服务。 3.进程间的通信方式每个进程各自有不同的用户地址空间，任何一个进程的全局变量在另一个进程中都看不到，所以进程之间要交换数据必须通过内核，在内核中开辟一块缓冲区，进程1把数据从用户空间拷到内核缓冲区，进程2再从内核缓冲区把数据读走，内核提供的这种机制称为进程间通信 管道/匿名管道(Pipes)：用于具有亲缘关系的父子进程间或兄弟进程之间的通信。 有名管道(Named Pipes)：匿名管道，由于没有名字，只能用于亲缘关系的进程间通信。为了克服这个缺点，提出了有名管道。有名管道不同于匿名管道之处在于它提供了一个路径名与之关联，以有名管道的文件形式存在于文件系统中，这样，即使与有名管道的创建进程不存在亲缘关系的进程，只要可以访问该路径，就能够彼此通过有名管道相互通信。 信号(Signal)：信号是软件层次上对中断机制的一种模拟，是一种异步通信方式，，信号可以在用户空间进程和内核之间直接交互，内核可以利用信号来通知用户空间的进程发生了哪些系统事件，信号事件主要有两个来源： 硬件来源：用户按键输入Ctrl+C退出、硬件异常如无效的存储访问等。 软件终止：终止进程信号、其他进程调用kill函数、软件异常产生信号。 消息队列(Message Queuing)：消息队列存放在内核中的消息链表。 信号量(Semaphores)：信号量是一个计数器，用于多进程对共享数据的访问，信号量的意图在于进程间同步。这种通信方式主要用于解决与同步相关的问题并避免竞争条件。 共享内存(Shared memory)： 使得多个进程可以可以直接读写同一块内存空间，是最快的可用进程通信形式。是针对其他通信机制运行效率较低而设计的。 为了在多个进程间交换信息，内核专门留出了一块内存区，可以由需要访问的进程将其映射到自己的私有地址空间。进程就可以直接读写这一块内存而不需要进行数据的拷贝，从而大大提高效率。 由于多个进程共享一段内存，因此需要依靠某种同步机制（如信号量）来达到进程间的同步及互斥。 套接字(Socket)：套接字是一种通信机制，凭借这种机制，客户/服务器（即要进行通信的进程）系统的开发工作既可以在本地单机上进行，也可以跨网络进行。也就是说它可以让不在同一台计算机但通过网络连接计算机上的进程进行通信。 4.线程间的同步方式线程同步是两个或多个共享关键资源的线程的并发执行。应该同步线程以避免关键的资源使用冲突。操作系统一般有下面三种线程同步方式。 互斥量(mutex)：采用互斥对象机制，只有拥有互斥对象的线程才有访问资源的权限。因为互斥对象只有一个，所以可以保证公共资源不会被多个线程同时访问。比如Java中的synchronized关键字和各种Lock都是这种机制。 信号量(Semphares)：多个资源可供访问。 事件(Event)：Wait/Notify：通过通知操作的方式来保持多线程同步。 5.进程的调度算法 时间片轮转：最古老，最简单，最公平且使用最广的算法。每个进程被分配一个时间片。 先到先服务：从就绪队列选择队首进程。直到完成或者发生某事件被阻塞放弃占用CPU。 短作业优先：从就绪队列中选一个估计运行时间最短的进程为之分配资源。 优先级调度：为每个进程分配优先级。相同优先级先来先服务。 多级反馈队列调度算法：公认的一种较好的进程调度算法，既照顾高优先级队列，也照顾短作业。 常用的Linux命令top 显示当前系统中耗费资源最多的进程 kill 杀死一个进程 kill -9 强制杀死 ps 该命令用于将某个时间点的进程运行情况选取下来并输出，process之意，它的常用参数如下 chmod 修改目录或文件的权限 chown 修改文件的所属用户和组 grep 根据文件的内容查找 比如在日志文件中查找某个ip地址 find 根据文件内容查找 比如查找.txt结尾的文件 locate 让使用者可以很快速的搜寻某个路径, 如locate /etc/sh 搜索etc目录下所有以sh开头的文件 wc 统计文本中行数、字数、字符数 touch 创建文件 df -h 显示已经挂载的分区列表 du 一般用于统计文件和目录所占用的空间大小 ifconfig 查看ip,网卡等信息 Linux 常见目录 / 根目录 /bin 命令保存目录（普通用户就可以读取的命令） /boot 启动目录，启动相关文件 /dev 设备文件保存目录 /etc 配置文件保存目录 /home 普通用户的家目录 /lib 系统库保存目录 /mnt 系统挂载目录 /media 挂载目录 /root 超级用户的家目录 /tmp 临时目录 /sbin 命令保存目录（超级用户才能使用的目录） /proc 直接写入内存的 /sys 将内核的一些信息映射，可供应用程序所用 /usr 系统软件资源目录 /usr/bin/ 系统命令（普通用户） /usr/sbin/ 系统命令（超级用户） /var 系统相关文档内容 /var/log/ 系统日志位置 /var/spool/mail/ 系统默认邮箱位置 /var/lib/ 默认安装的库文件目录]]></content>
  </entry>
  <entry>
    <title><![CDATA[Java核心技术卷一总结]]></title>
    <url>%2F2020%2F06%2F13%2FJava%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E5%8D%B7%E4%B8%80%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[实例域private修饰和public public : 允许程序中的任何方法对其进行修改和读取 private: 只有该类自身的方法能够访问这些实例域 私有方法：除了类自身方法，还可以通过反射访问。反射访问私有方法 static修饰实例域：这个类的实例共享这个实例域，它属于类，不属于对象。 12345public class Math&#123;public static final double PI = 3.1415926;&#125;//程序可以使用Math.PI获得这个常量，如果忽略static，PI就变成了Math类的一个实例域。需要通过Math类的对象访问PI，而且每一个Math对象都有它自己的一份PI拷贝 static修饰方法：不能访问非静态域，只可以访问静态域。不带隐式参数this static修饰类：静态内部类 12345678910111213141516171819//静态内部类实现单例模式public class Singleton &#123; // 声明为 private 避免调用默认构造方法创建对象 private Singleton() &#123; &#125; // 声明为 private 表明静态内部该类只能在该 Singleton 类中被访问 private static class SingletonHolder &#123; private static final Singleton INSTANCE = new Singleton(); &#125; public static Singleton getUniqueInstance() &#123; return SingletonHolder.INSTANCE; &#125;&#125;/*当 Singleton 类加载时，静态内部类 SingletonHolder 没有被加载进内存。只有当调用 getUniqueInstance()方法从而触发 SingletonHolder.INSTANCE 时 SingletonHolder 才会被加载，此时初始化 INSTANCE 实例，并且 JVM 能确保 INSTANCE 只被实例化一次。*/ 构造器 构造器总是伴随着new操作符的执行被调用 java方法总是按值传递，也就是说，方法得到的是所有参数值的一份拷贝。 所以： 1.一个方法不能修改一个基本数据类型的参数 2.一个方法可以改变一个对象参数的状态（改变的是对象的拷贝（引用的拷贝）的状态，两个引用执行一个对象） 3.一个方法不能让对象参数引用一个新的对象（如不能交换两个存储在a和b对象的引用，因为交换的是这两个的拷贝） ​ 动态绑定 当程序运行，并且采用动态绑定调用方法时，虚拟机一定调用与x所引用对象的实际类型最适合的那个类的方法。 编译器在每次调用方法时都要进行搜索，时间开销相当大。因此虚拟机会预先为每个类创建一个方发表（method table），其中列出了所有方法的签名和实际调用的方法。 Java用于控制可见性的4个访问修饰符： 1）仅对本类可见—-private 2）对所有类可见—-public 3）对本包和所有子类可见—-protected 4）对本包可见—-默认，不需要修饰符 Object：所有类的父类 在Java中，只有基本类型不是对象，所有的数组类型，和其它的都继承自Object类 反射Class类: Java运行时系统始终为所有的对象维护一个被称为运行时的类型标识，这个信息跟踪着每个对象所属的类。一个类中这些成员，成员方法、构造方法、在加入类中都有一个类来描述。 熟悉一下加载的时候：Class对象的由来是将class文件读入内存，并为之创建一个Class对象。 Java虚拟机为每个类型管理一个Class对象，获取Class类对象的三种方法 1） Empolyee e; Class c1 = e.getClass(); 2） Class c1 = Class.forName(“java.util.Random”); 3） Class c1 = Random.class; 123456Random e = new Random();Class c1 = e.getClass();Class c2 = Class.forName("java.util.Random");Class c3 = Random.class;System.out.println(c1==c2);//true System.out.println(c2==c3);//true LoadClass和forName的区别 class.forName()除了将类的.class文件加载到JVM中之外，还会对类进行解释，执行类中的static块。而classLoader只干一件事情，就是将.class文件加载到JVM中，不会执行static中的内容,只有在newInstance才会去执行static块。 创建一个与e具有相同类类型的实例 1）调用c2.newInstance()方法 此方法调用默认的构造器（无参构造器）初始化新创建的对象，如果这个类没有无参构造器，会抛异常。 2）Constructor类中的newInstance方法可以向类的构造器提供参数。 在java.lang.reflect包有三个类Field,Method和Constructor分别用于描述类的域，方法和构造器。 12345678910Employee e = new Employee("harry",21,'M');Class c1 = e.getClass();Field f = c1.getDeclaredField("name");//获取feiledObject v = f.get(harry);// the v: "harry"Method m = c1.getDeclaredMethod("getName");//获取方法String name = m.invoke(e);//harry//invoke方法，如果调用的是静态方法，第一个隐式参数可以被忽略，即可以将它设置为null//如 m = Math.class.getMethod("sqrt", double.class);//double y = m.invoke(null,x); 接口 接口中的方法都自动的设置为public 接口中不能包含实例域，却可以包含常量，接口中的域将自动设为public static final clone 浅拷贝：没有克隆对象中引用的其它对象 深拷贝：克隆对象中引用的其它对象 动态代理 见Spring总结) 常见面试题抽象类和接口的区别 接口和抽象类都是继承树的上层，他们的共同点如下：1) 都是上层的抽象层。2) 都不能被实例化3) 都能包含抽象的方法，这些抽象的方法用于描述类具备的功能，但是不比提供具体的实现。他们的区别如下：1) 在抽象类中可以写非抽象的方法，从而避免在子类中重复书写他们，这样可以提高代码的复用性，这是抽象类的优势；接口中只能有抽象的方法（default关键字修饰除外）。2) 一个类只能继承一个直接父类，这个父类可以是具体的类也可是抽象类；但是一个类可以实现多个接口。 ps:如果要继承多个类的多个方法，可以采用内部类。或直接就用接口。 12345class A extends B&#123; class InnerA extends C&#123; //在这里扩充类C &#125;&#125; JVM JDK 和 JRE 最详细通俗的解答 JVM Java 虚拟机（JVM）是运行 Java 字节码的虚拟机。JVM 有针对不同系统的特定实现（Windows，Linux，macOS），目的是使用相同的字节码，它们都会给出相同的结果。 什么是字节码?采用字节码的好处是什么?在 Java 中，JVM 可以理解的代码就叫做字节码（即扩展名为 .class 的文件），它不面向任何特定的处理器，只面向虚拟机。Java 语言通过字节码的方式，在一定程度上解决了传统解释型语言执行效率低的问题，同时又保留了解释型语言可移植的特点。所以 Java 程序运行时比较高效，而且，由于字节码并不针对一种特定的机器，因此，Java 程序无须重新编译便可在多种不同操作系统的计算机上运行。 Java 程序从源代码到运行一般有下面 3 步： JDK 和 JRE JDK 是 Java Development Kit，它是功能齐全的 Java SDK。它拥有 JRE 所拥有的一切，还有编译器（javac）和工具（如 javadoc 和 jdb）。它能够创建和编译程序。 JRE 是 Java 运行时环境。它是运行已编译 Java 程序所需的所有内容的集合，包括 Java 虚拟机（JVM），Java 类库，java 命令和其他的一些基础构件。但是，它不能用于创建新程序。 如果你只是为了运行一下 Java 程序的话，那么你只需要安装 JRE 就可以了。如果你需要进行一些 Java 编程方面的工作，那么你就需要安装 JDK 了。但是，这不是绝对的。有时，即使您不打算在计算机上进行任何 Java 开发，仍然需要安装 JDK。例如，如果要使用 JSP 部署 Web 应用程序，那么从技术上讲，您只是在应用程序服务器中运行 Java 程序。那你为什么需要 JDK 呢？因为应用程序服务器会将 JSP 转换为 Java servlet，并且需要使用 JDK 来编译 servlet。 Java 多态用最简单的一句话就是：父类型的引用指向子类型的对象。用一句比较通俗的话：同一操作作用于不同的对象，可以产生不同的效果。这就是多态。 多态是同一个行为具有多个不同表现形式或形态的能力。 多态的优点 消除类型之间的耦合关系 可替换性 可扩充性 接口性 灵活性 简化性 多态存在的三个必要条件 继承 子类对父类方法的重写 父类引用指向子类对象 重载（Overload）和（Override）的区别Overload: 同一个类或子类中，具有相同的方法名，但是方法的参数不同（类型，个数，顺序）。返回值可以相同也可以不同。 Override: 子类重写父类的方法，方法名相同，参数相同，返回类型相同。具体实现不同。 请说明一下final, finally, finalize的区别。final 用于声明属性，方法和类，分别表示属性不可变，方法不可重写，类不可继承。finally是异常处理语句结构的一部分，表示总是执行。finalize是Object类的一个方法，在垃圾收集器执行的时候会调用被回收对象的此方法，可以覆盖此方法提供垃圾收集时的其他资源回收，例如关闭文件等。 String为什么是不可变对象String底层实现是final修饰的char数组，不可变。同时String类也被final修饰，不可被继承。 StringBuilder 底层是一个可变的char数组。初始长度为16，存在扩容。 StringBuffer 同StringBuilder，经过Synchronized修饰 Default关键字1.在switch语句的时候使用default 2.在定义接口的时候使用default来修饰具体的方法 Java八种基本数据类型，各占多少字节byte 1字节;short 2字节；int 4字节；long 8字节；char 2字节，可以存储一个汉字。float 4字节；double 8字节；boolean false/true(理论上占用1bit,1/8字节，bai实际处理按1byte处理) 基本类型和引用类型的区别基本数据类型在被创建时，在栈上给其划分一块内存，将数值直接存储在栈上。 引用数据类型在被创建时，首先要在栈上给其引用（句柄）分配一块内存，而对象的具体信息都存储在堆内存上，然后由栈上面的引用指向堆中对象的地址。 int和Integer装箱和拆箱装箱时调用valueOf方法将原始类型值转换成对象 拆箱时调用intValue()方法 1234567891011 Integer a=300; int b=300; System.out.println(a==b);//true,自动装，拆箱 Integer a=300; Integer b=300; Integer c=100; Integer d=100; System.out.println(a==b);//false,比较的是引用 System.out.println(c==d);//true,-128和127之间,有一个cache整型数组，用来放在缓存中。//这样也就是说任意一个相同数值的Integer的数，如果在-128和127之间，那么它们之间的内存地址是相同的 序列化的优缺点（implements Serializbale）序列化机制允许将实现序列化的Java对象转换成字节序列，这些字节序列可以保存在磁盘上，或通过网络传输，以备以后重新恢复成原来的对象。序列化机制使得对象可以脱离程序的运行而独立存在。 缺点： 1.Java序列化技术是Java语言内部的私有协议，其他语言无法进行反序列化。 2.序列化的性能较低(耗时) 3.码流太大（耗空间） Integer和int的初始化值引用类型的初始化值为null int类型的为0 123456789public class Lee2 &#123; private static Integer age1; private static int age2; public static void main(String[] args)&#123; System.out.println(age1);//null System.out.println(age2);//0 &#125;&#125; Collections.sort和Arrays.sort排序原理Collections.sort方法底层就是调用的Arrays.sort方法，而Arrays.sort使用了三种排序方法，插入排序，快速排序和优化的归并排序。 快速排序主要是对那些基本类型数据（int,short,long等）排序， 而归并排序用于对Object类型进行排序。 总结： 首先先判断需要排序的数据量是否大于60。 小于60：使用插入排序，插入排序是稳定的 大于60的数据量会根据数据类型选择排序方式： 基本类型：使用快速排序。因为基本类型。1、2都是指向同一个常量池不需要考虑稳定性。 Object类型：使用归并排序。因为归并排序具有稳定性。 注意：不管是快速排序还是归并排序。在二分的时候小于60的数据量依旧会使用插入排序 Java创建对象的几种方式 new关键字 反射，newInstance clone()方法 反序列化 常见的编译时异常和运行时异常 运行时异常 NullPointerException StringIndexOutOfBoundsException String a = “abc” System.out.println(a.substring(1)); //正常，显示“bc” System.out.println(a.substring(4)); //错误，java.lang.StringIndexOutOfBoundsException: String index out of range: -1 因为一共只有3个字母。） ArithmeticException ：当出现异常的运算条件时，抛出此异常。如除0异常 ArrayIndexOutOfBoundsException int[] nums = new int[3]; System.out.println(nums[4]); 编译时异常 ClassNotFoundException ：找不到具有指定名称的类的定义。 FileNotFoundException ：当试图打开指定路径名表示的文件失败时，抛出此异常。 SQLException 比如SQL语句写错，访问的表不存在，连接数据库失败等等 java JDBC编程流程步骤第1步：注冊驱动 (仅仅做一次) Class.forName(“com.mysql.jdbc.Driver”); 第2步：建立连接(Connection) Connection conn =DriverManager.getConnection(url, user, password); 第3步：创建运行SQL的语句(Statement) Statement st = connection.createStatement(); Statement接口类还派生出两个接口类PreparedStatement和CallableStatement。PreparedStatement能够对SQL语句进行预编译，这样防止了 SQL注入，提高了安全性。PreparedStatement ps=connection.prepareStatement( &quot;update user set id=? where username=?”) 第4步：运行语句 ResultSet rs =st.executeQuery(sql); 第5步：处理运行结果(ResultSet) while(rs.next()){System.out.println(rs.getString(&quot;name&quot;))} 第6步：释放资源 rs.close(); conn.close() Java 关于强引用，软引用，弱引用的区别与用法 强引用 我们使用的大部分引用实际上都是强引用，这是使用最普遍的引用。如果一个对象具有强引用，那就类似于必不可少的生活用品，垃圾回收器绝不会回收它。当内存空间不足，Java虚拟机宁愿抛出OutOfMemoryError错误，使程序异常终止，也不会靠随意回收具有强引用的对象来解决内存不足问题。 软引用 如果内存空间足够，垃圾回收器就不会回收它，如果内存空间不足了，就会回收这些对象的内存。 应用：浏览器的后退按钮 （1）如果一个网页在浏览结束时就进行内容的回收，则按后退查看前面浏览过的页面时，需要重新构建 （2）如果将浏览过的网页存储到内存中会造成内存的大量浪费，甚至会造成内存溢出 这时候就可以使用软引用 弱引用 弱引用与软引用的区别在于：只具有弱引用的对象拥有更短暂的生命周期。在垃圾回收器线程扫描它 所管辖的内存区域的过程中，一旦发现了只具有弱引用的对象，不管当前内存空间足够与否，都会回收它的内存 泛型泛型本质是参数化类型，解决不确定对象具体类型的问题。 泛型的好处：① 类型安全，不存在 ClassCastException。② 提升可读性，编码阶段就显式知道泛型集合、泛型方法等处理的数据类型。 泛型用于编译阶段，编译后的字节码文件不包含泛型类型信息，因为虚拟机没有泛型类型对象，所有对象都属于普通类。例如定义 List&lt;Object&gt; 或 List&lt;String&gt;，在编译后都会变成 List 。 IO流Java 中的 BIO、NIO和 AIO 理解为是 Java 语言对操作系统的各种 IO 模型的封装。程序员在使用这些 API 的时候，不需要关心操作系统层面的知识，也不需要根据不同操作系统编写不同的代码。只需要使用Java的API就可以了。 同步与异步 同步： 同步就是发起一个调用后，被调用者未处理完请求之前，调用不返回。 异步： 异步就是发起一个调用后，立刻得到被调用者的回应表示已接收到请求，但是被调用者并没有返回结果，此时我们可以处理其他的请求，被调用者通常依靠事件，回调等机制来通知调用者其返回结果。 同步和异步的区别最大在于异步的话调用者不需要等待处理结果，被调用者会通过回调等机制来通知调用者其返回结果。 阻塞和非阻塞 阻塞： 阻塞就是发起一个请求，调用者一直等待请求结果返回，也就是当前线程会被挂起，无法从事其他任务，只有当条件就绪才能继续。 非阻塞： 非阻塞就是发起一个请求，调用者不用一直等着结果返回，可以先去干其他事情。 那么同步阻塞、同步非阻塞和异步非阻塞又代表什么意思呢？ 举个生活中简单的例子，你妈妈让你烧水，小时候你比较笨啊，在哪里傻等着水开（同步阻塞）。等你稍微再长大一点，你知道每次烧水的空隙可以去干点其他事，然后只需要时不时来看看水开了没有（同步非阻塞）。后来，你们家用上了水开了会发出声音的壶，这样你就只需要听到响声后就知道水开了，在这期间你可以随便干自己的事情，你需要去倒水了（异步非阻塞）。 BIO(Blocking I/O) 同步阻塞I/O模式，数据的读取写入必须阻塞在一个线程内等待其完成。 采用 BIO 通信模型 的服务端，通常由一个独立的 Acceptor 线程负责监听客户端的连接。我们一般通过在 while(true) 循环中服务端会调用 accept() 方法等待接收客户端的连接的方式监听请求，请求一旦接收到一个连接请求，就可以建立通信套接字在这个通信套接字上进行读写操作，此时不能再接收其他客户端连接请求，只能等待同当前连接的客户端的操作执行完成， 不过可以通过多线程来支持多个客户端的连接，如上图所示。 如果要让 BIO 通信模型 能够同时处理多个客户端请求，就必须使用多线程（主要原因是 socket.accept()、 socket.read()、 socket.write() 涉及的三个主要函数都是同步阻塞的），也就是说它在接收到客户端连接请求之后为每个客户端创建一个新的线程进行链路处理，处理完成之后，通过输出流返回应答给客户端，线程销毁。这就是典型的 一请求一应答通信模型 。我们可以设想一下如果这个连接不做任何事情的话就会造成不必要的线程开销，不过可以通过 线程池机制 改善，线程池还可以让线程的创建和回收成本相对较低。使用FixedThreadPool 可以有效的控制了线程的最大数量，保证了系统有限的资源的控制，实现了N(客户端请求数量):M(处理客户端请求的线程数量)的伪异步I/O模型（N 可以远远大于 M）。如下图。 采用线程池和任务队列可以实现一种叫做伪异步的 I/O 通信框架，它的模型图如上图所示。当有新的客户端接入时，将客户端的 Socket 封装成一个Task（该任务实现java.lang.Runnable接口）投递到后端的线程池中进行处理，JDK 的线程池维护一个消息队列和 N 个活跃线程，对消息队列中的任务进行处理。由于线程池可以设置消息队列的大小和最大线程数，因此，它的资源占用是可控的，无论多少个客户端并发访问，都不会导致资源的耗尽和宕机。 伪异步I/O通信框架采用了线程池实现，因此避免了为每个请求都创建一个独立线程造成的线程资源耗尽问题。不过因为它的底层任然是同步阻塞的BIO模型，因此无法从根本上解决问题。 NIO 1) NIO的特性/NIO与IO的区别 1.IO流是阻塞的，NIO流是不阻塞的。 Java NIO使我们可以进行非阻塞IO操作。比如说，单线程中从通道读取数据到buffer，同时可以继续做别的事情，当数据读取到buffer中后，线程再继续处理数据。写数据也是一样的。另外，非阻塞写也是如此。一个线程请求写入一些数据到某通道，但不需要等待它完全写入，这个线程同时可以去做别的事情。 Java IO的各种流是阻塞的。这意味着，当一个线程调用 read() 或 write() 时，该线程被阻塞，直到有一些数据被读取，或数据完全写入。该线程在此期间不能再干任何事情了 2.IO 面向流(Stream oriented)，而 NIO 面向缓冲区(Buffer oriented)。 Buffer是一个对象，它包含一些要写入或者要读出的数据。在NIO类库中加入Buffer对象，体现了新库与原I/O的一个重要区别。在面向流的I/O中·可以将数据直接写入或者将数据直接读到 Stream 对象中。虽然 Stream 中也有 Buffer 开头的扩展类，但只是流的包装类，还是从流读到缓冲区，而 NIO 却是直接读到 Buffer 中进行操作。 在NIO厍中，所有数据都是用缓冲区处理的。在读取数据时，它是直接读到缓冲区中的; 在写入数据时，写入到缓冲区中。任何时候访问NIO中的数据，都是通过缓冲区进行操作。 最常用的缓冲区是 ByteBuffer,一个 ByteBuffer 提供了一组功能用于操作 byte 数组。除了ByteBuffer,还有其他的一些缓冲区，事实上，每一种Java基本类型（除了Boolean类型）都对应有一种缓冲区。 3.NIO 通过Channel（通道） 进行读写 通道是双向的，可读也可写，而流的读写是单向的。无论读写，通道只能和Buffer交互。因为 Buffer，通道可以异步地读写。 4.Selectors(选择器) NIO有选择器，而IO没有。 多路复用器，轮询检查多个 Channel 的状态，判断 Channel 是否处于可读或可写状态。使用前需要将 Channel 注册到 Selector，注册后会得到一个 SelectionKey，通过 SelectionKey 获取 Channel 和 Selector 相关信息。 选择器用于使用单个线程处理多个通道。因此，它需要较少的线程来处理这些通道。线程之间的切换对于操作系统来说是昂贵的。 因此，为了提高系统效率选择器是有用的。 NIO 读数据和写数据方式 通常来说NIO中的所有IO都是从 Channel（通道） 开始的。 从通道进行数据读取 ：创建一个缓冲区，然后请求通道读取数据。 从通道进行数据写入 ：创建一个缓冲区，填充数据，并要求通道写入数据。 数据读取和写入操作图示： AIO AIO 也就是 NIO 2。在 Java 7 中引入了 NIO 的改进版 NIO 2,它是异步非阻塞的IO模型。异步 IO 是基于事件和回调机制实现的，也就是应用操作之后会直接返回，不会堵塞在那里，当后台处理完成，操作系统会通知相应的线程进行后续的操作。]]></content>
  </entry>
  <entry>
    <title><![CDATA[mybatis面试题]]></title>
    <url>%2F2020%2F05%2F23%2Fmybatis%E9%9D%A2%E8%AF%95%E9%A2%98%2F</url>
    <content type="text"><![CDATA[MyBatis介绍 持久层框架，内部封装了jdbc，使开发者只需要关注sql语句本身，而不需要花费精力去处理加载驱动、创建连接、创建statement等繁杂的过程。 MyBatis 可以使用 XML 或注解来配置和映射原生信息，将 POJO映射成数据库中的记录，避免了几乎所有的 JDBC 代码和手动设置参数以及获取结果集。 通过XML或者注解的方式将要执行的各种statement配置起来，并通过java对象和statement中sql的动态参数进行映射生成最终的sql语句，最后由mybatis框架执行sql并将结果映射为java对象并返回。 MyBatis和Hibernate的区别（1）Mybatis和hibernate不同，它不完全是一个ORM框架，因为MyBatis需要程序员自己编写Sql语句。 （2）Mybatis直接编写原生态sql，可以严格控制sql执行性能，灵活度高，非常适合对关系数据模型要求不高的软件开发，因为这类软件需求变化频繁，一但需求变化要求迅速输出成果。但是灵活的前提是mybatis无法做到数据库无关性，如果需要实现支持多种数据库的软件，则需要自定义多套sql映射文件，工作量大。 （3）Hibernate对象/关系映射能力强，数据库无关性好，对于关系模型要求高的软件，如果用hibernate开发可以节省很多代码，提高效率。 #{}和${}的区别是什么？#{}是预编译处理，${}是字符串替换。 Mybatis在处理#{}时，会将sql中的#{}替换为?号，调用PreparedStatement的set方法来赋值； Mybatis在处理${}时，就是把${}替换成变量的值。 使用#{}可以有效的防止SQL注入，提高系统安全性。 接口式编程原生： Dao ==========&gt; DaoImpl mybatis: Mapper ========&gt; xxMapper.xml Mapper是一个接口，并没有实现类，而是有一个与之对应得配置文件。这个配置文件就相当于Mapper得实现。 具体过程：mapper接口没有实现类，但是mybatis会为这个接口生成一个代理对象。(将接口和xml进行绑定) EmployeeMapper empMapper = sqlSession.getMapper(EmployeeMapper.class); Mybatis第一天讲义 Mybatis第二天讲义 Mybatis第三天讲义 Mybatis第四天讲义 mybatis参数设置单个参数： mybatis不会做特殊处理 #{参数名}：取出参数 多个参数：mybatis会做特殊处理，多个参数会被封装成一个map key: param1…paramN，或者参数的索引也可以 value: 传入的参数值 #{key}就是从map中获取指定的key值 这样写去参数容易眼花缭乱，可以使用 命名参数：明确指定封装参数时map的key：@Param(“id”) 多个参数会被封装成一个map, key：使用@Param注解指定的值 value: 参数值 #{指定的key}取出对应的参数值 POJO 如果多个参数正好是业务逻辑的数据模型，我们可以直接传入pojo #{属性名}： 取出传入的pojo的属性值 Map: 如果多个参数不是业务模型中的数据，没有对应的pojo，为了方便，我们也可以传入map #{key}: 取出map中对应的值 resultType和resultMap resultType:当使用resultType做SQL语句返回结果类型处理时，对于SQL语句查询出的字段在相应的pojo中必须有和它相同的字段对应. resultMap:当使用resultMap做SQL语句返回结果类型处理时，通常需要在mapper.xml中定义resultMap进行pojo和相应表字段的对应。 Mybatis是如何将sql执行结果封装为目标对象并返回的？都有哪些映射形式？ 第一种是使用标签，逐一定义数据库列名和对象属性名之间的映射关系。 第二种是使用sql列的别名功能，将列的别名书写为对象属性名。 有了列名与属性名的映射关系后，Mybatis通过反射创建对象，同时使用反射给对象的属性逐一赋值并返回，那些找不到映射关系的属性，是无法完成赋值的。 动态SQLif:判断 choose(when,otherwise):分支，选择 foreach遍历 两个内置参数：不只是方法传递过来的参数可以被用来判断，取值。mybatis默认还有两个内置参数 _parameter: 代表整个参数 ​ 单个参数：_parameter就是这个参数 ​ 多个参数：_parameter就是代表多个参数封装的map _databaseId: 全局配置了databaseIdProvider标签， _databaseId就是代表当前数据库的别名mysql sql标签 抽取可重用的sql片段，方便后面引用（使用include标签引用）。 mybatis缓存机制 一级、二级缓存1）一级缓存: 基于 PerpetualCache 的 HashMap 本地缓存，其存储作用域为 Session，当 Session flush 或 close 之后，该 Session 中的所有 Cache 就将清空。2）二级缓存与一级缓存其机制相同，默认也是采用 PerpetualCache，HashMap 存储，不同在于其存储作用域为 Mapper(Namespace)，并且可自定义存储源，如 Ehcache。要开启二级缓存，你需要在你的 SQL 映射文件中添加一行：3）对于缓存数据更新机制，当某一个作用域(一级缓存 Session/二级缓存Namespaces)的进行了C/U/D 操作后，默认该作用域下所有 select 中的缓存将被 clear。 mybatis系统中默认定义了两级缓存：一级缓存，二级缓存。 1.默认情况下，只有一级缓存（SqlSession级别的缓存，也成为本地缓存）开启，只要sqlSession没有flush或close，它就存在 。 2.二级缓存（全局缓存）需要手动开启和配置，他是基于namespace级别的缓存（在XXmapper.xml配置） 3.为了提高拓展性，mybatis定义了缓存接口Cache。我们可以通过实现Cache接口来自定义二级缓存。 一级缓存失效的四种情况 1.sqlSession不同 2.sqlSession相同，查询条件不同 3.sqlSession相同，两次查询之间执行了增删改操作（可能对当前数据有影响） 4.sqlSession相同，手动清空了一级缓存 二级缓存 工作机制 1.一个会话，查询一条数据，这个数据就会被放在当前会话的一级缓存中 2.如果会话关闭，一级缓存中的数据会被保存在二级缓存中 二级缓存注意事项：所缓存的类一定要序列化，这种就可以使用序列化的方式来保存对象。 查找顺序：二级缓存，一级缓存，数据库]]></content>
      <tags>
        <tag>面试题</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机网络常见面试题]]></title>
    <url>%2F2020%2F05%2F20%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98%2F</url>
    <content type="text"><![CDATA[OSI七层模型​ 应用层，很简单，就是应用程序。这一层负责确定通信对象，并确保由足够的资源用于通信，这些当然都是想要通信的应用程序干的事情。 表示层，负责数据的编码、转化，确保应用层的正常工作。这一层，是将我们看到的界面与二进制间互相转化的地方，就是我们的语言与机器语言间的转化。数据的压缩、解压，加密、解密都发生在这一层。这一层根据不同的应用目的将数据处理为不同的格式，表现出来就是我们看到的各种各样的文件扩展名。 会话层，负责建立、维护、控制会话，区分不同的会话，以及提供单工(Simplex)、半双工(Half duplex)、全双工(Full duplex)三种通信模式的服务。我们平时所知的NFS，RPC,X Windows等都工作在这一层。 传输层，负责分割、组合数据，实现端到端的逻辑连接。数据在上三层是整体的，到了这一层开始被分割，这一层分割后的数据被称为段(Segment)。三次握手(Three-way handshake)，面向连接(Connection-Oriented)或非面向连接(Connectionless-Oriented)的服务，流控(Flow control)等都发生在这一层。 网络层，负责管理网络地址，定位设备，决定路由。我们所熟知的IP地址和路由器就是工作在这一层。上层的数据段在这一层被分割，封装后叫做包(Packet)，包有两种，一种叫做用户数据包(Data packets)，是上层传下来的用户数据；另一种叫路由更新包(Route update packets)，是直接由路由器发出来的，用来和其他路由器进行路由信息的交换。 数据链路层，负责准备物理传输，CRC校验，错误通知，网络拓扑，流控等。我们所熟知的MAC地址和交换机都工作在这一层。上层传下来的包在这一层被分割封装后叫做帧(Frame)。 物理层，就是实实在在的物理链路，负责将数据以比特流的方式发送、接收。 为什么要分层 点击url发生了什么 总体来说分为以下几个过程: DNS解析 TCP连接 发送HTTP请求 服务器处理请求并返回HTTP报文 浏览器解析渲染页面 连接结束 HTTPS和HTTP的区别HTTP报文是包裹在TCP报文中发送的，服务器端收到TCP报文时会解包提取出HTTP报文。但是这个过程中存在一定的风险，HTTP报文是明文，如果中间被截取的话会存在一些信息泄露的风险。那么在进入TCP报文之前对HTTP做一次加密就可以解决这个问题了。HTTPS协议的本质就是HTTP + SSL(or TLS)。在HTTP报文进入TCP报文之前，先使用SSL对HTTP报文进行加密。从网络的层级结构看它位于HTTP协议与TCP协议之间。 HTTPS过程 HTTPS在传输数据之前需要客户端与服务器进行一个握手(TLS/SSL握手)，在握手过程中将确立双方加密传输数据的密码信息。TLS/SSL使用了非对称加密，对称加密以及hash等。具体过程请参考经典的阮一峰先生的博客TLS/SSL握手过程。HTTPS相比于HTTP，虽然提供了安全保证，但是势必会带来一些时间上的损耗，如握手和加密等过程，是否使用HTTPS需要根据具体情况在安全和性能方面做出权衡。 端口 ：HTTP的URL由“http://”起始且默认使用端口80，而HTTPS的URL由“https://”起始且默认使用端口443。 安全性和资源消耗： HTTP协议运行在TCP之上，所有传输的内容都是明文，客户端和服务器端都无法验证对方的身份。HTTPS是运行在SSL/TLS之上的HTTP协议，SSL/TLS 运行在TCP之上。所有传输的内容都经过加密，加密采用对称加密，但对称加密的密钥用服务器方的证书进行了非对称加密。所以说，HTTP 安全性没有 HTTPS高，但是 HTTPS 比HTTP耗费更多服务器资源。 对称加密：密钥只有一个，加密解密为同一个密码，且加解密速度快，典型的对称加密算法有DES、AES等； 非对称加密：密钥成对出现（且根据公钥无法推知私钥，根据私钥也无法推知公钥），加密解密使用不同密钥（公钥加密需要私钥解密，私钥加密需要公钥解密），相对对称加密速度较慢，典型的非对称加密算法有RSA、DSA等。 数字签名而数字签名，它的作用跟手写签名其实是一样的，用来证明某个消息或者文件是本人发出/认同的。有不可伪造和不可抵赖两个特性。 hash算法：是单向加密。就是只能从明文得到密文，却无法从密文得到明文。这种算法有一个好处，就是明文哪怕只有一位不一样，加密后得到的密文也不一样。所以常用来进行比较明文是否被篡改过。 .png?raw=true) HTTPS数字证书 三次握手 简易示意图： 客户端–发送带有 SYN 标志的数据包–一次握手–服务端 服务端–发送带有 SYN/ACK 标志的数据包–二次握手–客户端 客户端–发送带有带有 ACK 标志的数据包–三次握手–服务端 为什么要三次握手三次握手的目的是建立可靠的通信信道，说到通讯，简单来说就是数据的发送与接收，而三次握手最主要的目的就是双方确认自己与对方的发送与接收是正常的。 第一次握手：Client 什么都不能确认；Server 确认了对方发送正常，自己接收正常 第二次握手：Client 确认了：自己发送、接收正常，对方发送、接收正常；Server 确认了：对方发送正常，自己接收正常 第三次握手：Client 确认了：自己发送、接收正常，对方发送、接收正常；Server 确认了：自己发送、接收正常，对方发送、接收正常 所以三次握手就能确认双发收发功能都正常，缺一不可。 假如没有三次握手，可能会出现什么情况反例：A发出连接请求，但因为丢失了，故而不能收到B的确认。于是A重新发出请求。 ​ 但是，某种情况下，A的第一个连接请求在某个节点滞留了，延误到达。在A已经发送第二个连接请求，并且得到B的回应，建立了连接以后，这个报文段竟然到达了（本来这是一个早已失效的报文段），于是B就认为，A又发送了一个新的请求，于是发送确认报文段，同意建立连接，假若没有三次的握手，那么这个连接就建立起来了（有一个请求和一个回应），此时，A收到B的确认，但A知道自己并没有发送建立连接的请求，因为不会理睬B的这个确认，于是呢，A也不会发送任何数据，而B呢却以为新的连接建立了起来，一直等待A发送数据给自己，此时B的资源就被白白浪费了。但是采用三次握手的话，A就不发送确认，那么B由于收不到确认，也就知道并没有要求建立连接。 第2次握手传回了ACK，为什么还要传回SYN？接收端传回发送端所发送的ACK是为了告诉客户端，我接收到的信息确实就是你所发送的信号了，这表明从客户端到服务端的通信是正常的。而回传SYN则是为了建立并确认从服务端到客户端的通信。” DoS, DDoS, SYN泛洪攻击A（攻击者）发送TCP SYN，SYN是TCP三次握手中的第一个数据包，而当这个服务器返回ACK以后，A不再进行确认，那这个连接就处在了一个挂起的状态，也就是半连接的意思，那么服务器收不到再确认的一个消息，还会重复发送ACK给A。这样一来就会更加浪费服务器的资源。A就对服务器发送非法大量的这种TCP连接，由于每一个都没法完成握手的机制，所以它就会消耗服务器的内存最后可能导致服务器死机，就无法正常工作了。更进一步说，如果这些半连接的握手请求是恶意程序发出，并且持续不断，那么就会导致服务端较长时间内丧失服务功能——这样就形成了DoS攻击。这种攻击方式就称为SYN泛洪攻击。 如何防范： 最常用的一个手段就是优化主机系统设置。比如降低SYN timeout时间，使得主机尽快释放半连接的占用或者采用SYN cookie设置，如果短时间内收到了某个IP的重复SYN请求，我们就认为受到了攻击。我们合理的采用防火墙设置等外部网络也可以进行拦截。 四次挥手 断开一个 TCP 连接则需要“四次挥手”： 客户端-发送一个 FIN，用来关闭客户端到服务器的数据传送 服务器-收到这个 FIN，它发回一 个 ACK，确认序号为收到的序号加1 。和 SYN 一样，一个 FIN 将占用一个序号 服务器-关闭与客户端的连接，发送一个FIN给客户端 客户端-发回 ACK 报文确认，并将确认序号设置为收到序号加1 CLOSE_WAIT: 被动关闭方收到FIN, 发送ack后进入CLOSE_WAIT TIME_WAIT: TIME_WAIT 是主动关闭链接时形成的，等待2MSL时间，约4分钟。主要是防止最后一个ACK丢失。 由于TIME_WAIT 的时间会非常长，因此server端应尽量减少主动关闭连接 等待2MSL的原因：为了保证客户端最后一次挥手的报文能够到达服务器，若第4次挥手的报文段丢失了，服务器就会超时重传第3次挥手的报文段，所以客户端此时不是直接进入CLOSED，而是保持TIME_WAIT（等待2MSL就是TIME_WAIT）。当客户端再次受到服务器因为超时重传而发送的第3次挥手的请求时，客户端就会重新给服务器发送第4次挥手的报文（保证服务器能够受到客户端的回应报文） 任何一方都可以在数据传送结束后发出连接释放的通知，待对方确认后进入半关闭状态。当另一方也没有数据再发送的时候，则发出连接释放通知，对方确认后就完全关闭了TCP连接。 举个例子：A 和 B 打电话，通话即将结束后，A 说“我没啥要说的了”，B回答“我知道了”，但是 B 可能还会有要说的话，A 不能要求 B 跟着自己的节奏结束通话，于是 B 可能又巴拉巴拉说了一通，最后 B 说“我说完了”，A 回答“知道了”，这样通话才算结束。 TCP第四次挥手为什么要等待2MSL 1、为了保证客户端发送的最后一个ACK报文段能够到达服务器。因为这个ACK有可能丢失，从而导致处在LAST-ACK状态的服务器收不到对FIN-ACK的确认报文。服务器会超时重传这个FIN-ACK，接着客户端再重传一次确认，重新启动时间等待计时器。最后客户端和服务器都能正常的关闭。假设客户端不等待2MSL，而是在发送完ACK之后直接释放关闭，一但这个ACK丢失的话，服务器就无法正常的进入关闭连接状态。 2、他还可以防止已失效的报文段。客户端在发送最后一个ACK之后，再经过经过2MSL，就可以使本链接持续时间内所产生的所有报文段都从网络中消失。从保证在关闭连接后不会有还在网络中滞留的报文段去骚扰服务器。 TCP和UDP协议的区别 UDP 在传送数据之前不需要先建立连接，远地主机在收到 UDP 报文后，不需要给出任何确认。虽然 UDP 不提供可靠交付，但在某些情况下 UDP 确是一种最有效的工作方式（一般用于即时通信），比如： QQ 语音、 QQ 视频 、直播等等 TCP 提供面向连接的服务。在传送数据之前必须先建立连接，数据传送结束后要释放连接。 TCP 不提供广播或多播服务。由于 TCP 要提供可靠的，面向连接的传输服务（TCP的可靠体现在TCP在传递数据之前，会有三次握手来建立连接，而且在数据传递时，有确认、窗口、重传、拥塞控制机制，在数据传完后，还会断开连接用来节约系统资源），这一难以避免增加了许多开销，如确认，流量控制，计时器以及连接管理等。这不仅使协议数据单元的首部增大很多，还要占用许多处理机资源。TCP 一般用于文件传输、发送和接收邮件、远程登录等场景。 为什么说UDP是面向报文的，而TCP是面向字节流的？发送方的UDP 对应用程序交下来的报文，在添加首部后就向下交付IP 层。UDP对应用层交下来的报文，既不合并，也不拆分，而是保留这些报文的边界。这就是说，应用层交给UDP 多长的报文， UDP 就照样发送，即一次发送一个报文。 在接收方的UDP, 对IP 层交上来的UDP 用户数据报，在去除首部后就原封不动地交付上层的应用进程。也就是说， UDP 一次交付一个完整的报文。因此，应用程序必须选择合适大小的报文。若报文太长， UDP 把它交给IP 层后， IP 层在传送时可能要进行分片，这会降低IP层的效率。反之，若报文太短， UDP 把它交给IP 层后，会使IP 数据报的首部的相对长度太大，这也降低了IP 层的效率。 TCP通过字节流传输，即TCP将应用程序看成是一连串的无结构的字节流。每个TCP套接口有一个发送缓冲区，如果字节流太长时，TCP会将其拆分进行发送,当字节流太短时，TCP会等待缓冲区中的字节流达到一定程度时再构成报文发送出去 ARQ协议自动重传请求（Automatic Repeat-reQuest，ARQ）是OSI模型中数据链路层和传输层的错误纠正协议之一。它通过使用确认和超时这两个机制，在不可靠服务的基础上实现可靠的信息传输。如果发送方在发送后一段时间之内没有收到确认帧，它通常会重新发送。ARQ包括停止等待ARQ协议和连续ARQ协议。 停止等待ARQ协议 停止等待协议是为了实现可靠传输的，它的基本原理就是每发完一个分组就停止发送，等待对方确认（回复ACK）。如果过了一段时间（超时时间后），还是没有收到 ACK 确认，说明没有发送成功，需要重新发送，直到收到确认后再发下一个分组； 在停止等待协议中，若接收方收到重复分组，就丢弃该分组，但同时还要发送确认； 优点： 简单 缺点： 信道利用率低，等待时间长 连续ARQ协议连续 ARQ 协议可提高信道利用率。发送方维持一个发送窗口，凡位于发送窗口内的分组可以连续发送出去，而不需要等待对方确认。接收方一般采用累计确认，对按序到达的最后一个分组发送确认，表明到这个分组为止的所有分组都已经正确收到了。 优点： 信道利用率高，容易实现，即使确认丢失，也不必重传。 缺点： 不能向发送方反映出接收方已经正确收到的所有分组的信息。 比如：发送方发送了 5条 消息，中间第三条丢失（3号），这时接收方只能对前两个发送确认。发送方无法知道后三个分组的下落，而只好把后三个全部重传一次。这也叫 Go-Back-N（回退 N），表示需要退回来重传已经发送过的 N 个消息。 如何保证有序 主机每次发送数据时，TCP就给每个数据包分配一个序列号并且在一个特定的时间内等待接收主机对分配的这个序列号进行确认， 如果发送主机在一个特定时间内没有收到接收主机的确认，则发送主机会重传此数据包。 接收主机利用序列号对接收的数据进行确认，以便检测对方发送的数据是否有丢失或者乱序等 接收主机一旦收到已经顺序化的数据，它就将这些数据按正确的顺序重组成数据流并传递到高层进行处理 拥塞控制拥塞控制就是为了防止过多的数据注入到网络中，这样就可以使网络中的路由器或链路不致过载。拥塞控制所要做的都有一个前提，就是网络能够承受现有的网络负荷。拥塞控制是一个全局性的过程，涉及到所有的主机，所有的路由器，以及与降低网络传输性能有关的所有因素。相反，流量控制往往是点对点通信量的控制，是个端到端的问题。流量控制所要做到的就是抑制发送端发送数据的速率，以便使接收端来得及接收。 慢开始：当拥塞窗口cwnd&lt;慢开始门限ssthresh时，采用慢开始算法，每经过一个传输轮次，拥塞窗口cwnd就加倍。用这样的方法逐步增大发送方的拥塞窗口cwnd,可以使分组注入到网络的速率更加合理。 拥塞避免：为了防止拥塞窗口cwnd增长过大引起网络拥塞，当cwnd&gt;ssthresh 时，停止使用慢开始算法而改用拥塞避免算法。即每经过一个往返时间RTT,就把发送方的拥塞窗口cwnd加1,而不是加倍。这样，拥塞窗口cwnd按线性规律缓慢增长（加法增大） 快重传：快重传算法首先要求接收方每收到一个失序的报文段后，就立即发出重复确认（为的是使发送方及早知道有报文段没有到达对方），而不要等待自已发送数据时才进行捎带确认。发送方只要一连收到三个重复确认，就知道接收方确实没有收到报文段，因而应当立即进行重传（即“快重传”），这样就不会出现超时，发送方也不就会误认为出现了网络拥塞。 快恢复：当发送端收到连续三个重复的确认时，执行快恢复算法。ssthresh=cwnd/2, cwnd = ssthresh, 执行拥塞避免算法。(乘法减小) 常见面试题1.传输层协议有哪些，常见的应用层协议有哪些?传输层协议：UDP, TCP 应用层：HTTP, HTTPS, SMTP, FTP,DNS 2.HTTP GET和POST有什么不同? GET 用于获取信息，是无副作用的，是幂等的，且可缓存。数据在URL中对全部人可见。 POST 用于修改服务器上的数据，有副作用，非幂等，不可缓存。数据不显示在URL中。比get更安全。 3.什么是子网掩码？子网掩码，它是一种用来指明一个IP地址的哪些位标识的是主机所在的子网，以及哪些位标识的是主机的位掩码。子网掩码不能单独存在，它必须结合IP地址一起使用。子网掩码只有一个作用，就是将某个IP地址划分成网络地址和主机地址两部分。 4.HTTP状态码1XX: 信息状态码 状态码 含义 描述 100 继续 初始的请求已经接受，请客户端继续发送剩余部分 101 切换协议 请求这要求服务器切换协议，服务器已确定切换 2XX: 成功状态码 状态码 含义 描述 200 成功 服务器已成功处理了请求 201 已创建 请求成功并且服务器创建了新的资源 202 已接受 服务器已接受请求，但尚未处理 203 非授权信息 服务器已成功处理请求，但返回的信息可能来自另一个来源 204 无内容 服务器成功处理了请求，但没有返回任何内容 205 重置内容 服务器处理成功，用户终端应重置文档视图 206 部分内容 服务器成功处理了部分GET请求 3XX: 重定向状态码 状态码 含义 描述 300 多种选择 针对请求，服务器可执行多种操作 301 永久移动 请求的页面已永久跳转到新的url 302 临时移动 服务器目前从不同位置的网页响应请求，但请求仍继续使用原有位置来进行以后的请求 305 使用代理 请求者只能使用代理访问请求的网页 307 临时重定向 服务器目前从不同位置的网页响应请求，但请求者应继续使用原有位置来进行以后的请求 4XX: 客户端错误状态码 状态码 含义 描述 400 错误请求 服务器不理解请求的语法 401 未授权 请求要求用户的身份验证 403 禁止 服务器拒绝请求 404 未找到 服务器找不到请求的页面 405 方法禁用 禁用请求中指定的方法 408 请求超时 服务器等候请求时发生超时 410 已删除 客户端请求的资源已经不存在 5XX: 服务端错误状态码 状态码 含义 描述 500 服务器错误 服务器内部错误，无法完成请求 501 尚未实施 服务器不具备完成请求的功能 502 错误网关 服务器作为网关或代理出现错误 503 服务不可用 服务器目前无法使用 504 网关超时 网关或代理服务器，未及时获取请求 505 不支持版本 服务器不支持请求中使用的HTTP协议版本 5.Http是长连接的1. HTTP协议与TCP/IP协议的关系 HTTP的长连接和短连接本质上是TCP长连接和短连接。HTTP属于应用层协议，在传输层使用TCP协议，在网络层使用IP协议。 IP协议主要解决网络路由和寻址问题，TCP协议主要解决如何在IP层之上可靠地传递数据包，使得网络上接收端收到发送端所发出的所有包，并且顺序与发送顺序一致。TCP协议是可靠的、面向连接的。 2. 如何理解HTTP协议是无状态的 HTTP协议是无状态的，指的是协议对于事务处理没有记忆能力，服务器不知道客户端是什么状态。也就是说，打开一个服务器上的网页和上一次打开这个服务器上的网页之间没有任何联系。HTTP是一个无状态的面向连接的协议，无状态不代表HTTP不能保持TCP连接，更不能代表HTTP使用的是UDP协议（无连接）。 3. 什么是长连接、短连接？ 在HTTP/1.0中默认使用短连接。也就是说，客户端和服务器每进行一次HTTP操作，就建立一次连接，任务结束就中断连接。当客户端浏览器访问的某个HTML或其他类型的Web页中包含有其他的Web资源（如JavaScript文件、图像文件、CSS文件等），每遇到这样一个Web资源，浏览器就会重新建立一个HTTP会话。 而从HTTP/1.1起，默认使用长连接，用以保持连接特性。使用长连接的HTTP协议，会在响应头加入这行代码： 1Connection:keep-alive 在使用长连接的情况下，当一个网页打开完成后，客户端和服务器之间用于传输HTTP数据的TCP连接不会关闭，客户端再次访问这个服务器时，会继续使用这一条已经建立的连接。Keep-Alive不会永久保持连接，它有一个保持时间，可以在不同的服务器软件（如Apache）中设定这个时间。实现长连接需要客户端和服务端都支持长连接。 HTTP协议的长连接和短连接，实质上是TCP协议的长连接和短连接。 TCP短连接 模拟一下TCP短连接的情况：client向server发起连接请求，server接到请求，然后双方建立连接。client向server发送消息，server回应client，然后一次请求就完成了。这时候双方任意都可以发起close操作，不过一般都是client先发起close操作。上述可知，短连接一般只会在 client/server间传递一次请求操作。 短连接的优点是：管理起来比较简单，存在的连接都是有用的连接，不需要额外的控制手段。 TCP长连接 我们再模拟一下长连接的情况：client向server发起连接，server接受client连接，双方建立连接，client与server完成一次请求后，它们之间的连接并不会主动关闭，后续的读写操作会继续使用这个连接。 TCP的保活功能主要为服务器应用提供。如果客户端已经消失而连接未断开，则会使得服务器上保留一个半开放的连接，而服务器又在等待来自客户端的数据，此时服务器将永远等待客户端的数据。保活功能就是试图在服务端器端检测到这种半开放的连接。 如果一个给定的连接在两小时内没有任何动作，服务器就向客户发送一个探测报文段，根据客户端主机响应探测4个客户端状态： 客户主机依然正常运行，且服务器可达。此时客户的TCP响应正常，服务器将保活定时器复位。 客户主机已经崩溃，并且关闭或者正在重新启动。上述情况下客户端都不能响应TCP。服务端将无法收到客户端对探测的响应。服务器总共发送10个这样的探测，每个间隔75秒。若服务器没有收到任何一个响应，它就认为客户端已经关闭并终止连接。 客户端崩溃并已经重新启动。服务器将收到一个对其保活探测的响应，这个响应是一个复位，使得服务器终止这个连接。 客户机正常运行，但是服务器不可达。这种情况与第二种状态类似。 长连接和短连接的优点和缺点 长连接可以省去较多的TCP建立和关闭的操作，减少浪费，节约时间。对于频繁请求资源的客户来说，较适用长连接。不过这里存在一个问题，存活功能的探测周期太长，还有就是它只是探测TCP连接的存活，属于比较斯文的做法，遇到恶意的连接时，保活功能就不够使了。在长连接的应用场景下，client端一般不会主动关闭它们之间的连接，Client与server之间的连接如果一直不关闭的话，会存在一个问题，随着客户端连接越来越多，server早晚有扛不住的时候，这时候server端需要采取一些策略，如关闭一些长时间没有读写事件发生的连接，这样可 以避免一些恶意连接导致server端服务受损；如果条件再允许就可以以客户端机器为颗粒度，限制每个客户端的最大长连接数，这样可以完全避免某个蛋疼的客户端连累后端服务。 短连接对于服务器来说管理较为简单，存在的连接都是有用的连接，不需要额外的控制手段。但如果客户请求频繁，将在TCP的建立和关闭操作上浪费时间和带宽。 6.udp是否可以实现可靠传输可以。传输层无法保证数据的可靠传输，只能通过应用层来实现了。实现的方式可以参照tcp可靠性传输的方式，只是实现不在传输层，实现转移到了应用层。实现确认机制、重传机制、窗口确认机制。 7.TCP沾包现象https://blog.csdn.net/DamonREN/article/details/88119294 8.Session，cookie和token的区别？http是一个无状态协议 什么是无状态呢？就是说这一次请求和上一次请求是没有任何关系的，互不认识的，没有关联的。这种无状态的的好处是快速。坏处是假如我们想要把www.zhihu.com/login.html和www.zhihu.com/index.html关联起来，必须使用某些手段和工具 cookie和session 由于http的无状态性，为了使某个域名下的所有网页能够共享某些数据，session和cookie出现了。客户端访问服务器的流程如下 首先，客户端会发送一个http请求到服务器端。 服务器端接受客户端请求后，建立一个session，并发送一个http响应到客户端，这个响应头，其中就包含Set-Cookie头部。该头部包含了sessionId。Set-Cookie格式如下，具体请看Cookie详解Set-Cookie: value[; expires=date][; domain=domain][; path=path][; secure] 在客户端发起的第二次请求，假如服务器给了set-Cookie，浏览器会自动在请求头中添加cookie 服务器接收请求，分解cookie，验证信息，核对成功后返回response给客户端 注意 cookie只是实现session的其中一种方案。虽然是最常用的，但并不是唯一的方法。禁用cookie后还有其他方法存储，比如放在url中 现在大多都是Session + Cookie，但是只用session不用cookie，或是只用cookie，不用session在理论上都可以保持会话状态。可是实际中因为多种原因，一般不会单独使用 用session只需要在客户端保存一个id，实际上大量数据都是保存在服务端。如果全部用cookie，数据量大的时候客户端是没有那么多空间的。 如果只用cookie不用session，那么账户信息全部保存在客户端，一旦被劫持，全部信息都会泄露。并且客户端数据量变大，网络传输的数据量也会变大 小结 简而言之, session 有如用户信息档案表, 里面包含了用户的认证信息和登录状态等信息. 而 cookie 就是用户通行证 token token 也称作令牌，由uid+time+sign[+固定参数]token 的认证方式类似于临时的证书签名, 并且是一种服务端无状态的认证方式, 非常适合于 REST API 的场景. 所谓无状态就是服务端并不会保存身份认证相关的数据。 组成 uid: 用户唯一身份标识 time: 当前时间的时间戳 sign: 签名, 使用 hash/encrypt 压缩成定长的十六进制字符串，以防止第三方恶意拼接 固定参数(可选): 将一些常用的固定参数加入到 token 中是为了避免重复查库 存放 token在客户端一般存放于localStorage，cookie，或sessionStorage中。在服务器一般存于数据库中 token认证流程 token 的认证流程与cookie很相似 用户登录，成功后服务器返回Token给客户端。 客户端收到数据后保存在客户端 客户端再次访问服务器，将token放入headers中 服务器端采用filter过滤器校验。校验成功则返回请求数据，校验失败则返回错误码 总结 session存储于服务器，可以理解为一个状态列表，拥有一个唯一识别符号sessionId，通常存放于cookie中。服务器收到cookie后解析出sessionId，再去session列表中查找，才能找到相应session。依赖cookie cookie类似一个令牌，装有sessionId，存储在客户端，浏览器通常会自动添加。 token也类似一个令牌，无状态，用户信息都被加密到token中，服务器收到token后解密就可知道是哪个用户。需要开发者手动添加。]]></content>
  </entry>
  <entry>
    <title><![CDATA[Spring常见面试题]]></title>
    <url>%2F2020%2F05%2F20%2FSpring%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98%2F</url>
    <content type="text"><![CDATA[RESTful API介绍REST,即 REpresentational State Transfer 的缩写。这个词组的翻译过来就是”表现层状态转化”。这样理解起来甚是晦涩，实际上 REST 的全称是 Resource Representational State Transfe ，直白地翻译过来就是 “资源”在网络传输中以某种“表现形式”进行“状态转移” 。 资源（Resource） ：我们可以把真实的对象数据称为资源。一个资源既可以是一个集合，也可以是单个个体。比如我们的班级 classes 是代表一个集合形式的资源，而特定的 class 代表单个个体资源。每一种资源都有特定的 URI（统一资源定位符）与之对应，如果我们需要获取这个资源，访问这个 URI 就可以了，比如获取特定的班级：/class/12。另外，资源也可以包含子资源，比如 /classes/classId/teachers：列出某个指定班级的所有老师的信息 表现形式（Representational）：”资源”是一种信息实体，它可以有多种外在表现形式。我们把”资源”具体呈现出来的形式比如 json，xml，image,txt 等等叫做它的”表现层/表现形式”。 状态转移（State Transfer） ：大家第一眼看到这个词语一定会很懵逼？内心 BB：这尼玛是啥啊？ 大白话来说 REST 中的状态转移更多地描述的服务器端资源的状态，比如你通过增删改查（通过 HTTP 动词实现）引起资源状态的改变。ps:互联网通信协议 HTTP 协议，是一个无状态协议，所有的资源状态都保存在服务器端。 综合上面的解释，我们总结一下什么是 RESTful 架构： 每一个 URI 代表一种资源； 客户端和服务器之间，传递这种资源的某种表现形式比如 json，xml，image,txt 等等； 客户端通过特定的 HTTP 动词，对服务器端资源进行操作，实现”表现层状态转化”。 REST 接口规范 GET ：请求从服务器获取特定资源。举个例子：GET /classes（获取所有班级） POST ：在服务器上创建一个新的资源。举个例子：POST /classes（创建班级） PUT ：更新服务器上的资源（客户端提供更新后的整个资源）。举个例子：PUT /classes/12（更新编号为 12 的班级） DELETE ：从服务器删除特定的资源。举个例子：DELETE /classes/12（删除编号为 12 的班级） get和post的区别 GET 用于获取信息，是无副作用的，是幂等的，且可缓存。数据在URL中对全部人可见。 POST 用于修改服务器上的数据，有副作用，非幂等，不可缓存。数据不显示在URL中。比get更安全。 状态码范围： 2xx：成功 3xx：重定向 4xx：客户端错误 5xx：服务器错误 200 成功 301 永久重定向 400 错误请求 500 服务器错误 201 创建 304 资源未修改 401 未授权 502 网关错误 403 禁止访问 504 网关超时 404 未找到 405 请求方法不对 ### 介绍一下IOCIoC（Inverse of Control:控制反转）是一种设计思想，就是 将原本在程序中手动创建对象的控制权，交由Spring框架来管理。 IoC 在其他语言中也有应用，并非 Spring 特有。 IoC 容器是 Spring 用来实现 IoC 的载体， IoC 容器实际上就是个Map（key，value）,Map 中存放的是各种对象。 将对象之间的相互依赖关系交给 IoC 容器来管理，并由 IoC 容器完成对象的注入。这样可以很大程度上简化应用的开发，把应用从复杂的依赖关系中解放出来。 IoC 容器就像是一个工厂一样，当我们需要创建一个对象的时候，只需要配置好配置文件/注解即可，完全不用考虑对象是如何被创建出来的。 在实际项目中一个 Service 类可能有几百甚至上千个类作为它的底层，假如我们需要实例化这个 Service，你可能要每次都要搞清这个 Service 所有底层类的构造函数，这可能会把人逼疯。如果利用 IoC 的话，你只需要配置好，然后在需要的地方引用就行了，这大大增加了项目的可维护性且降低了开发难度。 Spring 时代我们一般通过 XML 文件来配置 Bean，后来开发人员觉得 XML 文件来配置不太好，于是 SpringBoot 注解配置就慢慢开始流行起来。 推荐阅读：https://www.zhihu.com/question/23277575/answer/169698662 Bean的作用域单实例：singleton 1.默认的，容器启动完成之前就已经创建好对象了，保存在容器中了。 2.任何时候获取，都是获取之前创建好的那个对象。 prototype 1.容器启动时，默认不会去创建多实例bean，获取的时候创建bean。 2.每次获取都会创建一个新的对象。 spring中的单例bean的线程安全问题了解吗？大部分时候我们并没有在系统中使用多线程，所以很少有人会关注这个问题。单例bean存在线程安全问题，主要是因为当多个线程操作同一个对象的时候，对这个对象的非静态成员变量的写操作会存在线程安全问题。 常见的两种解决方法： 在Bean对象中尽量避免定义可变的成员变量（不太现实）。 在类中定义一个ThreadLocal成员变量，将需要的可变成员变量保存在ThreadLocal中（推荐的一种方式）。 @Bean和@Component的区别是什么？相同点：两者的结果都是为spring容器注册Bean. 作用对象： @component注解作用于类，可以通过类路径来自动扫描并注册到spring容器中，也可以使用@ComponentScan定义需要扫描的路径。 @Bean注解作用于方法，告诉spring这个方法会返回一个对象，要将其注入到容器中。 @Bean相对来说就更加灵活了，而且如果你要用到第三方类库里面某个类或者方法的时候，你就只能用@Bean把这个类或者方法注册到spring容器，因为用@Component你需要配置组件扫描到这个第三方类路径而且还要在别人源代码加上这个注解，很明显是不现实的。 @Bean注解使用示例： 1234567@Configurationpublic class AppConfig &#123; @Bean public TransferService transferService() &#123; return new TransferServiceImpl(); &#125;&#125; 上面的代码相当于下面的xml配置 @Component : 通用的注解，可标注任意类为Spring组件。如果一个Bean不知道属于哪个层，可以使用这个注解。 @Repository ： 对应持久层即Dao层，主要用于数据库相关操作。 @Service : 对应服务层，主要涉及一些复杂的逻辑，需要用到Dao层。 @Controller : 对应Spring MVC控制层，主要用于接受用户请求并调用Service层返回数据给前端页面。 Spring中的Bean生命周期https://www.cnblogs.com/zrtqsk/p/3735273.html Spirng依赖注入的两种注入方式（IOC容器创建对象的方式，底层都是通过反射）：Spring框架的核心功能之一就是通过依赖注入的方式来管理Bean之间的依赖关系。 1.构造函数注入，使用构造器对对象的初始化注入对应的值 1234567891011121314151617181920&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans"xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"xsi:schemaLocation="http://www.springframework.org/schema/beanshttp://www.springframework.org/schema/beans/spring-beans-3.2.xsd"&gt; &lt;bean name="teacher" class="com.xxx.spring.ioc.bean.Teacher"&gt; &lt;!-- 1.按照属性名赋值 ，调用有参数的构造器，顺序是参数顺序--&gt; &lt;constructor-arg name="id" value="1"/&gt; &lt;!-- person(int id,String name, String gender) --&gt; &lt;constructor-arg name="name" value="tom"/&gt; &lt;constructor-arg name="gender" value="male"/&gt; &lt;!-- 2.index从0开始，按照属性在构造器中出现的顺序赋值 索引值是构造器中的属性顺序 --&gt; &lt;!-- &lt;constructor-arg index="0" value="2"/&gt; &lt;constructor-arg index="1" value="jack"/&gt; &lt;constructor-arg index="2" value="male"/&gt; --&gt; &lt;!-- 3.按照类型进行赋值，如果出现相同的类型，按照属性在构造器中出现的顺序进行复制 --&gt; &lt;!-- &lt;constructor-arg type="int" value="3"/&gt; &lt;constructor-arg type="String" value="rose"/&gt; &lt;constructor-arg type="String" value="female"/&gt; --&gt; &lt;/bean&gt;&lt;/beans&gt; Teacher.java 12345678910111213141516171819public class Teacher implements Serializable&#123; private static final long serialVersionUID = 1L; private int id; private String name; private String gender; public Teacher(int id, String name, String gender) &#123; super(); this.id = id; this.name = name; this.gender = gender; &#125; @Override public String toString() &#123; return "Teacher [id=" + id + ", name=" + name + ", gender=" + gender + "]"; &#125; 测试 1234567@Testpublic void test3() throws Exception &#123; ApplicationContext ac = new ClassPathXmlApplicationContext("beans.xml"); Teacher teacher = (Teacher) ac.getBean("teacher"); System.out.println(teacher);//Teacher [id=1, name=tom, gender=male]&#125; 2.set方法注入，就是在类中提供需要注入成员的set方法 beans.xml 1234567&lt;bean id="accountService" class="com.itheima.service.impl.AccountServiceImpl"&gt; &lt;property name="name" value="test"&gt;&lt;/property&gt; &lt;property name="age" value="21"&gt;&lt;/property&gt; &lt;property name="birthday" ref="now"&gt;&lt;/property&gt;&lt;/bean&gt; &lt;!--Spring就会通过反射调用没有参数的构造方法生成对象，同时通过反射对应的setter注入配置的值--&gt;&lt;bean id="now" class="java.util.Date"&gt;&lt;/bean&gt; AccountServiceImpl.java 1234567891011121314public class AccountServiceImpl implements IAccountService &#123; private String name; private Integer age; private Date birthday; public void setName(String name) &#123; this.name = name; &#125; public void setAge(Integer age) &#123; this.age = age; &#125; public void setBirthday(Date birthday) &#123; this.birthday = birthday; &#125; 常用注解用于创建对象的相当于： @Component 作用： 把资源让spring来管理。相当于在xml中配置一个bean。 属性： value：指定bean的id。如果不指定value属性，默认bean的id是当前类的类名。首字母小写。 @Controller @Service @Repository 他们三个注解都是针对一个的衍生注解，他们的作用及属性都是一模一样的。 他们只不过是提供了更加明确的语义化。 @Controller：一般用于表现层的注解。 @Service：一般用于业务层的注解。 @Repository：一般用于持久层的注解。 用于注入数据的@Autowired 作用： 自动按照类型注入。当使用注解注入属性时，在spring容器查找，找到了也可以注入成功。找不到就报错。自动装配值。找到多个的话，可以用qulifier指定id @Autowired private UserService userService; 如果没有Autowired注解，userService=null @Autowired 和 @Resource的区别 @Autowired更强大，spring框架，离开spring没法用（谁会舍得离开呢） @Resource是java自带的 @Qualifier 作用： 在自动按照类型注入的基础之上，再按照Bean的id注入。它在给字段注入时不能独立使用，必须和@Autowire一起使用；但是给方法参数注入时，可以独立使用。 属性： value：指定bean的id。 1、 @Autowired与@Resource都可以用来装配bean. 都可以写在字段上,或写在setter方法上。 2、 @Autowired默认按类型装配（这个注解是属业spring的），默认情况下必须要求依赖对象必须存在，如果要允许null值，可以设置它的required属性为false，如：@Autowired(required=false) ，如果我们想使用名称装配可以结合@Qualifier注解进行使用，如下： 1`@Autowired``()``@Qualifier``(``&quot;baseDao&quot;``)``private``BaseDao baseDao;` 3、@Resource（这个注解属于J2EE的），默认按照名称进行装配，名称可以通过name属性进行指定，如果没有指定name属性，当注解写在字段上时，默认取字段名进行安装名称查找，如果注解写在setter方法上默认取属性名进行装配。当找不到与名称匹配的bean时才按照类型进行装配。但是需要注意的是，如果name属性一旦指定，就只会按照名称进行装配。 1`@Resource``(name=``&quot;baseDao&quot;``)``private``BaseDao baseDao;` AOP区别OOP(Object Oriented Programming) 思想：在程序运行期间，讲某段代码动态的切入到指定方法的指定位置进行运行的这种编程方式 AOP(Aspect-Oriented Programming:面向切面编程)能够将那些与业务无关，却为业务模块所共同调用的逻辑或责任（例如事务处理、日志管理、权限控制等）封装起来，便于减少系统的重复代码，降低模块间的耦合度，并有利于未来的可拓展性和可维护性。 Spring AOP就是基于动态代理的，如果要代理的对象，实现了某个接口，那么Spring AOP会使用JDK Proxy，去创建代理对象，而对于没有实现接口的对象，就无法使用 JDK Proxy 去进行代理了，这时候Spring AOP会使用Cglib ，这时候Spring AOP会使用 Cglib 生成一个被代理对象的子类来作为代理， @Before：前置通知，在方法执行之前执行 @AfterRunning：返回通知，在方法返回正常结果之后执行 @AfterThrowing：异常通知，在方法抛出异常之后执行 @After：后置通知，在方法执行之后执行 @Around：环绕通知，围绕着方法执行 4合1 通知顺序：前置–返回–后置 前置–异常–后置 Aspect（切面）： Aspect 声明类似于 Java 中的类声明，在 Aspect 中会包含着一些 Pointcut 以及相应的 Advice。 Joint point（连接点）：表示在程序中明确定义的点，典型的包括方法调用，对类成员的访问以及异常处理程序块的执行等等，它自身还可以嵌套其它 joint point。 Pointcut（切点）：表示一组 joint point，这些 joint point 或是通过逻辑关系组合起来，或是通过通配、正则表达式等方式集中起来，它定义了相应的 Advice 将要发生的地方。 Advice（增强）：Advice 定义了在 Pointcut 里面定义的程序点具体要做的操作，它通过 before、after 和 around 来区别是在每个 joint point 之前、之后还是代替执行的代码。 Target（目标对象）：织入 Advice 的目标对象.。 Weaving（织入）：将 Aspect 和其他对象连接起来, 并创建 Adviced object 的过程 123456//切面如何编写1.导入切面场景 spring-boot-starter-aop2.编写切面 1&gt; @Aspect 2&gt; 切入点表达式 3&gt; 通知，前置，后置，环绕 动态代理可以在运行期动态创建某个interface的实例。实际上是jdk自动帮你inplements了这个接口类。XXXDynamicProxicy. Proxy.newProxyInstance(ClassLoader loader, Class&lt;?&gt;[] interfaces, InvocationHandler handler) 构造实现指定接口的代理类的一个新实例。所有方法会调用给定处理器对象handler的invoke方法 12345678910111213141516171819202122232425262728public class Main &#123; public static void main(String[] args) &#123; InvocationHandler handler = new InvocationHandler() &#123; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; System.out.println(method); if (method.getName().equals("morning")) &#123; System.out.println("Good morning, " + args[0]); &#125; return null; &#125; &#125;; Hello hello = (Hello) Proxy.newProxyInstance( Hello.class.getClassLoader(), // 传入ClassLoader new Class[] &#123; Hello.class &#125;, // 传入要实现的接口 handler); // 传入处理调用方法的InvocationHandler hello.morning("Bob"); &#125;&#125;interface Hello &#123; void morning(String name); //输出如下 /* public abstract void Hello.morning(java.lang.String) Good morning, Bob */&#125; 静态代理和动态代理廖雪峰 静态代理（看廖雪峰比较容易理解）首先, 定义接口和接口的实现类, 然后定义接口的代理对象, 将接口的实例注入到代理对象中, 然后通过代理对象去调用真正的实现类。 缺点：为现有的每一个类都编写一个对应的代理类，并且让它实现和目标类相同的接口（假设都有） 123456789101112131415161718192021222324252627282930313233343536public interface Movie &#123;//接口 void play();&#125;public class RealMovie implements Movie &#123;//接口的实现类 @Override public void play() &#123; // TODO Auto-generated method stub System.out.println("您正在观看电影 《肖申克的救赎》"); &#125;&#125;public class Cinema implements Movie &#123;//代理对象 RealMovie movie; public Cinema(RealMovie movie) &#123; super(); this.movie = movie; &#125; @Override public void play() &#123; guanggao(true); movie.play(); guanggao(false); &#125; public void guanggao(boolean isStart)&#123; if ( isStart ) &#123; System.out.println("电影马上开始了，爆米花、可乐、口香糖9.8折，快来买啊！"); &#125; else &#123; System.out.println("电影马上结束了，爆米花、可乐、口香糖9.8折，买回家吃吧！"); &#125; &#125; &#125; JDK和CGLIB动态1、JDK动态代理 利用拦截器(拦截器必须实现InvocationHanlder)加上反射机制生成一个实现代理接口的匿名类，在调用具体方法前调用InvokeHandler来处理。 2、CGLIB动态代理 利用ASM开源包，对代理对象类的class文件加载进来，通过修改其字节码生成子类来处理。 3、何时使用JDK还是CGLIB？ 1）如果目标对象实现了接口，默认情况下会采用JDK的动态代理实现AOP。 2）如果目标对象实现了接口，可以强制使用CGLIB实现AOP。 3）如果目标对象没有实现了接口，必须采用CGLIB库，Spring会自动在JDK动态代理和CGLIB之间转换。 4、如何强制使用CGLIB实现AOP？ 1）添加CGLIB库(aspectjrt-xxx.jar、aspectjweaver-xxx.jar、cglib-nodep-xxx.jar) 2）在Spring配置文件中加入&lt;aop:aspectj-autoproxy proxy-target-class=”true”/&gt; 5、JDK动态代理和CGLIB字节码生成的区别？ 1）JDK动态代理只能对实现了接口的类生成代理，而不能针对类。代理对象必须实现一个接口，否则会报异常，因为人家原理就是根据接口来生成代理对象的。 2）CGLIB是针对类实现代理，主要是对指定的类生成一个子类，覆盖其中的方法，并覆盖其中方法实现增强，但是因为采用的是继承，所以该类或方法最好不要声明成final，对于final类或方法，是无法继承的。 1234567891011121314151617181920212223242526272829303132public static interface Hello &#123; void hi(String msg);&#125;public static class HelloImpl implements Hello &#123; @Override public void hi(String msg) &#123; System.out.println("hello " + msg); &#125;&#125;/** * 代理类 */@Data@NoArgsConstructor@AllArgsConstructorpublic static class HelloProxy implements InvocationHandler &#123; private Object proxied = null; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; System.out.println("hello proxy"); return method.invoke(proxied, args); &#125;&#125;public static void main(String[] args) &#123; Hello hello = (Hello) Proxy.newProxyInstance(Hello.class.getClassLoader(), new Class[]&#123;Hello.class&#125;, new HelloProxy(new HelloImpl())); System.out.println(hello.getClass()); // class com.sun.proxy.$Proxy0 hello.hi("world");&#125; 介绍一下MVC及其优缺点 模型(Model)封装了应用程序数据，通常它们将由POJO类组成。 视图(View)负责渲染模型数据，一般来说它生成客户端浏览器可以解释HTML输出。 控制器(Controller)负责处理用户请求并构建适当的模型，并将其传递给视图进行渲染。 Spring MVC 的简单原理图如下： 请求流程： 具体步骤： 第一步：发起请求到前端控制器(DispatcherServlet) 第二步：前端控制器请求HandlerMapping查找 Handler (就是Cotroller对象和请求方式组合的一个Object对象)（可以根据xml配置、注解进行查找） 第三步：处理器映射器HandlerMapping向前端控制器返回Handler，HandlerMapping会把请求映射为HandlerExecutionChain对象（包含一个Handler处理器（页面控制器）对象，多个HandlerInterceptor拦截器对象），通过这种策略模式，很容易添加新的映射策略 第四步：前端控制器调用处理器适配器去执行Handler 第五步：处理器适配器HandlerAdapter将会根据适配的结果去执行Handler 第六步：Handler执行完成给适配器返回ModelAndView 第七步：处理器适配器向前端控制器返回ModelAndView （ModelAndView是springmvc框架的一个底层对象，包括 Model和view） 第八步：前端控制器请求视图解析器去进行视图解析 （根据逻辑视图名解析成真正的视图(jsp)），通过这种策略很容易更换其他视图技术，只需要更改视图解析器即可 第九步：视图解析器向前端控制器返回View 第十步：前端控制器进行视图渲染 （视图渲染将模型数据(在ModelAndView对象中)填充到request域） 第十一步：前端控制器向用户响应结果 MVC的优点： 1、低耦合性： 视图层和业务层分离，这样就允许更改视图层代码而不用重新编译模型和控制器代码。同样，一个应用的业务流程或者业务规则的改变只需要改动MVC的模型层即可，因为模型与控制器和视图相分离，所以很容易改变应用程序的数据层和业务规则。 2、高重用性和可适用性 MVC模式允许你使用各种不同样式的视图来访问同一个服务器端的代码。它 包括任何WEB（HTTP）浏览器或者无线浏览器（wap），例如：例如，很多数 据可能用HTML来表示，但是也有可能用WAP来表示，而这些表示所需要的仅令是改变视图层的实现方式，而控制层和模型层无需做任何改变。 3、较低的生命周期成本MVC使降低开发和维护用户接口的技术含量成为可能。 4、快速的部署 使用MVC模式使开发时间得到相当大的缩减，它使程序员（Java开发人员） 集中 精力于业务逻辑，界面程序员（HTML和JSP开发人员）集中精力于表现形式上 5、可维护性 优点：分层，结构清晰，耦合性低，大型项目代码的复用性得到极大的提高，开发人员分工明确，提高了开发的效率，维护方便，降低了维护成本。 MVC的缺点： 1、增加了系统结构和实现的复杂性 2、视图与控制器间的过于紧密的连接 3、视图对模型数据的低效率访问 缺点：简单的小型项目，使用MVC设计反而会降低开发效率，层和层虽然相互分离，但是之间关联性太强，没有做到独立的重用。（视图与控制器是相互分离，但却是联系紧密的部件，视图没有控制器的存在，其应用是很有限的，反之亦然，这样就妨碍了他们的独立重用。【例如，不可能总是在jsp页面中直接访问模型，一般放在逻辑控制层进行处理，servlet】） Spring设计模式常见面试题1.Spring 框架中用到了哪些设计模式？工厂设计模式 : Spring使用工厂模式通过 BeanFactory、ApplicationContext 创建 bean 对象。 代理设计模式 : Spring AOP 功能的实现。 单例设计模式 : Spring 中的 Bean 默认都是单例的。 模板方法模式 : Spring 中 jdbcTemplate、hibernateTemplate 等以 Template 结尾的对数据库操作的类，它们就使用到了模板模式。 观察者模式: Spring 事件驱动模型就是观察者模式很经典的一个应用。 适配器模式 :当我们要访问的接口A中没有我们想要的方法 ，却在另一个接口B中发现了合适的方法，我们又不能改变访问接口A，在这种情况下，我们可以定义一个适配器p来进行中转，这个适配器p要实现我们访问的接口A，这样我们就能继续访问当前接口A中的方法（虽然它目前不是我们的菜），然后再继承接口B的实现类BB，这样我们可以在适配器P中访问接口B的方法了，这时我们在适配器P中的接口A方法中直接引用BB中的合适方法，这样就完成了一个简单的类适配器。 Spring AOP 的增强或通知(Advice)使用到了适配器模式、spring MVC 中也是用到了适配器模式适配。除此之外，Java IO中由于InputStream是字节流不能享受到字符流读取字符那么便捷的功能，因此借助InputStreamReader将其转为Reader子类，因此可以拥有便捷操作文本文件方法。OutputStream同理。 装饰者设计模式 : 对装饰器模式来说，装饰者（Decorator）和被装饰者（Decoratee）都实现一个接口。 对代理模式来说，代理类（Proxy Class）和真实处理的类（Real Class）都实现同一个接口。 区别：装饰器模式偏重对原对象功能的扩展，扩展后的对象仍是是对象本身；然而代理模式偏重因自己无法完成或无需关心，需要他人干涉事件流程，更多的是对对象的控制（代理使客户端不需要知道实现类是什么，怎么做的，而客户端只需知道代理即可，即将客户端与实现类解耦） 换句话说，用代理模式，代理类（proxy class）可以对它的客户隐藏一个对象的具体信息。因此，当使用代理模式的时候，我们常常在一个代理类中创建一个对象的实例。并且，当我们使用装饰器模式的时候，我们通常的做法是将原始对象作为一个参数传给装饰者的构造器 eg1.我们的项目需要连接多个数据库，而且不同的客户在每次访问中根据需要会去访问不同的数据库。这种模式让我们可以根据客户的需求能够动态切换不同的数据源。 eg2.将InputStream字节流包装为BufferedReader过程就装饰的过程。一开始InputStream只有read一个字节的方法，包装为Reader之后拥有read一个字符的功能，在包装成BufferedReader之后就拥有read一行字符串功能。OutputStream同理。 Spring 框架中用到了哪些设计模式 #### 2.介绍一下单例模式，都怎么实现保证一个类仅有一个实例，并提供一个访问它的全局访问点。这种类型的设计模式属于创建型模式，它提供了一种创建对象的最佳方式。 这种模式涉及到一个单一的类，该类负责创建自己的对象，同时确保只有单个对象被创建。这个类提供了一种访问其唯一的对象的方式，可以直接访问，不需要实例化该类的对象。 懒汉式，线程安全 1234567891011//懒汉式，用到才创建，线程安全public class Singleton &#123; private static Singleton instance; private Singleton ()&#123;&#125; public static synchronized Singleton getInstance() &#123; if (instance == null) &#123; instance = new Singleton(); &#125; return instance; &#125; &#125; 饿汉式 12345678//线程安全，类加载时就初始化，浪费内存public class Singleton &#123; private static Singleton instance = new Singleton(); private Singleton ()&#123;&#125; public static Singleton getInstance() &#123; return instance; &#125; &#125; 双重校验锁 1234567891011121314public class Singleton &#123; private volatile static Singleton singleton; private Singleton ()&#123;&#125; public static Singleton getSingleton() &#123; if (singleton == null) &#123; synchronized (Singleton.class) &#123; if (singleton == null) &#123; singleton = new Singleton(); &#125; &#125; &#125; return singleton; &#125; &#125; 3.工厂模式都有哪几种？怎么实现？这种类型的设计模式属于创建型模式，它提供了一种创建对象的最佳方式。 在工厂模式中，我们在创建对象时不会对客户端暴露创建逻辑，并且是通过使用一个共同的接口来指向新创建的对象。 1.简单工厂模式 该模式对对象创建管理方式最为简单，因为其仅仅简单的对不同类对象的创建进行了一层薄薄的封装。该模式通过向工厂传递类型来指定要创建的对象 代码：点击下载 2.工厂方法模式 和简单工厂模式中工厂负责生产所有产品相比，工厂方法模式将生成具体产品的任务分发给具体的产品工厂 3.抽象工厂模式 4.spring如何解决循环依赖①：构造器(函数)的循环依赖。【这个Spring解决不了】 ②【setter循环依赖】【可以解决】 Spring是先将Bean对象实例化【依赖无参构造函数】—&gt;再设置对象属性的 【setter方式 单例，默认方式–&gt;通过递归方法找出当前Bean所依赖的Bean，然后提前缓存【会放入Cach中】起来。通过提前暴露 –&gt;暴露一个exposedObject用于返回提前暴露的Bean。】递归实例化所有的Bean对象后，再反递归设置对象属性。 5.设计模式六大原则1.单一原则：一个类或者一个方法只负责一项职责 2.里氏替换原则：子类可以扩展父类的功能，但不能改变原有父类的功能 3.依赖倒置原则：面向接口编程；上层模块不应该依赖下层模块，两者应依赖其抽象；抽象不应该依赖细节，细节应该依赖抽象； 通俗点就是说变量或者传参数，尽量使用抽象类，或者接口； 4.接口隔离：建立单一接口 简单理解：复杂的接口，根据业务拆分成多个简单接口；（对于有些业务的拆分多看看适配器的应用） 5.迪米特原则：最少知道原则，尽量降低类与类之间的耦合； 6.开闭原则：用抽象构建架构，用实现扩展原则；（总纲） 6.Spring，SpringMVC，SprinBoot有什么区别？ Spring Spring是一个开源容器框架，可以接管web层，业务层，dao层，持久层的组件，并且可以配置各种bean,和维护bean与bean之间的关系。其核心就是控制反转(IOC),和面向切面(AOP),简单的说就是一个分层的轻量级开源框架。 SpringMVC SpringMVC是基于Spring功能之上添加的Web框架，想用SpringMVC必须先依赖Spring。 SpringBoot 实现自动配置，去除大量xml配置文件。 Maven快速整合第三方框架，如spring-boot-starter-web 自带tomcat服务器 关系 Spring MVC和Spring Boot都属于Spring，Spring MVC 是基于Spring的一个 MVC 框架，而Spring Boot 是基于Spring的一套快速开发整合包]]></content>
  </entry>
  <entry>
    <title><![CDATA[软件测试]]></title>
    <url>%2F2020%2F05%2F19%2F%E8%BD%AF%E4%BB%B6%E6%B5%8B%E8%AF%95%2F</url>
    <content type="text"><![CDATA[面试题1：软件产品质量特性是什么？ 答：软件产品的质量属性有8个，分别为： 1、功能性：功能完备性、功能正确性、功能适合性、功能性的依从性。 2、性能效率：时间特性、资源利用率、容量、性能效率的依从性。 3、兼容性：共存性、互操作性、兼容性的依从性。 4、易用性：可辨识性、易学性、易操作性、用户差错防御性、用户界面舒适性、易访问性、易用性的依从性。 5、可靠性：成熟性、可用性、容错性、易恢复性、可靠性的依从性。 6、信息安全性：保密性、完整性、抗抵赖性、可核查性、真实性、信息安全性的依从性。 7、维护性：模块化、可重用性、易分析性、易修改性、易测试性、维护性的依从性。 8、可移植性：适应性、易安装性、易替换性、可移植性的依从性。 PS：每个质量特性的详细介绍如果记不住也没关系，能说出来一两个就ok。 面试题2：软件测试有哪些分类？ 答：按照不同的划分方式，有不同的分类。 1、按照开发阶段划分 软件测试可分为：单元测试、集成测试、系统测试、确认测试和验收测试。 2、按照测试实施组织划分 软件测试可分为开发方测试、用户测试、第三方测试。 3、按照测试技术划分 软件测试可分为：白盒测试、黑盒测试、灰盒测试。也可划分为静态测试和动态测试。 黑盒测试一般用来确认软件功能的正确性和可操作性,目的是检测软件的各个功能是否能得以实现,把被测试的程序当作一个黑盒,不考虑其内部结构,在知道该程序的输入和输出之间的关系或程序功能的情况下,依靠软件规格说明书来确定测试用例和推断测试结果的正确性。 白盒测试根据软件内部的逻辑结构分析来进行测试,是基于代码的测试，测试人员通过阅读程序代码或者通过使用开发工具中的单步调试来判断软件的质量，一般黑盒测试由项目经理在程序员开发中来实现。 静态测试是不运行程序本身而寻找程序代码中可能存在的错误或评估程序代码的过程。 动态测试是实际运行被测程序，输入相应的测试实例，检查运行结果与预期结果的差异，判定执行结果是否符合要求，从而检验程序的正确性、可靠性和有效性，并分析系统运行效率和健壮性等性能。 α测试是由一个用户在开发环境下进行的测试，也可以是公司内部的用户在模拟实际操作环境下进行的受控测试，Alpha测试不能由程序员或测试员完成。 β测试是软件的多个用户在一个或多个用户的实际使用环境下进行的测试。开发者通常不在测试现场，Beta测试不能由程序员或测试员完成。 面试题3：请简述黑盒测试和白盒测试的优缺点。 答：下面将分别简述。 1、黑盒测试优缺点 优点： 对测试人员要求不高； 执行起来较简单，不需要了解程序内部的代码及实现； 能够遍历说明书中全部的功能； 可以方便的测试复杂逻辑的程序功能。 缺点： 不可能进行穷举测试； 不可能进行覆盖所有代码的测试； 测试的正确率依赖于需求文档说明书，但是该文档也是人为编写的，存在一定的风险，黑盒测试对这种风险无能为力。 2、白盒测试优缺点 优点： 迫使测试人员去仔细思考软件的实现； 可以检测代码中的每条分支和路径； 揭示隐藏在代码中的错误； 对代码的测试比较彻底； 让软件最优化。 缺点： 昂贵； 无法检测代码中遗漏的路径和数据敏感性错误； 不验证规格的正确性。 面试题4：请简述黑盒测试的测试用例常见的设计方法。 1、等价类划分法 等价类划分，就是把程序的输入域划分为若干部分，从每个部分中选取少数、有代表性的数据作为程序输入的测试用例。每个部分的代表性数据在测试中的作用等价于这部分数据中其他数据。 2、边界值分析法 3、错误推测法、因果图法、判定表驱动法]]></content>
  </entry>
  <entry>
    <title><![CDATA[live2d设置]]></title>
    <url>%2F2020%2F05%2F14%2Flive2d%E8%AE%BE%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[最初级的用法使用官方包安装，安装非常简单，但效果一般hexo live-2d地址：https://github.com/xiazeyu/live2d-widget-modelsgit命令行中输入： 12npm install --save hexo-helper-live2d npm install live2d-widget-model-epsilon2_1 # 安装某个模型 同时在博客配置文件中修改： 增加的宠物功能123456789101112131415161718live2d: enable: true pluginRootPath: live2dw/ pluginJsPath: lib/ pluginModelPath: assets/ model: use: live2d-widget-model-epsilon2_1 display: position: right width: 250 height: 500 mobile: show: true scale: 0.5 react: opacityDefault: 1 opacityOnHover: 1 高级版首先下载大佬的github文件，修改好名字放置于\themes\next\source下 打开live2d-widget文件下的autoloads.js文件，修改绝对路径： 1const live2d_path = "/live2d/"; 打开_layout.swig文件，先在head标签下添加依赖，否则无法正常显示： 12&lt;script src="https://cdn.jsdelivr.net/npm/jquery/dist/jquery.min.js"&gt;&lt;/script&gt;&lt;link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome/css/font-awesome.min.css"&gt; 然后再在footer标签下添加： 1&lt;script src="https://hac135.github.io/live2d-widget/autoload.js"&gt;&lt;/script&gt; 然后把博客配置文件的live2d配置注释掉，在主题配置文件中添加 12live2d: enable: true 如何删除（启用）这个东西非常耗CPU和内存，一般来说直接设置false即可关闭。 彻底卸载如下： 1.初级版 根目录执行： 1npm uninstall hexo-helper-live2d -g 删除npm_modules/hexo-helper-live2d文件夹，注释掉博客配置文件live2d相关内容，或直接改为false 2.高级版 打开_layout.swig文件，删除 或者修改主题配置文件live2d为false]]></content>
  </entry>
  <entry>
    <title><![CDATA[登录和购物车功能]]></title>
    <url>%2F2020%2F05%2F12%2F%E7%99%BB%E5%BD%95%E5%92%8C%E8%B4%AD%E7%89%A9%E8%BD%A6%E5%8A%9F%E8%83%BD%2F</url>
    <content type="text"><![CDATA[单点登录SSO英文全称Single Sign On，单点登录； SSO是在多个应用系统中，用户只需要登录一次就可以访问所有相互信任的应用系统。 1）、任何系统都必须去登陆服务器进行登录 2）、服务器就记住了登录状态 3）、其他系统访问受保护资源，需要再次登录，跳转到sso_server登录的时候，服务器告诉客户端，已经登录过，无须登录。登录过得信息 单点登录流程图 社交登录OAuth2.0协议 OAuth：OAuth（开放授权）是一个开放标准，允许用户授权第三方网站访问他们存储在另外的服务提供者上的信息，而不需要将用户名和密码提供给第三方网站或分享他们数据的所有内容。 OAuth2.0：对于用户相关的OpenAPI（例如获取用户信息，动态同步，照片，日志，分享等），为了保护用户数据的安全和隐私，第三方网站访问用户数据前都需要显式的向用户征求授权。 官方版流程 ​ （A）用户打开客户端以后，客户端要求用户给予授权。 （B）用户同意给予客户端授权。 （C）客户端使用上一步获得的授权，向认证服务器申请令牌。 （D）认证服务器对客户端进行认证以后，确认无误，同意发放令牌。 （E）客户端使用令牌，向资源服务器申请获取资源。 （F）资源服务器确认令牌无误，同意向客户端开放资源。 社交登录的步骤1）、给页面放一个社交登录按钮，点击地址是 &lt;微博登录 2）、用户只要授权通过了，会自动跳转到我们指定的http://www.gulishop.com/success，会给url后面带一个code=xxxxxxxx 3）、拿到这个code发送请求换取access_token即可。 4）、拿到access_token可以调用所有的开放api； https://open.weibo.com/apps/771268000/privilege 你可以用户的信息都保存自己的网站。 核心： code一次性的，只要用过就作废。 access_token：是固定的，一段时间完全固定。 uid：是永远固定的。 我们自己的系统如何标识唯一用户，就是使用社交网站的uid。 购物车将购物车存在Redis，用Hash数据结构。 Hash是一个map,如下图。skuId代表库存商品编号 购物车分两种： 1.在线购物车，用户已经登录，生成一个access_token作为key 2.离线购物车，用户未登录，cart-key = uuid 1）、购物车数据保存在redis中，使用分布式集合；【redisson.getMap】 2）、用户对于购物车的所有操作，都需要传入cart-key，如果用户登录了，还需要传入token 购物车需要提供的所有方法； 1）、添加到购物车 2）、修改购物项 3）、删除购物项 4）、选中/选不中购物项 5）、返回整个购物车 6）、点击去结算-获取购物车中需要结算的数据 技术： 1）、分布式集合 2）、JSON.parseObject(str, new TypeReference&lt;Set&gt;() { });]]></content>
  </entry>
  <entry>
    <title><![CDATA[分布式锁与缓存]]></title>
    <url>%2F2020%2F05%2F07%2F%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E4%B8%8E%E7%BC%93%E5%AD%98%2F</url>
    <content type="text"><![CDATA[Redis实现分布式锁单机模式下，Synchronized和ReetrantLock都可以很好的处理锁问题，即使有多用户并发请求也可以运行正常。 但是，在分布式下，这些锁都会失效。（分布式下以前的所有锁都不能用，分布式系统JVM都是互不相关的，加不上同一把锁） 一般采用redis来实现分布式锁。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127/** * * setnx-&gt;set if not exist：原子操作。判断带保存。 * *1）、代码第一阶段； * public void hello()&#123; * * //获取和设置值必须是原子的 * String lock = getFromRedis("lock");//get("lock") * if(lock == null)&#123; * setRedisKey("lock","1"); * //执行业务 * delRedisKey("lock") * return ; * &#125;else&#123; * hello();//自旋 * &#125; * &#125; * //问题：加锁的原子性 * * 2、代码第二阶段 * public void hello()&#123; * //1、获取到锁 * Integer lock = setnx("lock',"111"); //0代表没有保存数据，说明已经有人占了。1代表占可坑成功 * if(lock!=0)&#123; * //执行业务逻辑 * //释放锁、删除锁 * del("lock") * &#125;else&#123; * //等待重试 * hello(); * &#125; * &#125; * //问题：如果由于各种问题（未捕获的异常、断电等）导致锁没释放。其他人永远获取不到锁。 * //解决：加个过期时间。 * * 3、代码第三阶段 * public void hello()&#123; * //超时和加锁必须原子 * Integer lock = setnx("lock',"111"); * if(lock!=null)&#123; * expire("lock",10s);//设置过期时间 * //执行业务逻辑 * // 释放锁 * del("lock') * &#125;else&#123; * hello(); * &#125; * * &#125; * 问题：刚拿到锁，机器炸了，没来得及设置超时。 * 解决：加锁和加超时也必须是原子的。 * * * 4、代码第四阶段： * public void hello()&#123; * String result = setnxex("lock","111",10s); * if(result=="ok")&#123; * //加锁成功 * //执行业务逻辑 * del("lock") * &#125;else&#123; * hello(); * &#125; * &#125; * 问题：如果业务逻辑超时，导致锁自动删除，业务执行完又删除一遍。至少多个人都获取到了锁。 * * 5、代码第五阶段。 * public void hello()&#123; * String token = UUID; * String result = setnxex("lock",token,10s); * if(result == "ok")&#123; * //执行业务 * * //删锁，保证删除自己的锁 * if(get("lock")==token)&#123; * del("lock") * &#125; * &#125;else&#123; * hello(); * &#125; * &#125; * 问题？：我们获取锁的时候，锁的值正在给我们返回。锁过期。redis删除了锁。 * 但是我们拿到了值，而且对比成功（此时此刻正好有人又获取）。我们还删除了锁。至少两个线程又进入同一个代码。 * 原因：？删锁不是原子。 * lua脚本。 * * 解决： * String script = * "if redis.call('get', KEYS[1]) == ARGV[1] then * return redis.call('del', KEYS[1]) * else * return 0 * end"; * * jedis.eval(script, Collections.singletonList(key), Collections.singletonList(token)); * * lua脚本进行删除。 * * * 1）、分布式锁的核心（保证原子性） * 1）、加锁。占坑一定要是原子的。（判断如果没有，就给redis中保存值） * 2）、锁要自动超时。 * 3）、解锁也要原子。 * * * 最终的分布式锁的代码：大家都去redis中占同一个坑。 * * * * @Lock * public void hello()&#123; * String token = uuid; * String lock = redis.setnxex("lock",token,10s); * if(lock=="ok")&#123; * //执行业务逻辑 * //脚本删除锁 * &#125;else&#123; * hello();//自旋。 * &#125; * &#125; * * AOP;上面的@Lock注解， * * RedisTemplate和Jedis客户端2选一 * */ RedissonRedisson是一个在Redis的基础上实现的Java驻内存数据网格（In-Memory Data Grid）。它不仅提供了一系列的分布式的Java常用对象，还提供了许多分布式服务。其中包括(BitSet, Set, Multimap, SortedSet, Map, List, Queue, BlockingQueue, Deque, BlockingDeque, Semaphore, Lock, AtomicLong, CountDownLatch, Publish / Subscribe, Bloom filter, Remote service, Spring cache, Executor service, Live Object service, Scheduler service) 基于Redis的Redisson分布式可重入锁RLock Java对象实现了java.util.concurrent.locks.Lock接口。 1234567891011121314151617RLock lock = redisson.getLock("anyLock");// 最常见的使用方法lock.lock();//大家都知道，如果负责储存这个分布式锁的Redisson节点宕机以后，而且这个锁正好处于锁住的状态时，这个锁会出现锁死的状态。// 加锁以后10秒钟自动解锁// 无需调用unlock方法手动解锁lock.lock(10, TimeUnit.SECONDS);// 尝试加锁，最多等待100秒，上锁以后10秒自动解锁boolean res = lock.tryLock(100, 10, TimeUnit.SECONDS);if (res) &#123; try &#123; ... &#125; finally &#123; lock.unlock(); &#125;&#125; 读写锁基于Redis的Redisson分布式可重入读写锁RReadWriteLock Java对象实现了java.util.concurrent.locks.ReadWriteLock接口。其中读锁和写锁都继承了RLock接口。 分布式可重入读写锁允许同时有多个读锁和一个写锁处于加锁状态。 12345RReadWriteLock rwlock = redisson.getReadWriteLock("anyRWLock");// 最常见的使用方法rwlock.readLock().lock();//一般会设置过期时间// 或rwlock.writeLock().lock(); 缓存1.问题：查询效率高，数据变化频率不是太快的。我们进缓存。如何让缓存和数据库同步？ 答： 写场景：更新数据库成功后，同步更新缓存； 读场景：先从缓存中读，没有再从数据库读，放入缓存。 你只要用缓存，就可能会涉及到缓存与数据库双存储双写，你只要是双写，就一定会有数据一致性的问题，那么你如何解决一致性问题？ 1）：一般来说，如果允许缓存可以稍微的跟数据库偶尔有不一致的情况，也就是说如果你的系统不是严格要求 “缓存+数据库” 必须保持一致性的话，最好不要做这个方案，即：读请求和写请求串行化，串到一个内存队列里去。 2）：可以用个读写锁。 性能慢，可以用粒度细点的锁。 （以上仅为雷丰阳个人观点，以下为博客观点） 如何解决缓存与数据库不一致？读取缓存步骤一般没有什么问题，但是一旦涉及到数据更新：数据库和缓存更新，就容易出现缓存和数据库间的数据一致性问题。不管是先写数据库，再删除缓存；还是先删除缓存，再写库，都有可能出现数据不一致的情况。举个例子： 1.如果删除了缓存Redis，还没有来得及写库MySQL，另一个线程就来读取，发现缓存为空，则去数据库中读取数据写入缓存，此时缓存中为脏数据。 2.如果先写了库，在删除缓存前，写库的线程宕机了，没有删除掉缓存，则也会出现数据不一致情况。 1.延时双删策略 在写库前后都进行redis.del(key)操作，并且设定合理的超时时间。具体步骤是： ​ 1）先删除缓存 ​ 2）再写数据库 ​ 3）休眠500毫秒（根据具体的业务时间来定） ​ 4）再次删除缓存。 那么，这个500毫秒怎么确定的，具体该休眠多久呢？ ​ 需要评估自己的项目的读数据业务逻辑的耗时。这么做的目的，就是确保读请求结束（读到旧数据的请求），写请求可以删除读请求造成的缓存脏数据。 设置缓存过期时间 从理论上来说，给缓存设置过期时间，是保证最终一致性的解决方案。所有的写操作以数据库为准，只要到达缓存过期时间，则后面的读请求自然会从数据库中读取新值然后回填缓存。 该方案的弊端 结合双删策略+缓存超时设置，这样最差的情况就是在超时时间内数据存在不一致（双删失败的情况），而且又增加了写请求的耗时 2.异步更新缓存(基于订阅binlog的同步机制) MySQL binlog增量订阅消费+消息队列+增量数据更新到redis 读Redis：热数据基本都在Redis 写MySQL:增删改都是操作MySQL 更新Redis数据：MySQ的数据操作binlog，来更新到Redis (1）数据操作主要分为两大块： 一个是全量(将全部数据一次写入到redis) 一个是增量（实时更新） 这里说的是增量,指的是mysql的update、insert、delate变更数据。 (2）读取binlog后分析 ，利用消息队列,推送更新各台的redis缓存数据。 这样一旦MySQL中产生了新的写入、更新、删除等操作，就可以把binlog相关的消息推送至Redis，Redis再根据binlog中的记录，对Redis进行更新。 Redis和ElasticSearchredis优缺点 1、redis最大特点是key-value存储，简单且性能高 一种key-value数据库中功能最全，最简单易用的款。2、redis会把所有数据加载到内存中。2、redis还支持数据持久化，list，set等多种数据结构，master-slave 复制备份。 redis缺点： 1、由于去掉了表字段，所有查询都用来key， 所以无法支持常规的多列查询，区段查询。2、由于Redis需要把数据存在内存中，这也大大限制了Redis可存储的数据量，这也决定了Redis难以用在数据规模很大的应用场景中 ES(ElasticSearch)ES：ElasticSearch 是一个分布式、高扩展、高实时的搜索与数据分析引擎。严格来说，他不是一个数据库，是个搜索引擎,即搜索服务器。es提供了一种分布式多用户能力的全文搜索引擎。 Elasticsearch是分布式的，这意味着索引可以被分成分片，每个分片可以有0个或多个副本。每个节点托管一个或多个分片，并充当协调器将操作委托给正确的分片。再平衡和路由是自动完成的。“相关数据通常存储在同一个索引中，该索引由一个或多个主分片和零个或多个复制分片组成。一旦创建了索引，就不能更改主分片的数量。 优点：能够达到实时搜索，稳定，可靠，快速，安装使用方便 缺点：也有很多，自己查 redis和ElasticSearch的区别 分布式事务CAP定理：Consistency（一致性）, Availability（可用性）和Partition tolerance（分区容错）这三个指标不可能同时做到。 分区容错的意思是，区间通信可能失败。比如，一台服务器放在中国，另一台服务器放在美国，这就是两个区，它们之间可能无法通信。一般来说，分区容错无法避免，因此可以认为 CAP 的 P 总是成立。CAP 定理告诉我们，剩下的 C 和 A 无法同时做到。（要么是CP, 要么是AP） Consistency 和 Availability 的矛盾 一致性和可用性，为什么不可能同时成立？答案很简单，因为可能通信失败（即出现分区容错）。 如果保证 P2 的一致性，那么 P1 必须在写操作时，锁定 P2 的读操作和写操作。只有数据同步后，才能重新开放读写。锁定期间，P2 不能读写，没有可用性不。 如果保证 P2 的可用性，那么势必不能锁定 P2，所以一致性不成立。 BASE理论BA：Basically Available 基本可用，分布式系统在出现故障的时候，允许损失部分可用性，即保证核心可用。S：Soft State 软状态，允许系统存在中间状态，而该中间状态不会影响系统整体可用性。E：Consistency 最终一致性，系统中的所有数据副本经过一定时间后，最终能够达到一致的状态。BASE 理论本质上是对 CAP 理论的延伸，是对 CAP 中 AP 方案的一个补充。 TCC(Try Confirm Cancel)Try阶段：尝试执行，预留业务资源。（eg: 库存表本来只有一个库存数字段，TCC方案可以多给他一个冻结库存数字段。本来商品库存为10，在用户下单完成支付这个流程中，假设买了一个商品，原来的逻辑就得改一下。正常正常你买1个商品，那库存就是10-1=9 咯，所以将库存数改为9。而在TCC下，你就不将他改为9，而是在冻结库存数上+1，即数据库状态变为 库存数10，冻结库存数1、那么在其他的用户购买时，你返回给前端的库存数应该就是 库存数10 减去 冻结库存数1 等于现在只有9个库存能够被使用。） Confirm阶段：确认。将库存字段真正减掉，也就是将10库存真正减1。 Cancel阶段：回滚。 如何实现接口幂等性创建订单时，第一次调用服务超时，再次调用是否产生两笔订单？ 订单支付时，服务端扣钱成功，但是接口反馈超时，此时再次调用支付，是否会多扣一笔呢？ 服务方需要使用幂等的方式保证一次和多次的请求结果一致！ 实验方式： 1.数据库去重表 在往数据库中插入数据的时候，利用数据库唯一索引特性，保证数据唯一。比如订单的流水号，也可以是多个字段的组合。 2.TOKEN机制 针对客户端连续点击或者调用方的超时重试等情况，例如提交订单，此种操作就可以用Token的机制实现防止重复提交。 主要的流程步骤如下： 客户端先发送获取token的请求，服务端会生成一个全局唯一的ID保存在redis中，同时把这个ID返回给客户端。 客户端调用业务请求的时候必须携带这个token，一般放在请求头上。 服务端会校验这个Token，如果校验成功，则执行业务。 如果校验失败，则表示重复操作，直接返回指定的结果给客户端。 通过以上的流程分析，唯一的重点就是这个全局唯一ID如何生成，在分布式服务中往往都会有一个生成全局ID的服务来保证ID的唯一性，但是工程量和实现难度比较大，UUID的数据量相对有些大，此处陈某选择的是雪花算法生成全局唯一ID，不了解雪花算法的读者下一篇文章会着重介绍。]]></content>
  </entry>
  <entry>
    <title><![CDATA[全排列]]></title>
    <url>%2F2020%2F05%2F01%2F%E5%85%A8%E6%8E%92%E5%88%97%2F</url>
    <content type="text"><![CDATA[给定一个 没有重复 数字的序列，返回其所有可能的全排列。 示例: 输入: [1,2,3]输出:[ [1,2,3], [1,3,2], [2,1,3], [2,3,1], [3,1,2], [3,2,1]]链接：https://leetcode-cn.com/problems/permutations 回溯法 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647class Solution &#123; public List&lt;List&lt;Integer&gt;&gt; permute(int[] nums)&#123; int len = nums.length; List&lt;List&lt;Integer&gt;&gt; res = new ArrayList&lt;&gt;(); if(len==0)&#123; return res; &#125; Deque&lt;Integer&gt; path = new ArrayDeque&lt;&gt;(); boolean[] used = new boolean[len]; dfs(nums,len,0,path,used,res); return res; &#125; private void dfs(int[] nums, int len, int depth, Deque&lt;Integer&gt; path, boolean[] used, List&lt;List&lt;Integer&gt;&gt; res) &#123; if(depth == len)//递归终止条件 &#123; res.add(new ArrayList&lt;&gt;(path)); return;//不执行下面的逻辑 &#125; for(int i=0; i&lt;len; i++)&#123; if(used[i]) continue; path.addLast(nums[i]); used[i] = true; dfs(nums, len, depth+1, path, used, res);//dfs一定要写在for循环里面。。。。 //回溯。。。。前面操作干了什么，就要反操作 path.removeLast(); used[i] = false; &#125; /*这样写是错的。他只会返回一个结果。。。 for(int i=0; i&lt;len; i++)&#123; if(used[i]) continue; path.addLast(nums[i]); used[i] = true; break; &#125; dfs(nums, len, depth+1, path, used, res);//dfs一定要写在for循环里面。。。。 //回溯。。。。 path.removeLast(); used[i] = false; */ &#125;&#125;]]></content>
  </entry>
  <entry>
    <title><![CDATA[ElasticSearch]]></title>
    <url>%2F2020%2F05%2F01%2FElasticSearch%2F</url>
    <content type="text"><![CDATA[Elasticsearch是一个分布式的开源搜索和分析引擎。全文检索属于最常见的需求，开源的Elasticsearch是目前全文搜索引擎的首选。它可以快速地存储，搜索和分析海量数据。 MySQL主要还是存储，持久化。CRUD。 Index（索引）—–数据库 动词，相当于MySQL中的insert； 名词，相当于MySQL中的Database Type（类型）—–表 在 Index（索引）中，可以定义一个或多个类型。 类似于MySQL中的Table；每一种类型的数据放在一起； Document（文档） 保存在某个索引（Index）下，某种类型（Type）下的一个数据（Document），文档是JSON格式。 索引一个文档保存一个数据，保存在哪个索引的哪个类型下，指定用哪个唯一标识 PUT customer/external/1 { “name”: “John Doe” }； 在customer索引下的external类型下保存1号数据为{ “name”: “John Doe” } ​ PUT和POST都可以， POST新增。如果不指定id，会自动生成id。指定id就会修改这个数据，并新增版本号。 PUT必须指定id；由于PUT需要指定id，我们一般都用来做修改操作，不指定id会报错。 倒排索引 插入时会维护一个倒排索引。先分词，在每个词都维护索引。 ElasticSearch相关知识 1.ElasticSearch复习点击下载]]></content>
  </entry>
  <entry>
    <title><![CDATA[五月天1]]></title>
    <url>%2F2020%2F05%2F01%2F%E4%BA%94%E6%9C%88%E5%A4%A91%2F</url>
    <content type="text"><![CDATA[Dubbo框架图 Dubbo集群容错使用：在@Service注解上 Failover(失败自动切换) Failsafe(失败安全) Failfast(快速失败) Failback(失败自动恢复) Forking(并行调用) Broadcast(广播调用) sharding-jdbc实现读写分离 事务的传播机制REQUIRED（默认）：支持使用当前事务，如果当前事务不存在，创建一个新事务。SUPPORTS：支持使用当前事务，如果当前事务不存在，则不使用事务。MANDATORY：中文翻译为强制，支持使用当前事务，如果当前事务不存在，则抛出Exception。REQUIRES_NEW：创建一个新事务，如果当前事务存在，把当前事务挂起。NOT_SUPPORTED：无事务执行，如果当前事务存在，把当前事务挂起。NEVER：无事务执行，如果当前有事务则抛出Exception。NESTED：嵌套事务（事务里开启一个事务），如果当前事务存在，那么在嵌套的事务中执行。如果当前事务不存在，创建一个新事物。 例子 1234567外事务&#123; A();//事务.Required: 跟着回滚,和外事务是一个事务 B();//事务.Requires_new: 不会滚，创建了一个新事物 //给数据库插入数据 int i = 10/0;&#125;]]></content>
  </entry>
  <entry>
    <title><![CDATA[约瑟夫环题解]]></title>
    <url>%2F2020%2F04%2F30%2F%E7%BA%A6%E7%91%9F%E5%A4%AB%E7%8E%AF%E9%A2%98%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[问题描述：编号为 1-N 的 N 个士兵围坐在一起形成一个圆圈，从编号为 1 的士兵开始依次报数（1，2，3…这样依次报），数到 m 的 士兵会被杀死出列，之后的士兵再从 1 开始报数。直到最后剩下一士兵，求这个士兵的编号。 1.方法一:数组 用一个数组来存放 1，2，3 … n 这 n 个编号，出局可以用-1标记。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public class Main01 &#123; public static void main(String[] args) &#123; fun1(11,3);&#125; public static void fun1(int n, int m)&#123; int[] array = new int[n];//定义数组存放最开始的顺序1,2,3...n for(int i=1;i&lt;=n;i++)&#123; array[i-1]=i; &#125; print_array(array); int taotai=0;//当前淘汰人数 int current=0;//当前下标，从0开始 while(taotai!=n-1)&#123;//淘汰人数等于十个人的时候退出循环 int move=1;//向后移动次数,默认已经在第一位 while(move!=m)&#123; current=move_forward(array,current);//向后移动一位 move++; &#125; taotai++; array[current]=-1; current = move_forward(array,current);//淘汰current位置后，到第一个位置 print_array(array); &#125; &#125; private static int move_forward(int[] array, int current) &#123;//向后报数一位 current++; if(current==array.length)&#123;// current=0; &#125; while(array[current]==-1)&#123;//已经出局 current=move_forward(array,current); &#125; return current; &#125; public static void print_array(int[] nums)&#123;//打印数组 for(int num:nums)&#123; System.out.print(num+" "); &#125; System.out.println(); &#125;&#125; 2.方法二：用循环链表模拟，出局直接移除该链表节点。 3.方法三：递推公式 递推公式： f(N,M)=(f(N−1,M)+M)%N f(N,M) 表示，N个人报数，每报到M时杀掉那个人，最终胜利者的编号 f(N−1,M)表示，N-1个人报数，每报到M时杀掉那个人，最终胜利者的编号 将上面表格的每一行看成数组，这个公式描述的是：幸存者在这一轮的下标位置 f(1,3)=0：只有1个人了，那个人就是获胜者，他的下标位置是0 f(2,3)=(f(1,3)+3)%2=3%2=1：在有2个人的时候，胜利者的下标位置为1 f(3,3)=(f(2,3)+3)%3=4%3=1：在有3个人的时候，胜利者的下标位置为1 f(4,3)=(f(3,3)+3)%4=4%4=0：在有4个人的时候，胜利者的下标位置为0 …… f(11,3)=6 很神奇吧！现在你还怀疑这个公式的正确性吗？上面这个例子验证了这个递推公式的确可以计算出胜利者的下标，下面将讲解怎么推导这个公式。 问题1：假设我们已经知道11个人时，胜利者的下标位置为6。那下一轮10个人时，胜利者的下标位置为多少？答：其实吧，第一轮删掉编号为3的人后，之后的人都往前面移动了3位，胜利这也往前移动了3位，所以他的下标位置由6变成3。 问题2：假设我们已经知道10个人时，胜利者的下标位置为3。那下一轮11个人时，胜利者的下标位置为多少？答：这可以看错是上一个问题的逆过程，大家都往后移动3位，所以f(11,3)=f(10,3)+3。不过有可能数组会越界，所以最后模上当前人数的个数，f(11,3)=（f(10,3)+3）%11 问题3：现在改为人数改为N，报到M时，把那个人杀掉，那么数组是怎么移动的？答：每杀掉一个人，下一个人成为头，相当于把数组向前移动M位。若已知N-1个人时，胜利者的下标位置位f(N−1,M)f(N−1,M)，则N个人的时候，就是往后移动M为，(因为有可能数组越界，超过的部分会被接到头上，所以还要模N)，既f(N,M)=(f(N−1,M)+M)%N 注：理解这个递推式的核心在于关注胜利者的下标位置是怎么变的。每杀掉一个人，其实就是把这个数组向前移动了M位。然后逆过来，就可以得到这个递推式。]]></content>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot]]></title>
    <url>%2F2020%2F04%2F02%2FSpringBoot%2F</url>
    <content type="text"><![CDATA[一、Spring Boot 入门1、Spring Boot 简介 简化Spring应用开发的一个框架； 整个Spring技术栈的一个大整合； J2EE开发的一站式解决方案； 2、微服务2014，martin fowler 微服务：架构风格（服务微化） 一个应用应该是一组小型服务；可以通过HTTP的方式进行互通； 单体应用：ALL IN ONE 微服务：每一个功能元素最终都是一个可独立替换和独立升级的软件单元； 详细参照微服务文档 3、环境准备http://www.gulixueyuan.com/ 谷粒学院 环境约束 –jdk1.8：Spring Boot 推荐jdk1.7及以上；java version “1.8.0_112” –maven3.x：maven 3.3以上版本；Apache Maven 3.3.9 –IntelliJIDEA2017：IntelliJ IDEA 2017.2.2 x64、STS –SpringBoot 1.5.9.RELEASE：1.5.9； 统一环境； 1、MAVEN设置；给maven 的settings.xml配置文件的profiles标签添加 123456789101112&lt;profile&gt; &lt;id&gt;jdk-1.8&lt;/id&gt; &lt;activation&gt; &lt;activeByDefault&gt;true&lt;/activeByDefault&gt; &lt;jdk&gt;1.8&lt;/jdk&gt; &lt;/activation&gt; &lt;properties&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;maven.compiler.compilerVersion&gt;1.8&lt;/maven.compiler.compilerVersion&gt; &lt;/properties&gt;&lt;/profile&gt; 2、IDEA设置整合maven进来； 4、Spring Boot HelloWorld一个功能： 浏览器发送hello请求，服务器接受请求并处理，响应Hello World字符串； 1、创建一个maven工程；（jar）2、导入spring boot相关的依赖1234567891011&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.5.9.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 3、编写一个主程序；启动Spring Boot应用123456789101112/** * @SpringBootApplication 来标注一个主程序类，说明这是一个Spring Boot应用 */@SpringBootApplicationpublic class HelloWorldMainApplication &#123; public static void main(String[] args) &#123; // Spring应用启动起来 SpringApplication.run(HelloWorldMainApplication.class,args); &#125;&#125; 4、编写相关的Controller、Service123456789@Controllerpublic class HelloController &#123; @ResponseBody @RequestMapping("/hello") public String hello()&#123; return "Hello World!"; &#125;&#125; 5、运行主程序测试6、简化部署123456789&lt;!-- 这个插件，可以将应用打包成一个可执行的jar包；--&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; 将这个应用打成jar包，直接使用java -jar的命令进行执行； 5、Hello World探究1、POM文件1、父项目1234567891011121314&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.5.9.RELEASE&lt;/version&gt;&lt;/parent&gt;他的父项目是&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt; &lt;version&gt;1.5.9.RELEASE&lt;/version&gt; &lt;relativePath&gt;../../spring-boot-dependencies&lt;/relativePath&gt;&lt;/parent&gt;他来真正管理Spring Boot应用里面的所有依赖版本； Spring Boot的版本仲裁中心； 以后我们导入依赖默认是不需要写版本；（没有在dependencies里面管理的依赖自然需要声明版本号） 2、启动器1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt; spring-boot-starter-==web==： ​ spring-boot-starter：spring-boot场景启动器；帮我们导入了web模块正常运行所依赖的组件； Spring Boot将所有的功能场景都抽取出来，做成一个个的starters（启动器），只需要在项目里面引入这些starter相关场景的所有依赖都会导入进来。要用什么功能就导入什么场景的启动器 2、主程序类，主入口类123456789101112/** * @SpringBootApplication 来标注一个主程序类，说明这是一个Spring Boot应用 */@SpringBootApplicationpublic class HelloWorldMainApplication &#123; public static void main(String[] args) &#123; // Spring应用启动起来 SpringApplication.run(HelloWorldMainApplication.class,args); &#125;&#125; @SpringBootApplication: Spring Boot应用标注在某个类上说明这个类是SpringBoot的主配置类，SpringBoot就应该运行这个类的main方法来启动SpringBoot应用； 12345678910@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@SpringBootConfiguration@EnableAutoConfiguration@ComponentScan(excludeFilters = &#123; @Filter(type = FilterType.CUSTOM, classes = TypeExcludeFilter.class), @Filter(type = FilterType.CUSTOM, classes = AutoConfigurationExcludeFilter.class) &#125;)public @interface SpringBootApplication &#123; @SpringBootConfiguration:Spring Boot的配置类； ​ 标注在某个类上，表示这是一个Spring Boot的配置类； ​ @Configuration:配置类上来标注这个注解； ​ 配置类 —– 配置文件；配置类也是容器中的一个组件；@Component @EnableAutoConfiguration：开启自动配置功能； ​ 以前我们需要配置的东西，Spring Boot帮我们自动配置；@EnableAutoConfiguration告诉SpringBoot开启自动配置功能；这样自动配置才能生效； 123@AutoConfigurationPackage@Import(EnableAutoConfigurationImportSelector.class)public @interface EnableAutoConfiguration &#123; ​ @AutoConfigurationPackage：自动配置包 ​ @Import(AutoConfigurationPackages.Registrar.class)： ​ Spring的底层注解@Import，给容器中导入一个组件；导入的组件由AutoConfigurationPackages.Registrar.class； ==将主配置类（@SpringBootApplication标注的类）的所在包及下面所有子包里面的所有组件扫描到Spring容器；== ​ @Import(EnableAutoConfigurationImportSelector.class)； ​ 给容器中导入组件？ ​ EnableAutoConfigurationImportSelector：导入哪些组件的选择器； ​ 将所有需要导入的组件以全类名的方式返回；这些组件就会被添加到容器中； ​ 会给容器中导入非常多的自动配置类（xxxAutoConfiguration）；就是给容器中导入这个场景需要的所有组件，并配置好这些组件； 有了自动配置类，免去了我们手动编写配置注入功能组件等的工作； ​ SpringFactoriesLoader.loadFactoryNames(EnableAutoConfiguration.class,classLoader)； ==Spring Boot在启动的时候从类路径下的META-INF/spring.factories中获取EnableAutoConfiguration指定的值，将这些值作为自动配置类导入到容器中，自动配置类就生效，帮我们进行自动配置工作；==以前我们需要自己配置的东西，自动配置类都帮我们； J2EE的整体整合解决方案和自动配置都在spring-boot-autoconfigure-1.5.9.RELEASE.jar； ​ ==Spring注解版（谷粒学院）== 6、使用Spring Initializer快速创建Spring Boot项目1、IDEA：使用 Spring Initializer快速创建项目IDE都支持使用Spring的项目创建向导快速创建一个Spring Boot项目； 选择我们需要的模块；向导会联网创建Spring Boot项目； 默认生成的Spring Boot项目； 主程序已经生成好了，我们只需要我们自己的逻辑 resources文件夹中目录结构 static：保存所有的静态资源； js css images； templates：保存所有的模板页面；（Spring Boot默认jar包使用嵌入式的Tomcat，默认不支持JSP页面）；可以使用模板引擎（freemarker、thymeleaf）； application.properties：Spring Boot应用的配置文件；可以修改一些默认设置； 2、STS使用 Spring Starter Project快速创建项目 二、配置文件1、配置文件SpringBoot使用一个全局的配置文件，配置文件名是固定的； •application.properties •application.yml 配置文件的作用：修改SpringBoot自动配置的默认值；SpringBoot在底层都给我们自动配置好； YAML（YAML Ain’t Markup Language） ​ YAML A Markup Language：是一个标记语言 ​ YAML isn’t Markup Language：不是一个标记语言； 标记语言： ​ 以前的配置文件；大多都使用的是 xxxx.xml文件； ​ YAML：以数据为中心，比json、xml等更适合做配置文件； ​ YAML：配置例子 12server: port: 8081 ​ XML： 123&lt;server&gt; &lt;port&gt;8081&lt;/port&gt;&lt;/server&gt; 2、YAML语法：1、基本语法k:(空格)v：表示一对键值对（空格必须有）； 以空格的缩进来控制层级关系；只要是左对齐的一列数据，都是同一个层级的 123server: port: 8081 path: /hello 属性和值也是大小写敏感； 2、值的写法字面量：普通的值（数字，字符串，布尔）​ k: v：字面直接来写； ​ 字符串默认不用加上单引号或者双引号； ​ “”：双引号；不会转义字符串里面的特殊字符；特殊字符会作为本身想表示的意思 ​ name: “zhangsan \n lisi”：输出；zhangsan 换行 lisi ​ ‘’：单引号；会转义特殊字符，特殊字符最终只是一个普通的字符串数据 ​ name: ‘zhangsan \n lisi’：输出；zhangsan \n lisi 对象、Map（属性和值）（键值对）：​ k: v：在下一行来写对象的属性和值的关系；注意缩进 ​ 对象还是k: v的方式 123friends: lastName: zhangsan age: 20 行内写法： 1friends: &#123;lastName: zhangsan,age: 18&#125; 数组（List、Set）：用- 值表示数组中的一个元素 1234pets: - cat - dog - pig 行内写法 1pets: [cat,dog,pig] 3、配置文件值注入配置文件 123456789101112person: lastName: hello age: 18 boss: false birth: 2017/12/12 maps: &#123;k1: v1,k2: 12&#125; lists: - lisi - zhaoliu dog: name: 小狗 age: 12 javaBean： 1234567891011121314151617181920/** * 将配置文件中配置的每一个属性的值，映射到这个组件中 * @ConfigurationProperties：告诉SpringBoot将本类中的所有属性和配置文件中相关的配置进行绑定； * prefix = "person"：配置文件中哪个下面的所有属性进行一一映射 * * 只有这个组件是容器中的组件，才能容器提供的@ConfigurationProperties功能； * */@Component@ConfigurationProperties(prefix = "person")public class Person &#123; private String lastName; private Integer age; private Boolean boss; private Date birth; private Map&lt;String,Object&gt; maps; private List&lt;Object&gt; lists; private Dog dog; 我们可以导入配置文件处理器，以后编写配置就有提示了 123456&lt;!--导入配置文件处理器，配置文件进行绑定就会有提示--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-configuration-processor&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; 1、properties配置文件在idea中默认utf-8可能会乱码调整 2、@Value获取值和@ConfigurationProperties获取值比较 @ConfigurationProperties @Value 功能 批量注入配置文件中的属性 一个个指定 松散绑定（松散语法） 支持 不支持 SpEL 不支持 支持 JSR303数据校验 支持 不支持 复杂类型封装 支持 不支持 配置文件yml还是properties他们都能获取到值； 如果说，我们只是在某个业务逻辑中需要获取一下配置文件中的某项值，使用@Value； 如果说，我们专门编写了一个javaBean来和配置文件进行映射，我们就直接使用@ConfigurationProperties； 3、配置文件注入值数据校验123456789101112131415161718192021222324@Component@ConfigurationProperties(prefix = "person")@Validatedpublic class Person &#123; /** * &lt;bean class="Person"&gt; * &lt;property name="lastName" value="字面量/$&#123;key&#125;从环境变量、配置文件中获取值/#&#123;SpEL&#125;"&gt;&lt;/property&gt; * &lt;bean/&gt; */ //lastName必须是邮箱格式 @Email //@Value("$&#123;person.last-name&#125;") private String lastName; //@Value("#&#123;11*2&#125;") private Integer age; //@Value("true") private Boolean boss; private Date birth; private Map&lt;String,Object&gt; maps; private List&lt;Object&gt; lists; private Dog dog; 4、@PropertySource&amp;@ImportResource&amp;@Bean@PropertySource：加载指定的配置文件； 1234567891011121314151617181920212223242526272829/** * 将配置文件中配置的每一个属性的值，映射到这个组件中 * @ConfigurationProperties：告诉SpringBoot将本类中的所有属性和配置文件中相关的配置进行绑定； * prefix = "person"：配置文件中哪个下面的所有属性进行一一映射 * * 只有这个组件是容器中的组件，才能容器提供的@ConfigurationProperties功能； * @ConfigurationProperties(prefix = "person")默认从全局配置文件中获取值； * */@PropertySource(value = &#123;"classpath:person.properties"&#125;)@Component@ConfigurationProperties(prefix = "person")//@Validatedpublic class Person &#123; /** * &lt;bean class="Person"&gt; * &lt;property name="lastName" value="字面量/$&#123;key&#125;从环境变量、配置文件中获取值/#&#123;SpEL&#125;"&gt;&lt;/property&gt; * &lt;bean/&gt; */ //lastName必须是邮箱格式 // @Email //@Value("$&#123;person.last-name&#125;") private String lastName; //@Value("#&#123;11*2&#125;") private Integer age; //@Value("true") private Boolean boss; @ImportResource：导入Spring的配置文件，让配置文件里面的内容生效； Spring Boot里面没有Spring的配置文件，我们自己编写的配置文件，也不能自动识别； 想让Spring的配置文件生效，加载进来；@ImportResource标注在一个配置类上 12@ImportResource(locations = &#123;"classpath:beans.xml"&#125;)导入Spring的配置文件让其生效 不来编写Spring的配置文件 12345678&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd"&gt; &lt;bean id="helloService" class="com.atguigu.springboot.service.HelloService"&gt;&lt;/bean&gt;&lt;/beans&gt; SpringBoot推荐给容器中添加组件的方式；推荐使用全注解的方式 1、配置类@Configuration——&gt;Spring配置文件 2、使用@Bean给容器中添加组件 12345678910111213141516/** * @Configuration：指明当前类是一个配置类；就是来替代之前的Spring配置文件 * * 在配置文件中用&lt;bean&gt;&lt;bean/&gt;标签添加组件 * */@Configurationpublic class MyAppConfig &#123; //将方法的返回值添加到容器中；容器中这个组件默认的id就是方法名 @Bean public HelloService helloService02()&#123; System.out.println("配置类@Bean给容器中添加组件了..."); return new HelloService(); &#125;&#125; ##4、配置文件占位符 1、随机数12$&#123;random.value&#125;、$&#123;random.int&#125;、$&#123;random.long&#125;$&#123;random.int(10)&#125;、$&#123;random.int[1024,65536]&#125; 2、占位符获取之前配置的值，如果没有可以是用:指定默认值123456789person.last-name=张三$&#123;random.uuid&#125;person.age=$&#123;random.int&#125;person.birth=2017/12/15person.boss=falseperson.maps.k1=v1person.maps.k2=14person.lists=a,b,cperson.dog.name=$&#123;person.hello:hello&#125;_dogperson.dog.age=15 5、Profile1、多Profile文件我们在主配置文件编写的时候，文件名可以是 application-{profile}.properties/yml 默认使用application.properties的配置； 2、yml支持多文档块方式12345678910111213141516171819server: port: 8081spring: profiles: active: prod---server: port: 8083spring: profiles: dev---server: port: 8084spring: profiles: prod #指定属于哪个环境 3、激活指定profile​ 1、在配置文件中指定 spring.profiles.active=dev ​ 2、命令行： ​ java -jar spring-boot-02-config-0.0.1-SNAPSHOT.jar –spring.profiles.active=dev； ​ 可以直接在测试的时候，配置传入命令行参数 ​ 3、虚拟机参数； ​ -Dspring.profiles.active=dev 6、配置文件加载位置springboot 启动会扫描以下位置的application.properties或者application.yml文件作为Spring boot的默认配置文件 –file:./config/ –file:./ –classpath:/config/ –classpath:/ 优先级由高到底，高优先级的配置会覆盖低优先级的配置； SpringBoot会从这四个位置全部加载主配置文件；互补配置； ==我们还可以通过spring.config.location来改变默认的配置文件位置== 项目打包好以后，我们可以使用命令行参数的形式，启动项目的时候来指定配置文件的新位置；指定配置文件和默认加载的这些配置文件共同起作用形成互补配置； java -jar spring-boot-02-config-02-0.0.1-SNAPSHOT.jar –spring.config.location=G:/application.properties 7、外部配置加载顺序==SpringBoot也可以从以下位置加载配置； 优先级从高到低；高优先级的配置覆盖低优先级的配置，所有的配置会形成互补配置== 1.命令行参数 所有的配置都可以在命令行上进行指定 java -jar spring-boot-02-config-02-0.0.1-SNAPSHOT.jar –server.port=8087 –server.context-path=/abc 多个配置用空格分开； –配置项=值 2.来自java:comp/env的JNDI属性 3.Java系统属性（System.getProperties()） 4.操作系统环境变量 5.RandomValuePropertySource配置的random.*属性值 ==由jar包外向jar包内进行寻找；== ==优先加载带profile== 6.jar包外部的application-{profile}.properties或application.yml(带spring.profile)配置文件 7.jar包内部的application-{profile}.properties或application.yml(带spring.profile)配置文件 ==再来加载不带profile== 8.jar包外部的application.properties或application.yml(不带spring.profile)配置文件 9.jar包内部的application.properties或application.yml(不带spring.profile)配置文件 10.@Configuration注解类上的@PropertySource 11.通过SpringApplication.setDefaultProperties指定的默认属性 所有支持的配置加载来源； 参考官方文档 8、自动配置原理配置文件到底能写什么？怎么写？自动配置原理； 配置文件能配置的属性参照 1、自动配置原理：1）、SpringBoot启动的时候加载主配置类，开启了自动配置功能 ==@EnableAutoConfiguration== 2）、@EnableAutoConfiguration 作用： 利用EnableAutoConfigurationImportSelector给容器中导入一些组件？ 可以查看selectImports()方法的内容； List configurations = getCandidateConfigurations(annotationMetadata, attributes);获取候选的配置 1234SpringFactoriesLoader.loadFactoryNames()扫描所有jar包类路径下 META-INF/spring.factories把扫描到的这些文件的内容包装成properties对象从properties中获取到EnableAutoConfiguration.class类（类名）对应的值，然后把他们添加在容器中 ==将 类路径下 META-INF/spring.factories 里面配置的所有EnableAutoConfiguration的值加入到了容器中；== 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798# Auto Configureorg.springframework.boot.autoconfigure.EnableAutoConfiguration=\org.springframework.boot.autoconfigure.admin.SpringApplicationAdminJmxAutoConfiguration,\org.springframework.boot.autoconfigure.aop.AopAutoConfiguration,\org.springframework.boot.autoconfigure.amqp.RabbitAutoConfiguration,\org.springframework.boot.autoconfigure.batch.BatchAutoConfiguration,\org.springframework.boot.autoconfigure.cache.CacheAutoConfiguration,\org.springframework.boot.autoconfigure.cassandra.CassandraAutoConfiguration,\org.springframework.boot.autoconfigure.cloud.CloudAutoConfiguration,\org.springframework.boot.autoconfigure.context.ConfigurationPropertiesAutoConfiguration,\org.springframework.boot.autoconfigure.context.MessageSourceAutoConfiguration,\org.springframework.boot.autoconfigure.context.PropertyPlaceholderAutoConfiguration,\org.springframework.boot.autoconfigure.couchbase.CouchbaseAutoConfiguration,\org.springframework.boot.autoconfigure.dao.PersistenceExceptionTranslationAutoConfiguration,\org.springframework.boot.autoconfigure.data.cassandra.CassandraDataAutoConfiguration,\org.springframework.boot.autoconfigure.data.cassandra.CassandraRepositoriesAutoConfiguration,\org.springframework.boot.autoconfigure.data.couchbase.CouchbaseDataAutoConfiguration,\org.springframework.boot.autoconfigure.data.couchbase.CouchbaseRepositoriesAutoConfiguration,\org.springframework.boot.autoconfigure.data.elasticsearch.ElasticsearchAutoConfiguration,\org.springframework.boot.autoconfigure.data.elasticsearch.ElasticsearchDataAutoConfiguration,\org.springframework.boot.autoconfigure.data.elasticsearch.ElasticsearchRepositoriesAutoConfiguration,\org.springframework.boot.autoconfigure.data.jpa.JpaRepositoriesAutoConfiguration,\org.springframework.boot.autoconfigure.data.ldap.LdapDataAutoConfiguration,\org.springframework.boot.autoconfigure.data.ldap.LdapRepositoriesAutoConfiguration,\org.springframework.boot.autoconfigure.data.mongo.MongoDataAutoConfiguration,\org.springframework.boot.autoconfigure.data.mongo.MongoRepositoriesAutoConfiguration,\org.springframework.boot.autoconfigure.data.neo4j.Neo4jDataAutoConfiguration,\org.springframework.boot.autoconfigure.data.neo4j.Neo4jRepositoriesAutoConfiguration,\org.springframework.boot.autoconfigure.data.solr.SolrRepositoriesAutoConfiguration,\org.springframework.boot.autoconfigure.data.redis.RedisAutoConfiguration,\org.springframework.boot.autoconfigure.data.redis.RedisRepositoriesAutoConfiguration,\org.springframework.boot.autoconfigure.data.rest.RepositoryRestMvcAutoConfiguration,\org.springframework.boot.autoconfigure.data.web.SpringDataWebAutoConfiguration,\org.springframework.boot.autoconfigure.elasticsearch.jest.JestAutoConfiguration,\org.springframework.boot.autoconfigure.freemarker.FreeMarkerAutoConfiguration,\org.springframework.boot.autoconfigure.gson.GsonAutoConfiguration,\org.springframework.boot.autoconfigure.h2.H2ConsoleAutoConfiguration,\org.springframework.boot.autoconfigure.hateoas.HypermediaAutoConfiguration,\org.springframework.boot.autoconfigure.hazelcast.HazelcastAutoConfiguration,\org.springframework.boot.autoconfigure.hazelcast.HazelcastJpaDependencyAutoConfiguration,\org.springframework.boot.autoconfigure.info.ProjectInfoAutoConfiguration,\org.springframework.boot.autoconfigure.integration.IntegrationAutoConfiguration,\org.springframework.boot.autoconfigure.jackson.JacksonAutoConfiguration,\org.springframework.boot.autoconfigure.jdbc.DataSourceAutoConfiguration,\org.springframework.boot.autoconfigure.jdbc.JdbcTemplateAutoConfiguration,\org.springframework.boot.autoconfigure.jdbc.JndiDataSourceAutoConfiguration,\org.springframework.boot.autoconfigure.jdbc.XADataSourceAutoConfiguration,\org.springframework.boot.autoconfigure.jdbc.DataSourceTransactionManagerAutoConfiguration,\org.springframework.boot.autoconfigure.jms.JmsAutoConfiguration,\org.springframework.boot.autoconfigure.jmx.JmxAutoConfiguration,\org.springframework.boot.autoconfigure.jms.JndiConnectionFactoryAutoConfiguration,\org.springframework.boot.autoconfigure.jms.activemq.ActiveMQAutoConfiguration,\org.springframework.boot.autoconfigure.jms.artemis.ArtemisAutoConfiguration,\org.springframework.boot.autoconfigure.flyway.FlywayAutoConfiguration,\org.springframework.boot.autoconfigure.groovy.template.GroovyTemplateAutoConfiguration,\org.springframework.boot.autoconfigure.jersey.JerseyAutoConfiguration,\org.springframework.boot.autoconfigure.jooq.JooqAutoConfiguration,\org.springframework.boot.autoconfigure.kafka.KafkaAutoConfiguration,\org.springframework.boot.autoconfigure.ldap.embedded.EmbeddedLdapAutoConfiguration,\org.springframework.boot.autoconfigure.ldap.LdapAutoConfiguration,\org.springframework.boot.autoconfigure.liquibase.LiquibaseAutoConfiguration,\org.springframework.boot.autoconfigure.mail.MailSenderAutoConfiguration,\org.springframework.boot.autoconfigure.mail.MailSenderValidatorAutoConfiguration,\org.springframework.boot.autoconfigure.mobile.DeviceResolverAutoConfiguration,\org.springframework.boot.autoconfigure.mobile.DeviceDelegatingViewResolverAutoConfiguration,\org.springframework.boot.autoconfigure.mobile.SitePreferenceAutoConfiguration,\org.springframework.boot.autoconfigure.mongo.embedded.EmbeddedMongoAutoConfiguration,\org.springframework.boot.autoconfigure.mongo.MongoAutoConfiguration,\org.springframework.boot.autoconfigure.mustache.MustacheAutoConfiguration,\org.springframework.boot.autoconfigure.orm.jpa.HibernateJpaAutoConfiguration,\org.springframework.boot.autoconfigure.reactor.ReactorAutoConfiguration,\org.springframework.boot.autoconfigure.security.SecurityAutoConfiguration,\org.springframework.boot.autoconfigure.security.SecurityFilterAutoConfiguration,\org.springframework.boot.autoconfigure.security.FallbackWebSecurityAutoConfiguration,\org.springframework.boot.autoconfigure.security.oauth2.OAuth2AutoConfiguration,\org.springframework.boot.autoconfigure.sendgrid.SendGridAutoConfiguration,\org.springframework.boot.autoconfigure.session.SessionAutoConfiguration,\org.springframework.boot.autoconfigure.social.SocialWebAutoConfiguration,\org.springframework.boot.autoconfigure.social.FacebookAutoConfiguration,\org.springframework.boot.autoconfigure.social.LinkedInAutoConfiguration,\org.springframework.boot.autoconfigure.social.TwitterAutoConfiguration,\org.springframework.boot.autoconfigure.solr.SolrAutoConfiguration,\org.springframework.boot.autoconfigure.thymeleaf.ThymeleafAutoConfiguration,\org.springframework.boot.autoconfigure.transaction.TransactionAutoConfiguration,\org.springframework.boot.autoconfigure.transaction.jta.JtaAutoConfiguration,\org.springframework.boot.autoconfigure.validation.ValidationAutoConfiguration,\org.springframework.boot.autoconfigure.web.DispatcherServletAutoConfiguration,\org.springframework.boot.autoconfigure.web.EmbeddedServletContainerAutoConfiguration,\org.springframework.boot.autoconfigure.web.ErrorMvcAutoConfiguration,\org.springframework.boot.autoconfigure.web.HttpEncodingAutoConfiguration,\org.springframework.boot.autoconfigure.web.HttpMessageConvertersAutoConfiguration,\org.springframework.boot.autoconfigure.web.MultipartAutoConfiguration,\org.springframework.boot.autoconfigure.web.ServerPropertiesAutoConfiguration,\org.springframework.boot.autoconfigure.web.WebClientAutoConfiguration,\org.springframework.boot.autoconfigure.web.WebMvcAutoConfiguration,\org.springframework.boot.autoconfigure.websocket.WebSocketAutoConfiguration,\org.springframework.boot.autoconfigure.websocket.WebSocketMessagingAutoConfiguration,\org.springframework.boot.autoconfigure.webservices.WebServicesAutoConfiguration 每一个这样的 xxxAutoConfiguration类都是容器中的一个组件，都加入到容器中；用他们来做自动配置； 3）、每一个自动配置类进行自动配置功能； 4）、以HttpEncodingAutoConfiguration（Http编码自动配置）为例解释自动配置原理； 12345678910111213141516171819202122232425262728@Configuration //表示这是一个配置类，以前编写的配置文件一样，也可以给容器中添加组件@EnableConfigurationProperties(HttpEncodingProperties.class) //启动指定类的ConfigurationProperties功能；将配置文件中对应的值和HttpEncodingProperties绑定起来；并把HttpEncodingProperties加入到ioc容器中@ConditionalOnWebApplication //Spring底层@Conditional注解（Spring注解版），根据不同的条件，如果满足指定的条件，整个配置类里面的配置就会生效； 判断当前应用是否是web应用，如果是，当前配置类生效@ConditionalOnClass(CharacterEncodingFilter.class) //判断当前项目有没有这个类CharacterEncodingFilter；SpringMVC中进行乱码解决的过滤器；@ConditionalOnProperty(prefix = "spring.http.encoding", value = "enabled", matchIfMissing = true) //判断配置文件中是否存在某个配置 spring.http.encoding.enabled；如果不存在，判断也是成立的//即使我们配置文件中不配置pring.http.encoding.enabled=true，也是默认生效的；public class HttpEncodingAutoConfiguration &#123; //他已经和SpringBoot的配置文件映射了 private final HttpEncodingProperties properties; //只有一个有参构造器的情况下，参数的值就会从容器中拿 public HttpEncodingAutoConfiguration(HttpEncodingProperties properties) &#123; this.properties = properties; &#125; @Bean //给容器中添加一个组件，这个组件的某些值需要从properties中获取 @ConditionalOnMissingBean(CharacterEncodingFilter.class) //判断容器没有这个组件？ public CharacterEncodingFilter characterEncodingFilter() &#123; CharacterEncodingFilter filter = new OrderedCharacterEncodingFilter(); filter.setEncoding(this.properties.getCharset().name()); filter.setForceRequestEncoding(this.properties.shouldForce(Type.REQUEST)); filter.setForceResponseEncoding(this.properties.shouldForce(Type.RESPONSE)); return filter; &#125; 根据当前不同的条件判断，决定这个配置类是否生效？ 一但这个配置类生效；这个配置类就会给容器中添加各种组件；这些组件的属性是从对应的properties类中获取的，这些类里面的每一个属性又是和配置文件绑定的； 5）、所有在配置文件中能配置的属性都是在xxxxProperties类中封装者‘；配置文件能配置什么就可以参照某个功能对应的这个属性类 1234@ConfigurationProperties(prefix = "spring.http.encoding") //从配置文件中获取指定的值和bean的属性进行绑定public class HttpEncodingProperties &#123; public static final Charset DEFAULT_CHARSET = Charset.forName("UTF-8"); 精髓： ​ 1）、SpringBoot启动会加载大量的自动配置类 ​ 2）、我们看我们需要的功能有没有SpringBoot默认写好的自动配置类； ​ 3）、我们再来看这个自动配置类中到底配置了哪些组件；（只要我们要用的组件有，我们就不需要再来配置了） ​ 4）、给容器中自动配置类添加组件的时候，会从properties类中获取某些属性。我们就可以在配置文件中指定这些属性的值； xxxxAutoConfigurartion：自动配置类； 给容器中添加组件 xxxxProperties:封装配置文件中相关属性； 2、细节1、@Conditional派生注解（Spring注解版原生的@Conditional作用）作用：必须是@Conditional指定的条件成立，才给容器中添加组件，配置配里面的所有内容才生效； @Conditional扩展注解 作用（判断是否满足当前指定条件） @ConditionalOnJava 系统的java版本是否符合要求 @ConditionalOnBean 容器中存在指定Bean； @ConditionalOnMissingBean 容器中不存在指定Bean； @ConditionalOnExpression 满足SpEL表达式指定 @ConditionalOnClass 系统中有指定的类 @ConditionalOnMissingClass 系统中没有指定的类 @ConditionalOnSingleCandidate 容器中只有一个指定的Bean，或者这个Bean是首选Bean @ConditionalOnProperty 系统中指定的属性是否有指定的值 @ConditionalOnResource 类路径下是否存在指定资源文件 @ConditionalOnWebApplication 当前是web环境 @ConditionalOnNotWebApplication 当前不是web环境 @ConditionalOnJndi JNDI存在指定项 自动配置类必须在一定的条件下才能生效； 我们怎么知道哪些自动配置类生效； ==我们可以通过启用 debug=true属性；来让控制台打印自动配置报告==，这样我们就可以很方便的知道哪些自动配置类生效； 1234567891011121314151617181920212223=========================AUTO-CONFIGURATION REPORT=========================Positive matches:（自动配置类启用的）----------------- DispatcherServletAutoConfiguration matched: - @ConditionalOnClass found required class 'org.springframework.web.servlet.DispatcherServlet'; @ConditionalOnMissingClass did not find unwanted class (OnClassCondition) - @ConditionalOnWebApplication (required) found StandardServletEnvironment (OnWebApplicationCondition) Negative matches:（没有启动，没有匹配成功的自动配置类）----------------- ActiveMQAutoConfiguration: Did not match: - @ConditionalOnClass did not find required classes 'javax.jms.ConnectionFactory', 'org.apache.activemq.ActiveMQConnectionFactory' (OnClassCondition) AopAutoConfiguration: Did not match: - @ConditionalOnClass did not find required classes 'org.aspectj.lang.annotation.Aspect', 'org.aspectj.lang.reflect.Advice' (OnClassCondition) 三、日志1、日志框架 小张；开发一个大型系统； ​ 1、System.out.println(“”)；将关键数据打印在控制台；去掉？写在一个文件？ ​ 2、框架来记录系统的一些运行时信息；日志框架 ； zhanglogging.jar； ​ 3、高大上的几个功能？异步模式？自动归档？xxxx？ zhanglogging-good.jar？ ​ 4、将以前框架卸下来？换上新的框架，重新修改之前相关的API；zhanglogging-prefect.jar； ​ 5、JDBC—数据库驱动； ​ 写了一个统一的接口层；日志门面（日志的一个抽象层）；logging-abstract.jar； ​ 给项目中导入具体的日志实现就行了；我们之前的日志框架都是实现的抽象层； 市面上的日志框架； JUL、JCL、Jboss-logging、logback、log4j、log4j2、slf4j…. 日志门面 （日志的抽象层） 日志实现 JCL（Jakarta Commons Logging） SLF4j（Simple Logging Facade for Java） jboss-logging Log4j JUL（java.util.logging） Log4j2 Logback 左边选一个门面（抽象层）、右边来选一个实现； 日志门面： SLF4J； 日志实现：Logback； SpringBoot：底层是Spring框架，Spring框架默认是用JCL；‘ ​ ==SpringBoot选用 SLF4j和logback；== 2、SLF4j使用1、如何在系统中使用SLF4j https://www.slf4j.org以后开发的时候，日志记录方法的调用，不应该来直接调用日志的实现类，而是调用日志抽象层里面的方法； 给系统里面导入slf4j的jar和 logback的实现jar 123456789import org.slf4j.Logger;import org.slf4j.LoggerFactory;public class HelloWorld &#123; public static void main(String[] args) &#123; Logger logger = LoggerFactory.getLogger(HelloWorld.class); logger.info("Hello World"); &#125;&#125; 图示； 每一个日志的实现框架都有自己的配置文件。使用slf4j以后，配置文件还是做成日志实现框架自己本身的配置文件； 2、遗留问题a（slf4j+logback）: Spring（commons-logging）、Hibernate（jboss-logging）、MyBatis、xxxx 统一日志记录，即使是别的框架和我一起统一使用slf4j进行输出？ 如何让系统中所有的日志都统一到slf4j； ==1、将系统中其他日志框架先排除出去；== ==2、用中间包来替换原有的日志框架；== ==3、我们导入slf4j其他的实现== 3、SpringBoot日志关系1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt;&lt;/dependency&gt; SpringBoot使用它来做日志功能； 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-logging&lt;/artifactId&gt; &lt;/dependency&gt; 底层依赖关系 总结： ​ 1）、SpringBoot底层也是使用slf4j+logback的方式进行日志记录 ​ 2）、SpringBoot也把其他的日志都替换成了slf4j； ​ 3）、中间替换包？ 123456@SuppressWarnings("rawtypes")public abstract class LogFactory &#123; static String UNSUPPORTED_OPERATION_IN_JCL_OVER_SLF4J = "http://www.slf4j.org/codes.html#unsupported_operation_in_jcl_over_slf4j"; static LogFactory logFactory = new SLF4JLogFactory(); ​ 4）、如果我们要引入其他框架？一定要把这个框架的默认日志依赖移除掉？ ​ Spring框架用的是commons-logging； 12345678910&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-core&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;commons-logging&lt;/groupId&gt; &lt;artifactId&gt;commons-logging&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt; ==SpringBoot能自动适配所有的日志，而且底层使用slf4j+logback的方式记录日志，引入其他框架的时候，只需要把这个框架依赖的日志框架排除掉即可；== 4、日志使用；1、默认配置SpringBoot默认帮我们配置好了日志； 123456789101112131415161718//记录器Logger logger = LoggerFactory.getLogger(getClass());@Testpublic void contextLoads() &#123; //System.out.println(); //日志的级别； //由低到高 trace&lt;debug&lt;info&lt;warn&lt;error //可以调整输出的日志级别；日志就只会在这个级别以以后的高级别生效 logger.trace("这是trace日志..."); logger.debug("这是debug日志..."); //SpringBoot默认给我们使用的是info级别的，没有指定级别的就用SpringBoot默认规定的级别；root级别 logger.info("这是info日志..."); logger.warn("这是warn日志..."); logger.error("这是error日志...");&#125; 123456789 日志输出格式：%d表示日期时间，%thread表示线程名，%-5level：级别从左显示5个字符宽度%logger&#123;50&#125; 表示logger名字最长50个字符，否则按照句点分割。 %msg：日志消息，%n是换行符 --&gt; %d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;50&#125; - %msg%n SpringBoot修改日志的默认配置 123456789101112131415logging.level.com.atguigu=trace#logging.path=# 不指定路径在当前项目下生成springboot.log日志# 可以指定完整的路径；#logging.file=G:/springboot.log# 在当前磁盘的根路径下创建spring文件夹和里面的log文件夹；使用 spring.log 作为默认文件logging.path=/spring/log# 在控制台输出的日志的格式logging.pattern.console=%d&#123;yyyy-MM-dd&#125; [%thread] %-5level %logger&#123;50&#125; - %msg%n# 指定文件中日志输出的格式logging.pattern.file=%d&#123;yyyy-MM-dd&#125; === [%thread] === %-5level === %logger&#123;50&#125; ==== %msg%n logging.file logging.path Example Description (none) (none) 只在控制台输出 指定文件名 (none) my.log 输出日志到my.log文件 (none) 指定目录 /var/log 输出到指定目录的 spring.log 文件中 2、指定配置给类路径下放上每个日志框架自己的配置文件即可；SpringBoot就不使用他默认配置的了 Logging System Customization Logback logback-spring.xml, logback-spring.groovy, logback.xml or logback.groovy Log4j2 log4j2-spring.xml or log4j2.xml JDK (Java Util Logging) logging.properties logback.xml：直接就被日志框架识别了； logback-spring.xml：日志框架就不直接加载日志的配置项，由SpringBoot解析日志配置，可以使用SpringBoot的高级Profile功能 1234&lt;springProfile name="staging"&gt; &lt;!-- configuration to be enabled when the "staging" profile is active --&gt; 可以指定某段配置只在某个环境下生效&lt;/springProfile&gt; 如： 12345678910111213141516171819&lt;appender name="stdout" class="ch.qos.logback.core.ConsoleAppender"&gt; &lt;!-- 日志输出格式： %d表示日期时间， %thread表示线程名， %-5level：级别从左显示5个字符宽度 %logger&#123;50&#125; 表示logger名字最长50个字符，否则按照句点分割。 %msg：日志消息， %n是换行符 --&gt; &lt;layout class="ch.qos.logback.classic.PatternLayout"&gt; &lt;springProfile name="dev"&gt; &lt;pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; ----&gt; [%thread] ---&gt; %-5level %logger&#123;50&#125; - %msg%n&lt;/pattern&gt; &lt;/springProfile&gt; &lt;springProfile name="!dev"&gt; &lt;pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; ==== [%thread] ==== %-5level %logger&#123;50&#125; - %msg%n&lt;/pattern&gt; &lt;/springProfile&gt; &lt;/layout&gt; &lt;/appender&gt; 如果使用logback.xml作为日志配置文件，还要使用profile功能，会有以下错误 no applicable action for [springProfile] 5、切换日志框架可以按照slf4j的日志适配图，进行相关的切换； slf4j+log4j的方式； 12345678910111213141516171819&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;logback-classic&lt;/artifactId&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;artifactId&gt;log4j-over-slf4j&lt;/artifactId&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt;&lt;/dependency&gt; 切换为log4j2 123456789101112131415 &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;spring-boot-starter-logging&lt;/artifactId&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-log4j2&lt;/artifactId&gt;&lt;/dependency&gt; 四、Web开发1、简介使用SpringBoot； 1）、创建SpringBoot应用，选中我们需要的模块； 2）、SpringBoot已经默认将这些场景配置好了，只需要在配置文件中指定少量配置就可以运行起来 3）、自己编写业务代码； 自动配置原理？ 这个场景SpringBoot帮我们配置了什么？能不能修改？能修改哪些配置？能不能扩展？xxx 12xxxxAutoConfiguration：帮我们给容器中自动配置组件；xxxxProperties:配置类来封装配置文件的内容； 2、SpringBoot对静态资源的映射规则；123@ConfigurationProperties(prefix = "spring.resources", ignoreUnknownFields = false)public class ResourceProperties implements ResourceLoaderAware &#123; //可以设置和静态资源有关的参数，缓存时间等 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364WebMvcAuotConfiguration： @Override public void addResourceHandlers(ResourceHandlerRegistry registry) &#123; if (!this.resourceProperties.isAddMappings()) &#123; logger.debug("Default resource handling disabled"); return; &#125; Integer cachePeriod = this.resourceProperties.getCachePeriod(); if (!registry.hasMappingForPattern("/webjars/**")) &#123; customizeResourceHandlerRegistration( registry.addResourceHandler("/webjars/**") .addResourceLocations( "classpath:/META-INF/resources/webjars/") .setCachePeriod(cachePeriod)); &#125; String staticPathPattern = this.mvcProperties.getStaticPathPattern(); //静态资源文件夹映射 if (!registry.hasMappingForPattern(staticPathPattern)) &#123; customizeResourceHandlerRegistration( registry.addResourceHandler(staticPathPattern) .addResourceLocations( this.resourceProperties.getStaticLocations()) .setCachePeriod(cachePeriod)); &#125; &#125; //配置欢迎页映射 @Bean public WelcomePageHandlerMapping welcomePageHandlerMapping( ResourceProperties resourceProperties) &#123; return new WelcomePageHandlerMapping(resourceProperties.getWelcomePage(), this.mvcProperties.getStaticPathPattern()); &#125; //配置喜欢的图标 @Configuration @ConditionalOnProperty(value = "spring.mvc.favicon.enabled", matchIfMissing = true) public static class FaviconConfiguration &#123; private final ResourceProperties resourceProperties; public FaviconConfiguration(ResourceProperties resourceProperties) &#123; this.resourceProperties = resourceProperties; &#125; @Bean public SimpleUrlHandlerMapping faviconHandlerMapping() &#123; SimpleUrlHandlerMapping mapping = new SimpleUrlHandlerMapping(); mapping.setOrder(Ordered.HIGHEST_PRECEDENCE + 1); //所有 **/favicon.ico mapping.setUrlMap(Collections.singletonMap("**/favicon.ico", faviconRequestHandler())); return mapping; &#125; @Bean public ResourceHttpRequestHandler faviconRequestHandler() &#123; ResourceHttpRequestHandler requestHandler = new ResourceHttpRequestHandler(); requestHandler .setLocations(this.resourceProperties.getFaviconLocations()); return requestHandler; &#125; &#125; ==1）、所有 /webjars/** ，都去 classpath:/META-INF/resources/webjars/ 找资源；== ​ webjars：以jar包的方式引入静态资源； http://www.webjars.org/ localhost:8080/webjars/jquery/3.3.1/jquery.js 123456&lt;!--引入jquery-webjar--&gt;在访问的时候只需要写webjars下面资源的名称即可 &lt;dependency&gt; &lt;groupId&gt;org.webjars&lt;/groupId&gt; &lt;artifactId&gt;jquery&lt;/artifactId&gt; &lt;version&gt;3.3.1&lt;/version&gt; &lt;/dependency&gt; ==2）、”/**” 访问当前项目的任何资源，都去（静态资源的文件夹）找映射== 12345&quot;classpath:/META-INF/resources/&quot;, &quot;classpath:/resources/&quot;,&quot;classpath:/static/&quot;, &quot;classpath:/public/&quot; &quot;/&quot;：当前项目的根路径 localhost:8080/abc === 去静态资源文件夹里面找abc ==3）、欢迎页； 静态资源文件夹下的所有index.html页面；被”/**”映射；== ​ localhost:8080/ 找index页面 ==4）、所有的 **/favicon.ico 都是在静态资源文件下找；== 3、模板引擎JSP、Velocity、Freemarker、Thymeleaf SpringBoot推荐的Thymeleaf； 语法更简单，功能更强大； 1、引入thymeleaf；123456789101112 &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt; 2.1.6 &lt;/dependency&gt;切换thymeleaf版本&lt;properties&gt; &lt;thymeleaf.version&gt;3.0.9.RELEASE&lt;/thymeleaf.version&gt; &lt;!-- 布局功能的支持程序 thymeleaf3主程序 layout2以上版本 --&gt; &lt;!-- thymeleaf2 layout1--&gt; &lt;thymeleaf-layout-dialect.version&gt;2.2.2&lt;/thymeleaf-layout-dialect.version&gt; &lt;/properties&gt; 2、Thymeleaf使用1234567891011@ConfigurationProperties(prefix = "spring.thymeleaf")public class ThymeleafProperties &#123; private static final Charset DEFAULT_ENCODING = Charset.forName("UTF-8"); private static final MimeType DEFAULT_CONTENT_TYPE = MimeType.valueOf("text/html"); public static final String DEFAULT_PREFIX = "classpath:/templates/"; public static final String DEFAULT_SUFFIX = ".html"; // 只要我们把HTML页面放在classpath:/templates/，thymeleaf就能自动渲染； 使用： 1、导入thymeleaf的名称空间 1&lt;html lang="en" xmlns:th="http://www.thymeleaf.org"&gt; 2、使用thymeleaf语法； 123456789101112&lt;!DOCTYPE html&gt;&lt;html lang="en" xmlns:th="http://www.thymeleaf.org"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;h1&gt;成功！&lt;/h1&gt; &lt;!--th:text 将div里面的文本内容设置为 --&gt; &lt;div th:text="$&#123;hello&#125;"&gt;这是显示欢迎信息&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 3、语法规则1）、th:text；改变当前元素里面的文本内容； ​ th：任意html属性；来替换原生属性的值 2）、表达式？ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869Simple expressions:（表达式语法） Variable Expressions: $&#123;...&#125;：获取变量值；OGNL； 1）、获取对象的属性、调用方法 2）、使用内置的基本对象： #ctx : the context object. #vars: the context variables. #locale : the context locale. #request : (only in Web Contexts) the HttpServletRequest object. #response : (only in Web Contexts) the HttpServletResponse object. #session : (only in Web Contexts) the HttpSession object. #servletContext : (only in Web Contexts) the ServletContext object. $&#123;session.foo&#125; 3）、内置的一些工具对象：#execInfo : information about the template being processed.#messages : methods for obtaining externalized messages inside variables expressions, in the same way as they would be obtained using #&#123;…&#125; syntax.#uris : methods for escaping parts of URLs/URIs#conversions : methods for executing the configured conversion service (if any).#dates : methods for java.util.Date objects: formatting, component extraction, etc.#calendars : analogous to #dates , but for java.util.Calendar objects.#numbers : methods for formatting numeric objects.#strings : methods for String objects: contains, startsWith, prepending/appending, etc.#objects : methods for objects in general.#bools : methods for boolean evaluation.#arrays : methods for arrays.#lists : methods for lists.#sets : methods for sets.#maps : methods for maps.#aggregates : methods for creating aggregates on arrays or collections.#ids : methods for dealing with id attributes that might be repeated (for example, as a result of an iteration). Selection Variable Expressions: *&#123;...&#125;：选择表达式：和$&#123;&#125;在功能上是一样； 补充：配合 th:object=&quot;$&#123;session.user&#125;： &lt;div th:object=&quot;$&#123;session.user&#125;&quot;&gt; &lt;p&gt;Name: &lt;span th:text=&quot;*&#123;firstName&#125;&quot;&gt;Sebastian&lt;/span&gt;.&lt;/p&gt; &lt;p&gt;Surname: &lt;span th:text=&quot;*&#123;lastName&#125;&quot;&gt;Pepper&lt;/span&gt;.&lt;/p&gt; &lt;p&gt;Nationality: &lt;span th:text=&quot;*&#123;nationality&#125;&quot;&gt;Saturn&lt;/span&gt;.&lt;/p&gt; &lt;/div&gt; Message Expressions: #&#123;...&#125;：获取国际化内容 Link URL Expressions: @&#123;...&#125;：定义URL； @&#123;/order/process(execId=$&#123;execId&#125;,execType=&apos;FAST&apos;)&#125; Fragment Expressions: ~&#123;...&#125;：片段引用表达式 &lt;div th:insert=&quot;~&#123;commons :: main&#125;&quot;&gt;...&lt;/div&gt; Literals（字面量） Text literals: &apos;one text&apos; , &apos;Another one!&apos; ,… Number literals: 0 , 34 , 3.0 , 12.3 ,… Boolean literals: true , false Null literal: null Literal tokens: one , sometext , main ,…Text operations:（文本操作） String concatenation: + Literal substitutions: |The name is $&#123;name&#125;|Arithmetic operations:（数学运算） Binary operators: + , - , * , / , % Minus sign (unary operator): -Boolean operations:（布尔运算） Binary operators: and , or Boolean negation (unary operator): ! , notComparisons and equality:（比较运算） Comparators: &gt; , &lt; , &gt;= , &lt;= ( gt , lt , ge , le ) Equality operators: == , != ( eq , ne )Conditional operators:条件运算（三元运算符） If-then: (if) ? (then) If-then-else: (if) ? (then) : (else) Default: (value) ?: (defaultvalue)Special tokens: No-Operation: _ 4、SpringMVC自动配置https://docs.spring.io/spring-boot/docs/1.5.10.RELEASE/reference/htmlsingle/#boot-features-developing-web-applications 1. Spring MVC auto-configurationSpring Boot 自动配置好了SpringMVC 以下是SpringBoot对SpringMVC的默认配置:==（WebMvcAutoConfiguration）== Inclusion of ContentNegotiatingViewResolver and BeanNameViewResolver beans. 自动配置了ViewResolver（视图解析器：根据方法的返回值得到视图对象（View），视图对象决定如何渲染（转发？重定向？）） ContentNegotiatingViewResolver：组合所有的视图解析器的； ==如何定制：我们可以自己给容器中添加一个视图解析器；自动的将其组合进来；== Support for serving static resources, including support for WebJars (see below).静态资源文件夹路径,webjars Static index.html support. 静态首页访问 Custom Favicon support (see below). favicon.ico 自动注册了 of Converter, GenericConverter, Formatter beans. Converter：转换器； public String hello(User user)：类型转换使用Converter Formatter 格式化器； 2017.12.17===Date； 12345@Bean@ConditionalOnProperty(prefix = "spring.mvc", name = "date-format")//在文件中配置日期格式化的规则public Formatter&lt;Date&gt; dateFormatter() &#123; return new DateFormatter(this.mvcProperties.getDateFormat());//日期格式化组件&#125; ​ ==自己添加的格式化器转换器，我们只需要放在容器中即可== Support for HttpMessageConverters (see below). HttpMessageConverter：SpringMVC用来转换Http请求和响应的；User—Json； HttpMessageConverters 是从容器中确定；获取所有的HttpMessageConverter； ==自己给容器中添加HttpMessageConverter，只需要将自己的组件注册容器中（@Bean,@Component）== Automatic registration of MessageCodesResolver (see below).定义错误代码生成规则 Automatic use of a ConfigurableWebBindingInitializer bean (see below). ==我们可以配置一个ConfigurableWebBindingInitializer来替换默认的；（添加到容器）== 12初始化WebDataBinder；请求数据=====JavaBean； org.springframework.boot.autoconfigure.web：web的所有自动场景； If you want to keep Spring Boot MVC features, and you just want to add additional MVC configuration (interceptors, formatters, view controllers etc.) you can add your own @Configuration class of type WebMvcConfigurerAdapter, but without @EnableWebMvc. If you wish to provide custom instances of RequestMappingHandlerMapping, RequestMappingHandlerAdapter or ExceptionHandlerExceptionResolver you can declare a WebMvcRegistrationsAdapter instance providing such components. If you want to take complete control of Spring MVC, you can add your own @Configuration annotated with @EnableWebMvc. 2、扩展SpringMVC1234567&lt;mvc:view-controller path="/hello" view-name="success"/&gt;&lt;mvc:interceptors&gt; &lt;mvc:interceptor&gt; &lt;mvc:mapping path="/hello"/&gt; &lt;bean&gt;&lt;/bean&gt; &lt;/mvc:interceptor&gt;&lt;/mvc:interceptors&gt; ==编写一个配置类（@Configuration），是WebMvcConfigurerAdapter类型；不能标注@EnableWebMvc==; 既保留了所有的自动配置，也能用我们扩展的配置； 1234567891011//使用WebMvcConfigurerAdapter可以来扩展SpringMVC的功能@Configurationpublic class MyMvcConfig extends WebMvcConfigurerAdapter &#123; @Override public void addViewControllers(ViewControllerRegistry registry) &#123; // super.addViewControllers(registry); //浏览器发送 /atguigu 请求来到 success registry.addViewController("/atguigu").setViewName("success"); &#125;&#125; 原理： ​ 1）、WebMvcAutoConfiguration是SpringMVC的自动配置类 ​ 2）、在做其他自动配置时会导入；@Import(EnableWebMvcConfiguration.class) 123456789101112131415161718 @Configurationpublic static class EnableWebMvcConfiguration extends DelegatingWebMvcConfiguration &#123; private final WebMvcConfigurerComposite configurers = new WebMvcConfigurerComposite(); //从容器中获取所有的WebMvcConfigurer @Autowired(required = false) public void setConfigurers(List&lt;WebMvcConfigurer&gt; configurers) &#123; if (!CollectionUtils.isEmpty(configurers)) &#123; this.configurers.addWebMvcConfigurers(configurers); //一个参考实现；将所有的WebMvcConfigurer相关配置都来一起调用； @Override // public void addViewControllers(ViewControllerRegistry registry) &#123; // for (WebMvcConfigurer delegate : this.delegates) &#123; // delegate.addViewControllers(registry); // &#125; &#125; &#125;&#125; ​ 3）、容器中所有的WebMvcConfigurer都会一起起作用； ​ 4）、我们的配置类也会被调用； ​ 效果：SpringMVC的自动配置和我们的扩展配置都会起作用； 3、全面接管SpringMVC；SpringBoot对SpringMVC的自动配置不需要了，所有都是我们自己配置；所有的SpringMVC的自动配置都失效了 我们需要在配置类中添加@EnableWebMvc即可； 123456789101112//使用WebMvcConfigurerAdapter可以来扩展SpringMVC的功能@EnableWebMvc@Configurationpublic class MyMvcConfig extends WebMvcConfigurerAdapter &#123; @Override public void addViewControllers(ViewControllerRegistry registry) &#123; // super.addViewControllers(registry); //浏览器发送 /atguigu 请求来到 success registry.addViewController("/atguigu").setViewName("success"); &#125;&#125; 原理： 为什么@EnableWebMvc自动配置就失效了； 1）@EnableWebMvc的核心 12@Import(DelegatingWebMvcConfiguration.class)public @interface EnableWebMvc &#123; 2）、 12@Configurationpublic class DelegatingWebMvcConfiguration extends WebMvcConfigurationSupport &#123; 3）、 12345678910@Configuration@ConditionalOnWebApplication@ConditionalOnClass(&#123; Servlet.class, DispatcherServlet.class, WebMvcConfigurerAdapter.class &#125;)//容器中没有这个组件的时候，这个自动配置类才生效@ConditionalOnMissingBean(WebMvcConfigurationSupport.class)@AutoConfigureOrder(Ordered.HIGHEST_PRECEDENCE + 10)@AutoConfigureAfter(&#123; DispatcherServletAutoConfiguration.class, ValidationAutoConfiguration.class &#125;)public class WebMvcAutoConfiguration &#123; 4）、@EnableWebMvc将WebMvcConfigurationSupport组件导入进来； 5）、导入的WebMvcConfigurationSupport只是SpringMVC最基本的功能； 5、如何修改SpringBoot的默认配置模式： ​ 1）、SpringBoot在自动配置很多组件的时候，先看容器中有没有用户自己配置的（@Bean、@Component）如果有就用用户配置的，如果没有，才自动配置；如果有些组件可以有多个（ViewResolver）将用户配置的和自己默认的组合起来； ​ 2）、在SpringBoot中会有非常多的xxxConfigurer帮助我们进行扩展配置 ​ 3）、在SpringBoot中会有很多的xxxCustomizer帮助我们进行定制配置 6、RestfulCRUD1）、默认访问首页12345678910111213141516171819202122232425//使用WebMvcConfigurerAdapter可以来扩展SpringMVC的功能//@EnableWebMvc 不要接管SpringMVC@Configurationpublic class MyMvcConfig extends WebMvcConfigurerAdapter &#123; @Override public void addViewControllers(ViewControllerRegistry registry) &#123; // super.addViewControllers(registry); //浏览器发送 /atguigu 请求来到 success registry.addViewController("/atguigu").setViewName("success"); &#125; //所有的WebMvcConfigurerAdapter组件都会一起起作用 @Bean //将组件注册在容器 public WebMvcConfigurerAdapter webMvcConfigurerAdapter()&#123; WebMvcConfigurerAdapter adapter = new WebMvcConfigurerAdapter() &#123; @Override public void addViewControllers(ViewControllerRegistry registry) &#123; registry.addViewController("/").setViewName("login"); registry.addViewController("/index.html").setViewName("login"); &#125; &#125;; return adapter; &#125;&#125; 2）、国际化1）、编写国际化配置文件； 2）、使用ResourceBundleMessageSource管理国际化资源文件 3）、在页面使用fmt:message取出国际化内容 步骤： 1）、编写国际化配置文件，抽取页面需要显示的国际化消息 2）、SpringBoot自动配置好了管理国际化资源文件的组件； 12345678910111213141516171819202122232425262728@ConfigurationProperties(prefix = "spring.messages")public class MessageSourceAutoConfiguration &#123; /** * Comma-separated list of basenames (essentially a fully-qualified classpath * location), each following the ResourceBundle convention with relaxed support for * slash based locations. If it doesn't contain a package qualifier (such as * "org.mypackage"), it will be resolved from the classpath root. */ private String basename = "messages"; //我们的配置文件可以直接放在类路径下叫messages.properties； @Bean public MessageSource messageSource() &#123; ResourceBundleMessageSource messageSource = new ResourceBundleMessageSource(); if (StringUtils.hasText(this.basename)) &#123; //设置国际化资源文件的基础名（去掉语言国家代码的） messageSource.setBasenames(StringUtils.commaDelimitedListToStringArray( StringUtils.trimAllWhitespace(this.basename))); &#125; if (this.encoding != null) &#123; messageSource.setDefaultEncoding(this.encoding.name()); &#125; messageSource.setFallbackToSystemLocale(this.fallbackToSystemLocale); messageSource.setCacheSeconds(this.cacheSeconds); messageSource.setAlwaysUseMessageFormat(this.alwaysUseMessageFormat); return messageSource; &#125; 3）、去页面获取国际化的值； 123456789101112131415161718192021222324252627282930313233343536&lt;!DOCTYPE html&gt;&lt;html lang="en" xmlns:th="http://www.thymeleaf.org"&gt; &lt;head&gt; &lt;meta http-equiv="Content-Type" content="text/html; charset=UTF-8"&gt; &lt;meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"&gt; &lt;meta name="description" content=""&gt; &lt;meta name="author" content=""&gt; &lt;title&gt;Signin Template for Bootstrap&lt;/title&gt; &lt;!-- Bootstrap core CSS --&gt; &lt;link href="asserts/css/bootstrap.min.css" th:href="@&#123;/webjars/bootstrap/4.0.0/css/bootstrap.css&#125;" rel="stylesheet"&gt; &lt;!-- Custom styles for this template --&gt; &lt;link href="asserts/css/signin.css" th:href="@&#123;/asserts/css/signin.css&#125;" rel="stylesheet"&gt; &lt;/head&gt; &lt;body class="text-center"&gt; &lt;form class="form-signin" action="dashboard.html"&gt; &lt;img class="mb-4" th:src="@&#123;/asserts/img/bootstrap-solid.svg&#125;" src="asserts/img/bootstrap-solid.svg" alt="" width="72" height="72"&gt; &lt;h1 class="h3 mb-3 font-weight-normal" th:text="#&#123;login.tip&#125;"&gt;Please sign in&lt;/h1&gt; &lt;label class="sr-only" th:text="#&#123;login.username&#125;"&gt;Username&lt;/label&gt; &lt;input type="text" class="form-control" placeholder="Username" th:placeholder="#&#123;login.username&#125;" required="" autofocus=""&gt; &lt;label class="sr-only" th:text="#&#123;login.password&#125;"&gt;Password&lt;/label&gt; &lt;input type="password" class="form-control" placeholder="Password" th:placeholder="#&#123;login.password&#125;" required=""&gt; &lt;div class="checkbox mb-3"&gt; &lt;label&gt; &lt;input type="checkbox" value="remember-me"/&gt; [[#&#123;login.remember&#125;]] &lt;/label&gt; &lt;/div&gt; &lt;button class="btn btn-lg btn-primary btn-block" type="submit" th:text="#&#123;login.btn&#125;"&gt;Sign in&lt;/button&gt; &lt;p class="mt-5 mb-3 text-muted"&gt;© 2017-2018&lt;/p&gt; &lt;a class="btn btn-sm"&gt;中文&lt;/a&gt; &lt;a class="btn btn-sm"&gt;English&lt;/a&gt; &lt;/form&gt; &lt;/body&gt;&lt;/html&gt; 效果：根据浏览器语言设置的信息切换了国际化； 原理： ​ 国际化Locale（区域信息对象）；LocaleResolver（获取区域信息对象）； 12345678910111213 @Bean @ConditionalOnMissingBean @ConditionalOnProperty(prefix = "spring.mvc", name = "locale") public LocaleResolver localeResolver() &#123; if (this.mvcProperties .getLocaleResolver() == WebMvcProperties.LocaleResolver.FIXED) &#123; return new FixedLocaleResolver(this.mvcProperties.getLocale()); &#125; AcceptHeaderLocaleResolver localeResolver = new AcceptHeaderLocaleResolver(); localeResolver.setDefaultLocale(this.mvcProperties.getLocale()); return localeResolver; &#125;默认的就是根据请求头带来的区域信息获取Locale进行国际化 4）、点击链接切换国际化 12345678910111213141516171819202122232425262728/** * 可以在连接上携带区域信息 */public class MyLocaleResolver implements LocaleResolver &#123; @Override public Locale resolveLocale(HttpServletRequest request) &#123; String l = request.getParameter("l"); Locale locale = Locale.getDefault(); if(!StringUtils.isEmpty(l))&#123; String[] split = l.split("_"); locale = new Locale(split[0],split[1]); &#125; return locale; &#125; @Override public void setLocale(HttpServletRequest request, HttpServletResponse response, Locale locale) &#123; &#125;&#125; @Bean public LocaleResolver localeResolver()&#123; return new MyLocaleResolver(); &#125;&#125; 3）、登陆开发期间模板引擎页面修改以后，要实时生效 1）、禁用模板引擎的缓存 12# 禁用缓存spring.thymeleaf.cache=false 2）、页面修改完成以后ctrl+f9：重新编译； 登陆错误消息的显示 1&lt;p style="color: red" th:text="$&#123;msg&#125;" th:if="$&#123;not #strings.isEmpty(msg)&#125;"&gt;&lt;/p&gt; 4）、拦截器进行登陆检查拦截器 123456789101112131415161718192021222324252627282930/** * 登陆检查， */public class LoginHandlerInterceptor implements HandlerInterceptor &#123; //目标方法执行之前 @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; Object user = request.getSession().getAttribute("loginUser"); if(user == null)&#123; //未登陆，返回登陆页面 request.setAttribute("msg","没有权限请先登陆"); request.getRequestDispatcher("/index.html").forward(request,response); return false; &#125;else&#123; //已登陆，放行请求 return true; &#125; &#125; @Override public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception &#123; &#125; @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception &#123; &#125;&#125; 注册拦截器 1234567891011121314151617181920212223//所有的WebMvcConfigurerAdapter组件都会一起起作用 @Bean //将组件注册在容器 public WebMvcConfigurerAdapter webMvcConfigurerAdapter()&#123; WebMvcConfigurerAdapter adapter = new WebMvcConfigurerAdapter() &#123; @Override public void addViewControllers(ViewControllerRegistry registry) &#123; registry.addViewController("/").setViewName("login"); registry.addViewController("/index.html").setViewName("login"); registry.addViewController("/main.html").setViewName("dashboard"); &#125; //注册拦截器 @Override public void addInterceptors(InterceptorRegistry registry) &#123; //super.addInterceptors(registry); //静态资源； *.css , *.js //SpringBoot已经做好了静态资源映射 registry.addInterceptor(new LoginHandlerInterceptor()).addPathPatterns("/**") .excludePathPatterns("/index.html","/","/user/login"); &#125; &#125;; return adapter; &#125; 5）、CRUD-员工列表实验要求： 1）、RestfulCRUD：CRUD满足Rest风格； URI： /资源名称/资源标识 HTTP请求方式区分对资源CRUD操作 普通CRUD（uri来区分操作） RestfulCRUD 查询 getEmp emp—GET 添加 addEmp?xxx emp—POST 修改 updateEmp?id=xxx&amp;xxx=xx emp/{id}—PUT 删除 deleteEmp?id=1 emp/{id}—DELETE 2）、实验的请求架构; 实验功能 请求URI 请求方式 查询所有员工 emps GET 查询某个员工(来到修改页面) emp/1 GET 来到添加页面 emp GET 添加员工 emp POST 来到修改页面（查出员工进行信息回显） emp/1 GET 修改员工 emp PUT 删除员工 emp/1 DELETE 3）、员工列表： thymeleaf公共页面元素抽取12345678910111213141、抽取公共片段&lt;div th:fragment="copy"&gt;&amp;copy; 2011 The Good Thymes Virtual Grocery&lt;/div&gt;2、引入公共片段&lt;div th:insert="~&#123;footer :: copy&#125;"&gt;&lt;/div&gt;~&#123;templatename::selector&#125;：模板名::选择器~&#123;templatename::fragmentname&#125;:模板名::片段名3、默认效果：insert的公共片段在div标签中如果使用th:insert等属性进行引入，可以不用写~&#123;&#125;：行内写法可以加上：[[~&#123;&#125;]];[(~&#123;&#125;)]； 三种引入公共片段的th属性： th:insert：将公共片段整个插入到声明引入的元素中 th:replace：将声明引入的元素替换为公共片段 th:include：将被引入的片段的内容包含进这个标签中 1234567891011121314151617181920212223&lt;footer th:fragment="copy"&gt;&amp;copy; 2011 The Good Thymes Virtual Grocery&lt;/footer&gt;引入方式&lt;div th:insert="footer :: copy"&gt;&lt;/div&gt;&lt;div th:replace="footer :: copy"&gt;&lt;/div&gt;&lt;div th:include="footer :: copy"&gt;&lt;/div&gt;效果&lt;div&gt; &lt;footer&gt; &amp;copy; 2011 The Good Thymes Virtual Grocery &lt;/footer&gt;&lt;/div&gt;&lt;footer&gt;&amp;copy; 2011 The Good Thymes Virtual Grocery&lt;/footer&gt;&lt;div&gt;&amp;copy; 2011 The Good Thymes Virtual Grocery&lt;/div&gt; 引入片段的时候传入参数： 1234567891011121314151617&lt;nav class="col-md-2 d-none d-md-block bg-light sidebar" id="sidebar"&gt; &lt;div class="sidebar-sticky"&gt; &lt;ul class="nav flex-column"&gt; &lt;li class="nav-item"&gt; &lt;a class="nav-link active" th:class="$&#123;activeUri=='main.html'?'nav-link active':'nav-link'&#125;" href="#" th:href="@&#123;/main.html&#125;"&gt; &lt;svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-home"&gt; &lt;path d="M3 9l9-7 9 7v11a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2z"&gt;&lt;/path&gt; &lt;polyline points="9 22 9 12 15 12 15 22"&gt;&lt;/polyline&gt; &lt;/svg&gt; Dashboard &lt;span class="sr-only"&gt;(current)&lt;/span&gt; &lt;/a&gt; &lt;/li&gt;&lt;!--引入侧边栏;传入参数--&gt;&lt;div th:replace="commons/bar::#sidebar(activeUri='emps')"&gt;&lt;/div&gt; 6）、CRUD-员工添加添加页面 123456789101112131415161718192021222324252627282930313233343536&lt;form&gt; &lt;div class="form-group"&gt; &lt;label&gt;LastName&lt;/label&gt; &lt;input type="text" class="form-control" placeholder="zhangsan"&gt; &lt;/div&gt; &lt;div class="form-group"&gt; &lt;label&gt;Email&lt;/label&gt; &lt;input type="email" class="form-control" placeholder="zhangsan@atguigu.com"&gt; &lt;/div&gt; &lt;div class="form-group"&gt; &lt;label&gt;Gender&lt;/label&gt;&lt;br/&gt; &lt;div class="form-check form-check-inline"&gt; &lt;input class="form-check-input" type="radio" name="gender" value="1"&gt; &lt;label class="form-check-label"&gt;男&lt;/label&gt; &lt;/div&gt; &lt;div class="form-check form-check-inline"&gt; &lt;input class="form-check-input" type="radio" name="gender" value="0"&gt; &lt;label class="form-check-label"&gt;女&lt;/label&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="form-group"&gt; &lt;label&gt;department&lt;/label&gt; &lt;select class="form-control"&gt; &lt;option&gt;1&lt;/option&gt; &lt;option&gt;2&lt;/option&gt; &lt;option&gt;3&lt;/option&gt; &lt;option&gt;4&lt;/option&gt; &lt;option&gt;5&lt;/option&gt; &lt;/select&gt; &lt;/div&gt; &lt;div class="form-group"&gt; &lt;label&gt;Birth&lt;/label&gt; &lt;input type="text" class="form-control" placeholder="zhangsan"&gt; &lt;/div&gt; &lt;button type="submit" class="btn btn-primary"&gt;添加&lt;/button&gt;&lt;/form&gt; 提交的数据格式不对：生日：日期； 2017-12-12；2017/12/12；2017.12.12； 日期的格式化；SpringMVC将页面提交的值需要转换为指定的类型; 2017-12-12—Date； 类型转换，格式化; 默认日期是按照/的方式； 7）、CRUD-员工修改修改添加二合一表单 123456789101112131415161718192021222324252627282930313233343536373839404142&lt;!--需要区分是员工修改还是添加；--&gt;&lt;form th:action="@&#123;/emp&#125;" method="post"&gt; &lt;!--发送put请求修改员工数据--&gt; &lt;!--1、SpringMVC中配置HiddenHttpMethodFilter;（SpringBoot自动配置好的）2、页面创建一个post表单3、创建一个input项，name="_method";值就是我们指定的请求方式--&gt; &lt;input type="hidden" name="_method" value="put" th:if="$&#123;emp!=null&#125;"/&gt; &lt;input type="hidden" name="id" th:if="$&#123;emp!=null&#125;" th:value="$&#123;emp.id&#125;"&gt; &lt;div class="form-group"&gt; &lt;label&gt;LastName&lt;/label&gt; &lt;input name="lastName" type="text" class="form-control" placeholder="zhangsan" th:value="$&#123;emp!=null&#125;?$&#123;emp.lastName&#125;"&gt; &lt;/div&gt; &lt;div class="form-group"&gt; &lt;label&gt;Email&lt;/label&gt; &lt;input name="email" type="email" class="form-control" placeholder="zhangsan@atguigu.com" th:value="$&#123;emp!=null&#125;?$&#123;emp.email&#125;"&gt; &lt;/div&gt; &lt;div class="form-group"&gt; &lt;label&gt;Gender&lt;/label&gt;&lt;br/&gt; &lt;div class="form-check form-check-inline"&gt; &lt;input class="form-check-input" type="radio" name="gender" value="1" th:checked="$&#123;emp!=null&#125;?$&#123;emp.gender==1&#125;"&gt; &lt;label class="form-check-label"&gt;男&lt;/label&gt; &lt;/div&gt; &lt;div class="form-check form-check-inline"&gt; &lt;input class="form-check-input" type="radio" name="gender" value="0" th:checked="$&#123;emp!=null&#125;?$&#123;emp.gender==0&#125;"&gt; &lt;label class="form-check-label"&gt;女&lt;/label&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="form-group"&gt; &lt;label&gt;department&lt;/label&gt; &lt;!--提交的是部门的id--&gt; &lt;select class="form-control" name="department.id"&gt; &lt;option th:selected="$&#123;emp!=null&#125;?$&#123;dept.id == emp.department.id&#125;" th:value="$&#123;dept.id&#125;" th:each="dept:$&#123;depts&#125;" th:text="$&#123;dept.departmentName&#125;"&gt;1&lt;/option&gt; &lt;/select&gt; &lt;/div&gt; &lt;div class="form-group"&gt; &lt;label&gt;Birth&lt;/label&gt; &lt;input name="birth" type="text" class="form-control" placeholder="zhangsan" th:value="$&#123;emp!=null&#125;?$&#123;#dates.format(emp.birth, 'yyyy-MM-dd HH:mm')&#125;"&gt; &lt;/div&gt; &lt;button type="submit" class="btn btn-primary" th:text="$&#123;emp!=null&#125;?'修改':'添加'"&gt;添加&lt;/button&gt;&lt;/form&gt; 8）、CRUD-员工删除123456789101112131415161718192021&lt;tr th:each="emp:$&#123;emps&#125;"&gt; &lt;td th:text="$&#123;emp.id&#125;"&gt;&lt;/td&gt; &lt;td&gt;[[$&#123;emp.lastName&#125;]]&lt;/td&gt; &lt;td th:text="$&#123;emp.email&#125;"&gt;&lt;/td&gt; &lt;td th:text="$&#123;emp.gender&#125;==0?'女':'男'"&gt;&lt;/td&gt; &lt;td th:text="$&#123;emp.department.departmentName&#125;"&gt;&lt;/td&gt; &lt;td th:text="$&#123;#dates.format(emp.birth, 'yyyy-MM-dd HH:mm')&#125;"&gt;&lt;/td&gt; &lt;td&gt; &lt;a class="btn btn-sm btn-primary" th:href="@&#123;/emp/&#125;+$&#123;emp.id&#125;"&gt;编辑&lt;/a&gt; &lt;button th:attr="del_uri=@&#123;/emp/&#125;+$&#123;emp.id&#125;" class="btn btn-sm btn-danger deleteBtn"&gt;删除&lt;/button&gt; &lt;/td&gt;&lt;/tr&gt;&lt;script&gt; $(".deleteBtn").click(function()&#123; //删除当前员工的 $("#deleteEmpForm").attr("action",$(this).attr("del_uri")).submit(); return false; &#125;);&lt;/script&gt; 7、错误处理机制1）、SpringBoot默认的错误处理机制默认效果： ​ 1）、浏览器，返回一个默认的错误页面 浏览器发送请求的请求头： ​ 2）、如果是其他客户端，默认响应一个json数据 ​ 原理： ​ 可以参照ErrorMvcAutoConfiguration；错误处理的自动配置； 给容器中添加了以下组件 ​ 1、DefaultErrorAttributes： 1234567891011帮我们在页面共享信息；@Override public Map&lt;String, Object&gt; getErrorAttributes(RequestAttributes requestAttributes, boolean includeStackTrace) &#123; Map&lt;String, Object&gt; errorAttributes = new LinkedHashMap&lt;String, Object&gt;(); errorAttributes.put("timestamp", new Date()); addStatus(errorAttributes, requestAttributes); addErrorDetails(errorAttributes, requestAttributes, includeStackTrace); addPath(errorAttributes, requestAttributes); return errorAttributes; &#125; ​ 2、BasicErrorController：处理默认/error请求 12345678910111213141516171819202122232425@Controller@RequestMapping("$&#123;server.error.path:$&#123;error.path:/error&#125;&#125;")public class BasicErrorController extends AbstractErrorController &#123; @RequestMapping(produces = "text/html")//产生html类型的数据；浏览器发送的请求来到这个方法处理 public ModelAndView errorHtml(HttpServletRequest request, HttpServletResponse response) &#123; HttpStatus status = getStatus(request); Map&lt;String, Object&gt; model = Collections.unmodifiableMap(getErrorAttributes( request, isIncludeStackTrace(request, MediaType.TEXT_HTML))); response.setStatus(status.value()); //去哪个页面作为错误页面；包含页面地址和页面内容 ModelAndView modelAndView = resolveErrorView(request, response, status, model); return (modelAndView == null ? new ModelAndView("error", model) : modelAndView); &#125; @RequestMapping @ResponseBody //产生json数据，其他客户端来到这个方法处理； public ResponseEntity&lt;Map&lt;String, Object&gt;&gt; error(HttpServletRequest request) &#123; Map&lt;String, Object&gt; body = getErrorAttributes(request, isIncludeStackTrace(request, MediaType.ALL)); HttpStatus status = getStatus(request); return new ResponseEntity&lt;Map&lt;String, Object&gt;&gt;(body, status); &#125; ​ 3、ErrorPageCustomizer： 12@Value("$&#123;error.path:/error&#125;")private String path = "/error"; 系统出现错误以后来到error请求进行处理；（web.xml注册的错误页面规则） ​ 4、DefaultErrorViewResolver： 123456789101112131415161718192021222324@Override public ModelAndView resolveErrorView(HttpServletRequest request, HttpStatus status, Map&lt;String, Object&gt; model) &#123; ModelAndView modelAndView = resolve(String.valueOf(status), model); if (modelAndView == null &amp;&amp; SERIES_VIEWS.containsKey(status.series())) &#123; modelAndView = resolve(SERIES_VIEWS.get(status.series()), model); &#125; return modelAndView; &#125; private ModelAndView resolve(String viewName, Map&lt;String, Object&gt; model) &#123; //默认SpringBoot可以去找到一个页面？ error/404 String errorViewName = "error/" + viewName; //模板引擎可以解析这个页面地址就用模板引擎解析 TemplateAvailabilityProvider provider = this.templateAvailabilityProviders .getProvider(errorViewName, this.applicationContext); if (provider != null) &#123; //模板引擎可用的情况下返回到errorViewName指定的视图地址 return new ModelAndView(errorViewName, model); &#125; //模板引擎不可用，就在静态资源文件夹下找errorViewName对应的页面 error/404.html return resolveResource(errorViewName, model); &#125; ​ 步骤： ​ 一但系统出现4xx或者5xx之类的错误；ErrorPageCustomizer就会生效（定制错误的响应规则）；就会来到/error请求；就会被BasicErrorController处理； ​ 1）响应页面；去哪个页面是由DefaultErrorViewResolver解析得到的； 1234567891011protected ModelAndView resolveErrorView(HttpServletRequest request, HttpServletResponse response, HttpStatus status, Map&lt;String, Object&gt; model) &#123; //所有的ErrorViewResolver得到ModelAndView for (ErrorViewResolver resolver : this.errorViewResolvers) &#123; ModelAndView modelAndView = resolver.resolveErrorView(request, status, model); if (modelAndView != null) &#123; return modelAndView; &#125; &#125; return null;&#125; 2）、如果定制错误响应：1）、如何定制错误的页面；​ 1）、有模板引擎的情况下；error/状态码; 【将错误页面命名为 错误状态码.html 放在模板引擎文件夹里面的 error文件夹下】，发生此状态码的错误就会来到 对应的页面； ​ 我们可以使用4xx和5xx作为错误页面的文件名来匹配这种类型的所有错误，精确优先（优先寻找精确的状态码.html）； ​ 页面能获取的信息； ​ timestamp：时间戳 ​ status：状态码 ​ error：错误提示 ​ exception：异常对象 ​ message：异常消息 ​ errors：JSR303数据校验的错误都在这里 ​ 2）、没有模板引擎（模板引擎找不到这个错误页面），静态资源文件夹下找； ​ 3）、以上都没有错误页面，就是默认来到SpringBoot默认的错误提示页面； 2）、如何定制错误的json数据；​ 1）、自定义异常处理&amp;返回定制json数据； 12345678910111213@ControllerAdvicepublic class MyExceptionHandler &#123; @ResponseBody @ExceptionHandler(UserNotExistException.class) public Map&lt;String,Object&gt; handleException(Exception e)&#123; Map&lt;String,Object&gt; map = new HashMap&lt;&gt;(); map.put("code","user.notexist"); map.put("message",e.getMessage()); return map; &#125;&#125;//没有自适应效果... ​ 2）、转发到/error进行自适应响应效果处理 1234567891011121314@ExceptionHandler(UserNotExistException.class) public String handleException(Exception e, HttpServletRequest request)&#123; Map&lt;String,Object&gt; map = new HashMap&lt;&gt;(); //传入我们自己的错误状态码 4xx 5xx，否则就不会进入定制错误页面的解析流程 /** * Integer statusCode = (Integer) request .getAttribute("javax.servlet.error.status_code"); */ request.setAttribute("javax.servlet.error.status_code",500); map.put("code","user.notexist"); map.put("message",e.getMessage()); //转发到/error return "forward:/error"; &#125; 3）、将我们的定制数据携带出去；出现错误以后，会来到/error请求，会被BasicErrorController处理，响应出去可以获取的数据是由getErrorAttributes得到的（是AbstractErrorController（ErrorController）规定的方法）； ​ 1、完全来编写一个ErrorController的实现类【或者是编写AbstractErrorController的子类】，放在容器中； ​ 2、页面上能用的数据，或者是json返回能用的数据都是通过errorAttributes.getErrorAttributes得到； ​ 容器中DefaultErrorAttributes.getErrorAttributes()；默认进行数据处理的； 自定义ErrorAttributes 1234567891011//给容器中加入我们自己定义的ErrorAttributes@Componentpublic class MyErrorAttributes extends DefaultErrorAttributes &#123; @Override public Map&lt;String, Object&gt; getErrorAttributes(RequestAttributes requestAttributes, boolean includeStackTrace) &#123; Map&lt;String, Object&gt; map = super.getErrorAttributes(requestAttributes, includeStackTrace); map.put("company","atguigu"); return map; &#125;&#125; 最终的效果：响应是自适应的，可以通过定制ErrorAttributes改变需要返回的内容， 8、配置嵌入式Servlet容器SpringBoot默认使用Tomcat作为嵌入式的Servlet容器； 问题？ 1）、如何定制和修改Servlet容器的相关配置；1、修改和server有关的配置（ServerProperties【也是EmbeddedServletContainerCustomizer】）； 123456789server.port=8081server.context-path=/crudserver.tomcat.uri-encoding=UTF-8//通用的Servlet容器设置server.xxx//Tomcat的设置server.tomcat.xxx 2、编写一个EmbeddedServletContainerCustomizer：嵌入式的Servlet容器的定制器；来修改Servlet容器的配置 1234567891011@Bean //一定要将这个定制器加入到容器中public EmbeddedServletContainerCustomizer embeddedServletContainerCustomizer()&#123; return new EmbeddedServletContainerCustomizer() &#123; //定制嵌入式的Servlet容器相关的规则 @Override public void customize(ConfigurableEmbeddedServletContainer container) &#123; container.setPort(8083); &#125; &#125;;&#125; 2）、注册Servlet三大组件【Servlet、Filter、Listener】由于SpringBoot默认是以jar包的方式启动嵌入式的Servlet容器来启动SpringBoot的web应用，没有web.xml文件。 注册三大组件用以下方式 ServletRegistrationBean 123456//注册三大组件@Beanpublic ServletRegistrationBean myServlet()&#123; ServletRegistrationBean registrationBean = new ServletRegistrationBean(new MyServlet(),"/myServlet"); return registrationBean;&#125; FilterRegistrationBean 1234567@Beanpublic FilterRegistrationBean myFilter()&#123; FilterRegistrationBean registrationBean = new FilterRegistrationBean(); registrationBean.setFilter(new MyFilter()); registrationBean.setUrlPatterns(Arrays.asList("/hello","/myServlet")); return registrationBean;&#125; ServletListenerRegistrationBean 12345@Beanpublic ServletListenerRegistrationBean myListener()&#123; ServletListenerRegistrationBean&lt;MyListener&gt; registrationBean = new ServletListenerRegistrationBean&lt;&gt;(new MyListener()); return registrationBean;&#125; SpringBoot帮我们自动SpringMVC的时候，自动的注册SpringMVC的前端控制器；DIspatcherServlet； DispatcherServletAutoConfiguration中： 1234567891011121314151617@Bean(name = DEFAULT_DISPATCHER_SERVLET_REGISTRATION_BEAN_NAME)@ConditionalOnBean(value = DispatcherServlet.class, name = DEFAULT_DISPATCHER_SERVLET_BEAN_NAME)public ServletRegistrationBean dispatcherServletRegistration( DispatcherServlet dispatcherServlet) &#123; ServletRegistrationBean registration = new ServletRegistrationBean( dispatcherServlet, this.serverProperties.getServletMapping()); //默认拦截： / 所有请求；包静态资源，但是不拦截jsp请求； /*会拦截jsp //可以通过server.servletPath来修改SpringMVC前端控制器默认拦截的请求路径 registration.setName(DEFAULT_DISPATCHER_SERVLET_BEAN_NAME); registration.setLoadOnStartup( this.webMvcProperties.getServlet().getLoadOnStartup()); if (this.multipartConfig != null) &#123; registration.setMultipartConfig(this.multipartConfig); &#125; return registration;&#125; 2）、SpringBoot能不能支持其他的Servlet容器； 3）、替换为其他嵌入式Servlet容器 默认支持： Tomcat（默认使用） 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; 引入web模块默认就是使用嵌入式的Tomcat作为Servlet容器；&lt;/dependency&gt; Jetty 1234567891011121314151617&lt;!-- 引入web模块 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt;&lt;!--引入其他的Servlet容器--&gt;&lt;dependency&gt; &lt;artifactId&gt;spring-boot-starter-jetty&lt;/artifactId&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&lt;/dependency&gt; Undertow 1234567891011121314151617&lt;!-- 引入web模块 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt;&lt;!--引入其他的Servlet容器--&gt;&lt;dependency&gt; &lt;artifactId&gt;spring-boot-starter-undertow&lt;/artifactId&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&lt;/dependency&gt; 4）、嵌入式Servlet容器自动配置原理；EmbeddedServletContainerAutoConfiguration：嵌入式的Servlet容器自动配置？ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051@AutoConfigureOrder(Ordered.HIGHEST_PRECEDENCE)@Configuration@ConditionalOnWebApplication@Import(BeanPostProcessorsRegistrar.class)//导入BeanPostProcessorsRegistrar：Spring注解版；给容器中导入一些组件//导入了EmbeddedServletContainerCustomizerBeanPostProcessor：//后置处理器：bean初始化前后（创建完对象，还没赋值赋值）执行初始化工作public class EmbeddedServletContainerAutoConfiguration &#123; @Configuration @ConditionalOnClass(&#123; Servlet.class, Tomcat.class &#125;)//判断当前是否引入了Tomcat依赖； @ConditionalOnMissingBean(value = EmbeddedServletContainerFactory.class, search = SearchStrategy.CURRENT)//判断当前容器没有用户自己定义EmbeddedServletContainerFactory：嵌入式的Servlet容器工厂；作用：创建嵌入式的Servlet容器 public static class EmbeddedTomcat &#123; @Bean public TomcatEmbeddedServletContainerFactory tomcatEmbeddedServletContainerFactory() &#123; return new TomcatEmbeddedServletContainerFactory(); &#125; &#125; /** * Nested configuration if Jetty is being used. */ @Configuration @ConditionalOnClass(&#123; Servlet.class, Server.class, Loader.class, WebAppContext.class &#125;) @ConditionalOnMissingBean(value = EmbeddedServletContainerFactory.class, search = SearchStrategy.CURRENT) public static class EmbeddedJetty &#123; @Bean public JettyEmbeddedServletContainerFactory jettyEmbeddedServletContainerFactory() &#123; return new JettyEmbeddedServletContainerFactory(); &#125; &#125; /** * Nested configuration if Undertow is being used. */ @Configuration @ConditionalOnClass(&#123; Servlet.class, Undertow.class, SslClientAuthMode.class &#125;) @ConditionalOnMissingBean(value = EmbeddedServletContainerFactory.class, search = SearchStrategy.CURRENT) public static class EmbeddedUndertow &#123; @Bean public UndertowEmbeddedServletContainerFactory undertowEmbeddedServletContainerFactory() &#123; return new UndertowEmbeddedServletContainerFactory(); &#125; &#125; 1）、EmbeddedServletContainerFactory（嵌入式Servlet容器工厂） 1234567public interface EmbeddedServletContainerFactory &#123; //获取嵌入式的Servlet容器 EmbeddedServletContainer getEmbeddedServletContainer( ServletContextInitializer... initializers);&#125; 2）、EmbeddedServletContainer：（嵌入式的Servlet容器） 3）、以TomcatEmbeddedServletContainerFactory为例 123456789101112131415161718192021222324@Overridepublic EmbeddedServletContainer getEmbeddedServletContainer( ServletContextInitializer... initializers) &#123; //创建一个Tomcat Tomcat tomcat = new Tomcat(); //配置Tomcat的基本环节 File baseDir = (this.baseDirectory != null ? this.baseDirectory : createTempDir("tomcat")); tomcat.setBaseDir(baseDir.getAbsolutePath()); Connector connector = new Connector(this.protocol); tomcat.getService().addConnector(connector); customizeConnector(connector); tomcat.setConnector(connector); tomcat.getHost().setAutoDeploy(false); configureEngine(tomcat.getEngine()); for (Connector additionalConnector : this.additionalTomcatConnectors) &#123; tomcat.getService().addConnector(additionalConnector); &#125; prepareContext(tomcat.getHost(), initializers); //将配置好的Tomcat传入进去，返回一个EmbeddedServletContainer；并且启动Tomcat服务器 return getTomcatEmbeddedServletContainer(tomcat);&#125; 4）、我们对嵌入式容器的配置修改是怎么生效？ 1ServerProperties、EmbeddedServletContainerCustomizer EmbeddedServletContainerCustomizer：定制器帮我们修改了Servlet容器的配置？ 怎么修改的原理？ 5）、容器中导入了EmbeddedServletContainerCustomizerBeanPostProcessor 12345678910111213141516171819202122232425262728293031323334353637//初始化之前@Overridepublic Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException &#123; //如果当前初始化的是一个ConfigurableEmbeddedServletContainer类型的组件 if (bean instanceof ConfigurableEmbeddedServletContainer) &#123; // postProcessBeforeInitialization((ConfigurableEmbeddedServletContainer) bean); &#125; return bean;&#125;private void postProcessBeforeInitialization( ConfigurableEmbeddedServletContainer bean) &#123; //获取所有的定制器，调用每一个定制器的customize方法来给Servlet容器进行属性赋值； for (EmbeddedServletContainerCustomizer customizer : getCustomizers()) &#123; customizer.customize(bean); &#125;&#125;private Collection&lt;EmbeddedServletContainerCustomizer&gt; getCustomizers() &#123; if (this.customizers == null) &#123; // Look up does not include the parent context this.customizers = new ArrayList&lt;EmbeddedServletContainerCustomizer&gt;( this.beanFactory //从容器中获取所有这葛类型的组件：EmbeddedServletContainerCustomizer //定制Servlet容器，给容器中可以添加一个EmbeddedServletContainerCustomizer类型的组件 .getBeansOfType(EmbeddedServletContainerCustomizer.class, false, false) .values()); Collections.sort(this.customizers, AnnotationAwareOrderComparator.INSTANCE); this.customizers = Collections.unmodifiableList(this.customizers); &#125; return this.customizers;&#125;ServerProperties也是定制器 步骤： 1）、SpringBoot根据导入的依赖情况，给容器中添加相应的EmbeddedServletContainerFactory【TomcatEmbeddedServletContainerFactory】 2）、容器中某个组件要创建对象就会惊动后置处理器；EmbeddedServletContainerCustomizerBeanPostProcessor； 只要是嵌入式的Servlet容器工厂，后置处理器就工作； 3）、后置处理器，从容器中获取所有的EmbeddedServletContainerCustomizer，调用定制器的定制方法 ###5）、嵌入式Servlet容器启动原理； 什么时候创建嵌入式的Servlet容器工厂？什么时候获取嵌入式的Servlet容器并启动Tomcat； 获取嵌入式的Servlet容器工厂： 1）、SpringBoot应用启动运行run方法 2）、refreshContext(context);SpringBoot刷新IOC容器【创建IOC容器对象，并初始化容器，创建容器中的每一个组件】；如果是web应用创建AnnotationConfigEmbeddedWebApplicationContext，否则：AnnotationConfigApplicationContext 3）、refresh(context);刷新刚才创建好的ioc容器； 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263public void refresh() throws BeansException, IllegalStateException &#123; synchronized (this.startupShutdownMonitor) &#123; // Prepare this context for refreshing. prepareRefresh(); // Tell the subclass to refresh the internal bean factory. ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory(); // Prepare the bean factory for use in this context. prepareBeanFactory(beanFactory); try &#123; // Allows post-processing of the bean factory in context subclasses. postProcessBeanFactory(beanFactory); // Invoke factory processors registered as beans in the context. invokeBeanFactoryPostProcessors(beanFactory); // Register bean processors that intercept bean creation. registerBeanPostProcessors(beanFactory); // Initialize message source for this context. initMessageSource(); // Initialize event multicaster for this context. initApplicationEventMulticaster(); // Initialize other special beans in specific context subclasses. onRefresh(); // Check for listener beans and register them. registerListeners(); // Instantiate all remaining (non-lazy-init) singletons. finishBeanFactoryInitialization(beanFactory); // Last step: publish corresponding event. finishRefresh(); &#125; catch (BeansException ex) &#123; if (logger.isWarnEnabled()) &#123; logger.warn("Exception encountered during context initialization - " + "cancelling refresh attempt: " + ex); &#125; // Destroy already created singletons to avoid dangling resources. destroyBeans(); // Reset 'active' flag. cancelRefresh(ex); // Propagate exception to caller. throw ex; &#125; finally &#123; // Reset common introspection caches in Spring's core, since we // might not ever need metadata for singleton beans anymore... resetCommonCaches(); &#125; &#125;&#125; 4）、 onRefresh(); web的ioc容器重写了onRefresh方法 5）、webioc容器会创建嵌入式的Servlet容器；createEmbeddedServletContainer(); 6）、获取嵌入式的Servlet容器工厂： EmbeddedServletContainerFactory containerFactory = getEmbeddedServletContainerFactory(); ​ 从ioc容器中获取EmbeddedServletContainerFactory 组件；TomcatEmbeddedServletContainerFactory创建对象，后置处理器一看是这个对象，就获取所有的定制器来先定制Servlet容器的相关配置； 7）、使用容器工厂获取嵌入式的Servlet容器：this.embeddedServletContainer = containerFactory .getEmbeddedServletContainer(getSelfInitializer()); 8）、嵌入式的Servlet容器创建对象并启动Servlet容器； 先启动嵌入式的Servlet容器，再将ioc容器中剩下没有创建出的对象获取出来； ==IOC容器启动创建嵌入式的Servlet容器== 9、使用外置的Servlet容器嵌入式Servlet容器：应用打成可执行的jar ​ 优点：简单、便携； ​ 缺点：默认不支持JSP、优化定制比较复杂（使用定制器【ServerProperties、自定义EmbeddedServletContainerCustomizer】，自己编写嵌入式Servlet容器的创建工厂【EmbeddedServletContainerFactory】）； 外置的Servlet容器：外面安装Tomcat—应用war包的方式打包； 步骤1）、必须创建一个war项目；（利用idea创建好目录结构） 2）、将嵌入式的Tomcat指定为provided； 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt; 3）、必须编写一个SpringBootServletInitializer的子类，并调用configure方法 123456789public class ServletInitializer extends SpringBootServletInitializer &#123; @Override protected SpringApplicationBuilder configure(SpringApplicationBuilder application) &#123; //传入SpringBoot应用的主程序 return application.sources(SpringBoot04WebJspApplication.class); &#125;&#125; 4）、启动服务器就可以使用； 原理jar包：执行SpringBoot主类的main方法，启动ioc容器，创建嵌入式的Servlet容器； war包：启动服务器，服务器启动SpringBoot应用【SpringBootServletInitializer】，启动ioc容器； servlet3.0（Spring注解版）： 8.2.4 Shared libraries / runtimes pluggability： 规则： ​ 1）、服务器启动（web应用启动）会创建当前web应用里面每一个jar包里面ServletContainerInitializer实例： ​ 2）、ServletContainerInitializer的实现放在jar包的META-INF/services文件夹下，有一个名为javax.servlet.ServletContainerInitializer的文件，内容就是ServletContainerInitializer的实现类的全类名 ​ 3）、还可以使用@HandlesTypes，在应用启动的时候加载我们感兴趣的类； 流程： 1）、启动Tomcat 2）、org\springframework\spring-web\4.3.14.RELEASE\spring-web-4.3.14.RELEASE.jar!\META-INF\services\javax.servlet.ServletContainerInitializer： Spring的web模块里面有这个文件：org.springframework.web.SpringServletContainerInitializer 3）、SpringServletContainerInitializer将@HandlesTypes(WebApplicationInitializer.class)标注的所有这个类型的类都传入到onStartup方法的Set&lt;Class&lt;?&gt;&gt;；为这些WebApplicationInitializer类型的类创建实例； 4）、每一个WebApplicationInitializer都调用自己的onStartup； 5）、相当于我们的SpringBootServletInitializer的类会被创建对象，并执行onStartup方法 6）、SpringBootServletInitializer实例执行onStartup的时候会createRootApplicationContext；创建容器 1234567891011121314151617181920212223242526272829303132333435363738protected WebApplicationContext createRootApplicationContext( ServletContext servletContext) &#123; //1、创建SpringApplicationBuilder SpringApplicationBuilder builder = createSpringApplicationBuilder(); StandardServletEnvironment environment = new StandardServletEnvironment(); environment.initPropertySources(servletContext, null); builder.environment(environment); builder.main(getClass()); ApplicationContext parent = getExistingRootWebApplicationContext(servletContext); if (parent != null) &#123; this.logger.info("Root context already created (using as parent)."); servletContext.setAttribute( WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE, null); builder.initializers(new ParentContextApplicationContextInitializer(parent)); &#125; builder.initializers( new ServletContextApplicationContextInitializer(servletContext)); builder.contextClass(AnnotationConfigEmbeddedWebApplicationContext.class); //调用configure方法，子类重写了这个方法，将SpringBoot的主程序类传入了进来 builder = configure(builder); //使用builder创建一个Spring应用 SpringApplication application = builder.build(); if (application.getSources().isEmpty() &amp;&amp; AnnotationUtils .findAnnotation(getClass(), Configuration.class) != null) &#123; application.getSources().add(getClass()); &#125; Assert.state(!application.getSources().isEmpty(), "No SpringApplication sources have been defined. Either override the " + "configure method or add an @Configuration annotation"); // Ensure error pages are registered if (this.registerErrorPageFilter) &#123; application.getSources().add(ErrorPageFilterConfiguration.class); &#125; //启动Spring应用 return run(application);&#125; 7）、Spring的应用就启动并且创建IOC容器 1234567891011121314151617181920212223242526272829303132333435public ConfigurableApplicationContext run(String... args) &#123; StopWatch stopWatch = new StopWatch(); stopWatch.start(); ConfigurableApplicationContext context = null; FailureAnalyzers analyzers = null; configureHeadlessProperty(); SpringApplicationRunListeners listeners = getRunListeners(args); listeners.starting(); try &#123; ApplicationArguments applicationArguments = new DefaultApplicationArguments( args); ConfigurableEnvironment environment = prepareEnvironment(listeners, applicationArguments); Banner printedBanner = printBanner(environment); context = createApplicationContext(); analyzers = new FailureAnalyzers(context); prepareContext(context, environment, listeners, applicationArguments, printedBanner); //刷新IOC容器 refreshContext(context); afterRefresh(context, applicationArguments); listeners.finished(context, null); stopWatch.stop(); if (this.logStartupInfo) &#123; new StartupInfoLogger(this.mainApplicationClass) .logStarted(getApplicationLog(), stopWatch); &#125; return context; &#125; catch (Throwable ex) &#123; handleRunFailure(context, listeners, analyzers, ex); throw new IllegalStateException(ex); &#125;&#125; ==启动Servlet容器，再启动SpringBoot应用== 五、Docker1、简介Docker是一个开源的应用容器引擎；是一个轻量级容器技术； Docker支持将软件编译成一个镜像；然后在镜像中各种软件做好配置，将镜像发布出去，其他使用者可以直接使用这个镜像； 运行中的这个镜像称为容器，容器启动是非常快速的。 2、核心概念docker主机(Host)：安装了Docker程序的机器（Docker直接安装在操作系统之上）； docker客户端(Client)：连接docker主机进行操作； docker仓库(Registry)：用来保存各种打包好的软件镜像； docker镜像(Images)：软件打包好的镜像；放在docker仓库中； docker容器(Container)：镜像启动后的实例称为一个容器；容器是独立运行的一个或一组应用 使用Docker的步骤： 1）、安装Docker 2）、去Docker仓库找到这个软件对应的镜像； 3）、使用Docker运行这个镜像，这个镜像就会生成一个Docker容器； 4）、对容器的启动停止就是对软件的启动停止； 3、安装Docker1）、安装linux虚拟机​ 1）、VMWare、VirtualBox（安装）； ​ 2）、导入虚拟机文件centos7-atguigu.ova； ​ 3）、双击启动linux虚拟机;使用 root/ 123456登陆 ​ 4）、使用客户端连接linux服务器进行命令操作； ​ 5）、设置虚拟机网络； ​ 桥接网络===选好网卡====接入网线； ​ 6）、设置好网络以后使用命令重启虚拟机的网络 1service network restart ​ 7）、查看linux的ip地址 1ip addr ​ 8）、使用客户端连接linux； 2）、在linux虚拟机上安装docker步骤： 12345678910111213141、检查内核版本，必须是3.10及以上uname -r2、安装dockeryum install docker3、输入y确认安装4、启动docker[root@localhost ~]# systemctl start docker[root@localhost ~]# docker -vDocker version 1.12.6, build 3e8e77d/1.12.65、开机启动docker[root@localhost ~]# systemctl enable dockerCreated symlink from /etc/systemd/system/multi-user.target.wants/docker.service to /usr/lib/systemd/system/docker.service.6、停止dockersystemctl stop docker 4、Docker常用命令&amp;操作1）、镜像操作 操作 命令 说明 检索 docker search 关键字 eg：docker search redis 我们经常去docker hub上检索镜像的详细信息，如镜像的TAG。 拉取 docker pull 镜像名:tag :tag是可选的，tag表示标签，多为软件的版本，默认是latest 列表 docker images 查看所有本地镜像 删除 docker rmi image-id 删除指定的本地镜像 https://hub.docker.com/ 2）、容器操作软件镜像（QQ安装程序）—-运行镜像—-产生一个容器（正在运行的软件，运行的QQ）； 步骤： 1234567891011121314151617181920212223242526272829301、搜索镜像[root@localhost ~]# docker search tomcat2、拉取镜像[root@localhost ~]# docker pull tomcat3、根据镜像启动容器docker run --name mytomcat -d tomcat:latest4、docker ps 查看运行中的容器5、 停止运行中的容器docker stop 容器的id6、查看所有的容器docker ps -a7、启动容器docker start 容器id8、删除一个容器 docker rm 容器id9、启动一个做了端口映射的tomcat[root@localhost ~]# docker run -d -p 8888:8080 tomcat-d：后台运行-p: 将主机的端口映射到容器的一个端口 主机端口:容器内部的端口10、为了演示简单关闭了linux的防火墙service firewalld status ；查看防火墙状态service firewalld stop：关闭防火墙11、查看容器的日志docker logs container-name/container-id更多命令参看https://docs.docker.com/engine/reference/commandline/docker/可以参考每一个镜像的文档 3）、安装MySQL示例1docker pull mysql 错误的启动 1234567891011121314151617[root@localhost ~]# docker run --name mysql01 -d mysql42f09819908bb72dd99ae19e792e0a5d03c48638421fa64cce5f8ba0f40f5846mysql退出了[root@localhost ~]# docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES42f09819908b mysql "docker-entrypoint.sh" 34 seconds ago Exited (1) 33 seconds ago mysql01538bde63e500 tomcat "catalina.sh run" About an hour ago Exited (143) About an hour ago compassionate_goldstinec4f1ac60b3fc tomcat "catalina.sh run" About an hour ago Exited (143) About an hour ago lonely_fermi81ec743a5271 tomcat "catalina.sh run" About an hour ago Exited (143) About an hour ago sick_ramanujan//错误日志[root@localhost ~]# docker logs 42f09819908berror: database is uninitialized and password option is not specified You need to specify one of MYSQL_ROOT_PASSWORD, MYSQL_ALLOW_EMPTY_PASSWORD and MYSQL_RANDOM_ROOT_PASSWORD；这个三个参数必须指定一个 正确的启动 12345[root@localhost ~]# docker run --name mysql01 -e MYSQL_ROOT_PASSWORD=123456 -d mysqlb874c56bec49fb43024b3805ab51e9097da779f2f572c22c695305dedd684c5f[root@localhost ~]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESb874c56bec49 mysql "docker-entrypoint.sh" 4 seconds ago Up 3 seconds 3306/tcp mysql01 做了端口映射 12345[root@localhost ~]# docker run -p 3306:3306 --name mysql02 -e MYSQL_ROOT_PASSWORD=123456 -d mysqlad10e4bc5c6a0f61cbad43898de71d366117d120e39db651844c0e73863b9434[root@localhost ~]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESad10e4bc5c6a mysql "docker-entrypoint.sh" 4 seconds ago Up 2 seconds 0.0.0.0:3306-&gt;3306/tcp mysql02 几个其他的高级操作 123456docker run --name mysql03 -v /conf/mysql:/etc/mysql/conf.d -e MYSQL_ROOT_PASSWORD=my-secret-pw -d mysql:tag把主机的/conf/mysql文件夹挂载到 mysqldocker容器的/etc/mysql/conf.d文件夹里面改mysql的配置文件就只需要把mysql配置文件放在自定义的文件夹下（/conf/mysql）docker run --name some-mysql -e MYSQL_ROOT_PASSWORD=my-secret-pw -d mysql:tag --character-set-server=utf8mb4 --collation-server=utf8mb4_unicode_ci指定mysql的一些配置参数 六、SpringBoot与数据访问1、JDBC123456789&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-jdbc&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; 123456spring: datasource: username: root password: 123456 url: jdbc:mysql://192.168.15.22:3306/jdbc driver-class-name: com.mysql.jdbc.Driver 效果： ​ 默认是用org.apache.tomcat.jdbc.pool.DataSource作为数据源； ​ 数据源的相关配置都在DataSourceProperties里面； 自动配置原理： org.springframework.boot.autoconfigure.jdbc： 1、参考DataSourceConfiguration，根据配置创建数据源，默认使用Tomcat连接池；可以使用spring.datasource.type指定自定义的数据源类型； 2、SpringBoot默认可以支持； 1org.apache.tomcat.jdbc.pool.DataSource、HikariDataSource、BasicDataSource、 3、自定义数据源类型 1234567891011121314/** * Generic DataSource configuration. */@ConditionalOnMissingBean(DataSource.class)@ConditionalOnProperty(name = "spring.datasource.type")static class Generic &#123; @Bean public DataSource dataSource(DataSourceProperties properties) &#123; //使用DataSourceBuilder创建数据源，利用反射创建响应type的数据源，并且绑定相关属性 return properties.initializeDataSourceBuilder().build(); &#125;&#125; 4、DataSourceInitializer：ApplicationListener； ​ 作用： ​ 1）、runSchemaScripts();运行建表语句； ​ 2）、runDataScripts();运行插入数据的sql语句； 默认只需要将文件命名为： 123456schema-*.sql、data-*.sql默认规则：schema.sql，schema-all.sql；可以使用 schema: - classpath:department.sql 指定位置 5、操作数据库：自动配置了JdbcTemplate操作数据库 2、整合Druid数据源12345678910111213141516171819202122232425262728293031323334353637383940414243导入druid数据源@Configurationpublic class DruidConfig &#123; @ConfigurationProperties(prefix = "spring.datasource") @Bean public DataSource druid()&#123; return new DruidDataSource(); &#125; //配置Druid的监控 //1、配置一个管理后台的Servlet @Bean public ServletRegistrationBean statViewServlet()&#123; ServletRegistrationBean bean = new ServletRegistrationBean(new StatViewServlet(), "/druid/*"); Map&lt;String,String&gt; initParams = new HashMap&lt;&gt;(); initParams.put("loginUsername","admin"); initParams.put("loginPassword","123456"); initParams.put("allow","");//默认就是允许所有访问 initParams.put("deny","192.168.15.21"); bean.setInitParameters(initParams); return bean; &#125; //2、配置一个web监控的filter @Bean public FilterRegistrationBean webStatFilter()&#123; FilterRegistrationBean bean = new FilterRegistrationBean(); bean.setFilter(new WebStatFilter()); Map&lt;String,String&gt; initParams = new HashMap&lt;&gt;(); initParams.put("exclusions","*.js,*.css,/druid/*"); bean.setInitParameters(initParams); bean.setUrlPatterns(Arrays.asList("/*")); return bean; &#125;&#125; 3、整合MyBatis12345&lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.3.1&lt;/version&gt;&lt;/dependency&gt; 步骤： ​ 1）、配置数据源相关属性（见上一节Druid） ​ 2）、给数据库建表 ​ 3）、创建JavaBean 4）、注解版1234567891011121314151617//指定这是一个操作数据库的mapper@Mapperpublic interface DepartmentMapper &#123; @Select("select * from department where id=#&#123;id&#125;") public Department getDeptById(Integer id); @Delete("delete from department where id=#&#123;id&#125;") public int deleteDeptById(Integer id); @Options(useGeneratedKeys = true,keyProperty = "id") @Insert("insert into department(departmentName) values(#&#123;departmentName&#125;)") public int insertDept(Department department); @Update("update department set departmentName=#&#123;departmentName&#125; where id=#&#123;id&#125;") public int updateDept(Department department);&#125; 问题： 自定义MyBatis的配置规则；给容器中添加一个ConfigurationCustomizer； 1234567891011121314@org.springframework.context.annotation.Configurationpublic class MyBatisConfig &#123; @Bean public ConfigurationCustomizer configurationCustomizer()&#123; return new ConfigurationCustomizer()&#123; @Override public void customize(Configuration configuration) &#123; configuration.setMapUnderscoreToCamelCase(true); &#125; &#125;; &#125;&#125; 123456789使用MapperScan批量扫描所有的Mapper接口；@MapperScan(value = "com.atguigu.springboot.mapper")@SpringBootApplicationpublic class SpringBoot06DataMybatisApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringBoot06DataMybatisApplication.class, args); &#125;&#125; 5）、配置文件版123mybatis: config-location: classpath:mybatis/mybatis-config.xml 指定全局配置文件的位置 mapper-locations: classpath:mybatis/mapper/*.xml 指定sql映射文件的位置 更多使用参照 http://www.mybatis.org/spring-boot-starter/mybatis-spring-boot-autoconfigure/ 4、整合SpringData JPA1）、SpringData简介 2）、整合SpringData JPAJPA:ORM（Object Relational Mapping）； 1）、编写一个实体类（bean）和数据表进行映射，并且配置好映射关系； 12345678910111213//使用JPA注解配置映射关系@Entity //告诉JPA这是一个实体类（和数据表映射的类）@Table(name = "tbl_user") //@Table来指定和哪个数据表对应;如果省略默认表名就是user；public class User &#123; @Id //这是一个主键 @GeneratedValue(strategy = GenerationType.IDENTITY)//自增主键 private Integer id; @Column(name = "last_name",length = 50) //这是和数据表对应的一个列 private String lastName; @Column //省略默认列名就是属性名 private String email; 2）、编写一个Dao接口来操作实体类对应的数据表（Repository） 123//继承JpaRepository来完成对数据库的操作public interface UserRepository extends JpaRepository&lt;User,Integer&gt; &#123;&#125; 3）、基本的配置JpaProperties 1234567spring: jpa: hibernate:# 更新或者创建数据表结构 ddl-auto: update# 控制台显示SQL show-sql: true 七、启动配置原理几个重要的事件回调机制 配置在META-INF/spring.factories ApplicationContextInitializer SpringApplicationRunListener 只需要放在ioc容器中 ApplicationRunner CommandLineRunner 启动流程： 1、创建SpringApplication对象12345678910111213141516initialize(sources);private void initialize(Object[] sources) &#123; //保存主配置类 if (sources != null &amp;&amp; sources.length &gt; 0) &#123; this.sources.addAll(Arrays.asList(sources)); &#125; //判断当前是否一个web应用 this.webEnvironment = deduceWebEnvironment(); //从类路径下找到META-INF/spring.factories配置的所有ApplicationContextInitializer；然后保存起来 setInitializers((Collection) getSpringFactoriesInstances( ApplicationContextInitializer.class)); //从类路径下找到ETA-INF/spring.factories配置的所有ApplicationListener setListeners((Collection) getSpringFactoriesInstances(ApplicationListener.class)); //从多个配置类中找到有main方法的主配置类 this.mainApplicationClass = deduceMainApplicationClass();&#125; 2、运行run方法12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public ConfigurableApplicationContext run(String... args) &#123; StopWatch stopWatch = new StopWatch(); stopWatch.start(); ConfigurableApplicationContext context = null; FailureAnalyzers analyzers = null; configureHeadlessProperty(); //获取SpringApplicationRunListeners；从类路径下META-INF/spring.factories SpringApplicationRunListeners listeners = getRunListeners(args); //回调所有的获取SpringApplicationRunListener.starting()方法 listeners.starting(); try &#123; //封装命令行参数 ApplicationArguments applicationArguments = new DefaultApplicationArguments( args); //准备环境 ConfigurableEnvironment environment = prepareEnvironment(listeners, applicationArguments); //创建环境完成后回调SpringApplicationRunListener.environmentPrepared()；表示环境准备完成 Banner printedBanner = printBanner(environment); //创建ApplicationContext；决定创建web的ioc还是普通的ioc context = createApplicationContext(); analyzers = new FailureAnalyzers(context); //准备上下文环境;将environment保存到ioc中；而且applyInitializers()； //applyInitializers()：回调之前保存的所有的ApplicationContextInitializer的initialize方法 //回调所有的SpringApplicationRunListener的contextPrepared()； // prepareContext(context, environment, listeners, applicationArguments, printedBanner); //prepareContext运行完成以后回调所有的SpringApplicationRunListener的contextLoaded（）； //s刷新容器；ioc容器初始化（如果是web应用还会创建嵌入式的Tomcat）；Spring注解版 //扫描，创建，加载所有组件的地方；（配置类，组件，自动配置） refreshContext(context); //从ioc容器中获取所有的ApplicationRunner和CommandLineRunner进行回调 //ApplicationRunner先回调，CommandLineRunner再回调 afterRefresh(context, applicationArguments); //所有的SpringApplicationRunListener回调finished方法 listeners.finished(context, null); stopWatch.stop(); if (this.logStartupInfo) &#123; new StartupInfoLogger(this.mainApplicationClass) .logStarted(getApplicationLog(), stopWatch); &#125; //整个SpringBoot应用启动完成以后返回启动的ioc容器； return context; &#125; catch (Throwable ex) &#123; handleRunFailure(context, listeners, analyzers, ex); throw new IllegalStateException(ex); &#125;&#125; 3、事件监听机制配置在META-INF/spring.factories ApplicationContextInitializer 123456public class HelloApplicationContextInitializer implements ApplicationContextInitializer&lt;ConfigurableApplicationContext&gt; &#123; @Override public void initialize(ConfigurableApplicationContext applicationContext) &#123; System.out.println("ApplicationContextInitializer...initialize..."+applicationContext); &#125;&#125; SpringApplicationRunListener 123456789101112131415161718192021222324252627282930313233public class HelloSpringApplicationRunListener implements SpringApplicationRunListener &#123; //必须有的构造器 public HelloSpringApplicationRunListener(SpringApplication application, String[] args)&#123; &#125; @Override public void starting() &#123; System.out.println("SpringApplicationRunListener...starting..."); &#125; @Override public void environmentPrepared(ConfigurableEnvironment environment) &#123; Object o = environment.getSystemProperties().get("os.name"); System.out.println("SpringApplicationRunListener...environmentPrepared.."+o); &#125; @Override public void contextPrepared(ConfigurableApplicationContext context) &#123; System.out.println("SpringApplicationRunListener...contextPrepared..."); &#125; @Override public void contextLoaded(ConfigurableApplicationContext context) &#123; System.out.println("SpringApplicationRunListener...contextLoaded..."); &#125; @Override public void finished(ConfigurableApplicationContext context, Throwable exception) &#123; System.out.println("SpringApplicationRunListener...finished..."); &#125;&#125; 配置（META-INF/spring.factories） 12345org.springframework.context.ApplicationContextInitializer=\com.atguigu.springboot.listener.HelloApplicationContextInitializerorg.springframework.boot.SpringApplicationRunListener=\com.atguigu.springboot.listener.HelloSpringApplicationRunListener 只需要放在ioc容器中 ApplicationRunner 1234567@Componentpublic class HelloApplicationRunner implements ApplicationRunner &#123; @Override public void run(ApplicationArguments args) throws Exception &#123; System.out.println("ApplicationRunner...run...."); &#125;&#125; CommandLineRunner 1234567@Componentpublic class HelloCommandLineRunner implements CommandLineRunner &#123; @Override public void run(String... args) throws Exception &#123; System.out.println("CommandLineRunner...run..."+ Arrays.asList(args)); &#125;&#125; 八、自定义starterstarter： ​ 1、这个场景需要使用到的依赖是什么？ ​ 2、如何编写自动配置 12345678910111213@Configuration //指定这个类是一个配置类@ConditionalOnXXX //在指定条件成立的情况下自动配置类生效@AutoConfigureAfter //指定自动配置类的顺序@Bean //给容器中添加组件@ConfigurationPropertie结合相关xxxProperties类来绑定相关的配置@EnableConfigurationProperties //让xxxProperties生效加入到容器中自动配置类要能加载将需要启动就加载的自动配置类，配置在META-INF/spring.factoriesorg.springframework.boot.autoconfigure.EnableAutoConfiguration=\org.springframework.boot.autoconfigure.admin.SpringApplicationAdminJmxAutoConfiguration,\org.springframework.boot.autoconfigure.aop.AopAutoConfiguration,\ ​ 3、模式： 启动器只用来做依赖导入； 专门来写一个自动配置模块； 启动器依赖自动配置；别人只需要引入启动器（starter） mybatis-spring-boot-starter；自定义启动器名-spring-boot-starter 步骤： 1）、启动器模块 12345678910111213141516171819202122&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.atguigu.starter&lt;/groupId&gt; &lt;artifactId&gt;atguigu-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;!--启动器--&gt; &lt;dependencies&gt; &lt;!--引入自动配置模块--&gt; &lt;dependency&gt; &lt;groupId&gt;com.atguigu.starter&lt;/groupId&gt; &lt;artifactId&gt;atguigu-spring-boot-starter-autoconfigurer&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 2）、自动配置模块 123456789101112131415161718192021222324252627282930313233343536373839&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.atguigu.starter&lt;/groupId&gt; &lt;artifactId&gt;atguigu-spring-boot-starter-autoconfigurer&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;atguigu-spring-boot-starter-autoconfigurer&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.5.10.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;!--引入spring-boot-starter；所有starter的基本配置--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 1234567891011121314151617181920212223242526package com.atguigu.starter;import org.springframework.boot.context.properties.ConfigurationProperties;@ConfigurationProperties(prefix = "atguigu.hello")public class HelloProperties &#123; private String prefix; private String suffix; public String getPrefix() &#123; return prefix; &#125; public void setPrefix(String prefix) &#123; this.prefix = prefix; &#125; public String getSuffix() &#123; return suffix; &#125; public void setSuffix(String suffix) &#123; this.suffix = suffix; &#125;&#125; 123456789101112131415161718package com.atguigu.starter;public class HelloService &#123; HelloProperties helloProperties; public HelloProperties getHelloProperties() &#123; return helloProperties; &#125; public void setHelloProperties(HelloProperties helloProperties) &#123; this.helloProperties = helloProperties; &#125; public String sayHellAtguigu(String name)&#123; return helloProperties.getPrefix()+"-" +name + helloProperties.getSuffix(); &#125;&#125; 12345678910111213141516171819202122package com.atguigu.starter;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.autoconfigure.condition.ConditionalOnWebApplication;import org.springframework.boot.context.properties.EnableConfigurationProperties;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;@Configuration@ConditionalOnWebApplication //web应用才生效@EnableConfigurationProperties(HelloProperties.class)public class HelloServiceAutoConfiguration &#123; @Autowired HelloProperties helloProperties; @Bean public HelloService helloService()&#123; HelloService service = new HelloService(); service.setHelloProperties(helloProperties); return service; &#125;&#125; 更多SpringBoot整合示例https://github.com/spring-projects/spring-boot/tree/master/spring-boot-samples]]></content>
  </entry>
  <entry>
    <title><![CDATA[Java容器]]></title>
    <url>%2F2020%2F03%2F27%2FJava%E5%AE%B9%E5%99%A8%2F</url>
    <content type="text"><![CDATA[说说List,Set,Map三者的区别？ List(对付顺序的好帮手)： List接口存储一组不唯一（可以有多个元素引用相同的对象），有序的对象 Set(注重独一无二的性质): 不允许重复的集合。不会有多个元素引用相同的对象。 Map(用Key来搜索的专家): 使用键值对存储。Map会维护与Key有关联的值。两个Key可以引用相同的对象，但Key不能重复，典型的Key是String类型，但也可以是任何对象。 ArraylistJava的动态数组 以无参数构造方法创建 ArrayList 时，实际上初始化赋值的是一个空数组。当真正对数组进行添加元素操作时，才真正分配容量。即向数组中添加第一个元素时，数组容量扩为10 每次扩容大概是之前容量的1.5倍左右 123 //我们知道位运算的速度远远快于整除运算，整句运算式的结果就是将新容量更新为旧容量的1.5倍， int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1);//右移一位相当于/2，是奇数的化会丢掉小数 Arraylist 与 LinkedList 区别?1. 是否保证线程安全： ArrayList 和 LinkedList 都是不同步的，也就是不保证线程安全 2. 底层数据结构： Arraylist 底层使用的是 Object 数组；LinkedList 底层使用的是 双向链表 数据结构 3. 插入和删除是否受元素位置的影响： ① ArrayList 采用数组存储，所以插入和删除元素的时间复杂度受元素位置的影响。 比如：执行add(E e)方法的时候， ArrayList 会默认在将指定的元素追加到此列表的末尾，这种情况时间复杂度就是O(1)。但是如果要在指定位置 i 插入和删除元素的话（add(int index, E element)）时间复杂度就为 O(n-i)。因为在进行上述操作的时候集合中第 i 和第 i 个元素之后的(n-i)个元素都要执行向后位/向前移一位的操作。 ② LinkedList 采用链表存储，所以对于add(�E e)方法的插入，删除元素时间复杂度不受元素位置的影响，近似 O（1），如果是要在指定位置i插入和删除元素的话（(add(int index, E element)） 时间复杂度近似为o(n))因为需要先移动到指定位置再插入。 4. 是否支持快速随机访问： LinkedList 不支持高效的随机元素访问，而 ArrayList 支持。快速随机访问就是通过元素的序号快速获取元素对象(对应于get(int index)方法)。 5. 内存空间占用： ArrayList的空 间浪费主要体现在在list列表的结尾会预留一定的容量空间，而LinkedList的空间花费则体现在它的每一个元素都需要消耗比ArrayList更多的空间（因为要存放直接后继和直接前驱以及数据）。 ArrayList 与 Vector 区别呢?为什么要用Arraylist取代Vector呢？Vector类的所有方法都是同步的。可以由两个线程安全地访问一个Vector对象、但是一个线程访问Vector的话代码要在同步操作上耗费大量的时间。（其实就是加个Synchronized） Arraylist不是同步的，所以在不需要保证线程安全时建议使用Arraylist。 HashMap HashMap结构 1hashmap.put("1","2") // entry---&gt;key---&gt;---&gt;hash---&gt;index 会把key, value包装成一个entry对象，entry里面还需next属性。 为什么HashMap里数组的容量必须是2的幂次方 求数组下标： hashcode 与数组length-1 与操作 eg： length=16 0000 1111 与hashcode与操作后，得到的值会从0-15,符合我们的要求。 但如果数组容量是17 0001 0000 与hashcode与操作后，得到的值要么是0，要么是16，其它空间都浪费了。 JDK1.8为什么不用链表了 链表查询（get）效率太低 其实还是用的，当链表长度增加大于等于8时，将采用红黑树。 当链表长度（删除） 小于6时，改回链表。 为什么用红黑树，不用完全平衡二叉树 AVL树是更加严格的平衡，因此可以提供更快的查找速度，一般读取查找密集型任务，适用AVL树。 但平衡AVL树可能需要O（log n）旋转，而红黑树将需要最多两次旋转使其达到平衡(所以AVL插入复杂度更高) JDK1.7是头插法，1.8是尾插法 主要原因在于并发执行put操作时，可能会造成元素之间会形成一个循环链表，导致死循环。不过，jdk 1.8 后解决了这个问题，但是还是不建议在多线程下使用 HashMap,因为多线程下使用 HashMap 还是会存在其他问题比如数据丢失。并发环境下推荐使用 ConcurrentHashMap 。 HashSetHashSet 底层就是基于 HashMap 实现的. HashMap HashSet 实现了Map接口 实现Set接口 存储键值对 仅存储对象 调用 put（）向map中添加元素 调用 add（）方法向Set中添加元素 HashMap使用键（Key）计算Hashcode HashSet使用成员对象来计算hashcode值，对于两个对象来说hashcode可能相同，所以equals()方法用来判断对象的相等性， HashSet如何检查重复当你把对象加入HashSet时，HashSet会先计算对象的hashcode值来判断对象加入的位置，同时也会与其他加入的对象的hashcode值作比较，如果没有相符的hashcode，HashSet会假设对象没有重复出现。但是如果发现有相同hashcode值的对象，这时会调用equals（）方法来检查hashcode相等的对象是否真的相同。如果两者相同，HashSet就不会让加入操作成功。 HashSet使用不当会导致内存泄漏修改hashset中对象的属性值，且属性值是计算哈希值的字段，这时会引起内存泄漏 即：当一个对象被存储进HashSet集合中以后，就不能修改该对象的参与计算哈希值的属性值了，否则对象修改后的哈希值与最初存储进HashSet集合中时的哈希值就不同了，在这种情况下，即使在contains方法使用该对象的当前引用作为参数去HashSet集合中检索对象，也将返回找不到对象的结果，这也会导致无法从HashSet集合中删除当前对象，造成内存泄露。 hashCode（）与equals（）的相关规定： 如果两个对象相等，则hashcode一定也是相同的 两个对象相等,对两个equals方法返回true 两个对象有相同的hashcode值，它们也不一定是相等的 综上，equals方法被覆盖过，则hashCode方法也必须被覆盖 hashCode()的默认行为是对堆上的对象产生独特值。如果没有重写hashCode()，则该class的两个对象无论如何都不会相等（即使这两个对象指向相同的数据）。 自己理解：equls返回为true,则两者的hashcode一定相等，意即相等的对象必须具有相等的哈希码。每当equals方法被覆写，通常需要重写hashCode方法。 1234567891011121314151617181920212223242526public V put(K key, V value) &#123; if (table == EMPTY_TABLE) &#123; inflateTable(threshold); &#125; if (key == null) return putForNullKey(value); int hash = hash(key); int i = indexFor(hash, table.length); for (Entry&lt;K,V&gt; e = table[i]; e != null; e = e.next) &#123; Object k; //hashcode如果不同，短路，就会直接加入到hashset,hashmap /*如果没有重写Person类的hashcode方法，那么 Set&lt;Person&gt; set = new HashSet&lt;&gt;();可能会出现同一个Person */ if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) &#123; V oldValue = e.value; e.value = value; e.recordAccess(this); return oldValue; &#125; &#125; modCount++; addEntry(hash, key, value, i); return null; &#125; hashcode有啥用hashcode是用来快速查找的，如果你学过数据结构就应该知道，在查找和排序这一章有例如内存中有这样的位置0 1 2 3 4 5 6 7 而我有个类，这个类有个字段叫ID,我要把这个类存放在以上8个位置之一，如果不用hashcode而任意存放，那么当查找时就需要到这八个位置里挨个去找，或者用二分法一类的算法。但如果用hashcode那就会使效率提高很多。我们这个类中有个字段叫ID,那么我们就定义我们的hashcode为ID％8，然后把我们的类存放在取得得余数那个位置。比如我们的ID为9，9除8的余数为1，那么我们就把该类存在1这个位置，如果ID是13，求得的余数是5，那么我们就把该类放在5这个位置。这样，以后在查找该类时就可以通过ID除 8求余数直接找到存放的位置了。2.但是如果两个类有相同的hashcode怎么办那（我们假设上面的类的ID不是唯一的），例如9除以8和17除以8的余数都是1，那么这是不是合法的，回答是：可以这样。那么如何判断呢？在这个时候就需要定义 equals了。也就是说，我们先通过 hashcode来判断两个类是否存放某个桶里，但这个桶里可能有很多类，那么我们就需要再通过 equals 来在这个桶里找到我们要的类。 ==与equals ==既可以比较基本类型(比较值是否相等)， 也可以比较引用类型(比较地址是否相等) equals本身是object类的方法，如果没有被重写，比较的是地址；被重写后，有可能比较的是值(String) 为什么HashSet里value不是null?value是一个final修饰的、值为null的Object对象。 private static final Object PRESENT = new Object(); 如果value是null,而HashSet的remove是使用HashMap实现,则是map.remove 而map的移除会返回value,如果底层value都是存null,显然将无法分辨是否移除成功.因为没找到也返回null TreeMap &amp;&amp; LinkedHashMap(有序的map) 红黑树,继承自map,有序 名称 HashMap LinkedHashMap TreeMap 共同点 线程不安全 线程不安全 线程不安全 不同点 数据无序 数据有序（存储顺序） 数据有序还可以对数据进行排序 数据结构 数组+链表+红黑树 双向链表+HashMap 红黑树 HashTable是线程安全的，HashTable 内部的方法基本都经过synchronized 修饰。（如果你要保证线程安全的话就使用 ConcurrentHashMap 吧！）另外，HashTable 基本被淘汰，不要在代码中使用它。 HashMap 和 Hashtable 的区别 线程是否安全： HashMap 是非线程安全的，HashTable 是线程安全的；HashTable 内部的方法基本都经过synchronized 修饰。（如果你要保证线程安全的话就使用 ConcurrentHashMap 吧！）； 效率： 因为线程安全的问题，HashMap 要比 HashTable 效率高一点。另外，HashTable 基本被淘汰，不要在代码中使用它； 对Null key 和Null value的支持： HashMap 中，null 可以作为键，这样的键只有一个，可以有一个或多个键所对应的值为 null。。但是在 HashTable 中 put 进的键值只要有一个 null，直接抛出 NullPointerException。 初始容量大小和每次扩充容量大小的不同 ： ①创建时如果不指定容量初始值，Hashtable 默认的初始大小为11，之后每次扩充，容量变为原来的2n+1。HashMap 默认的初始化大小为16。之后每次扩充，容量变为原来的2倍。②创建时如果给定了容量初始值，那么 Hashtable 会直接使用你给定的大小，而 HashMap 会将其扩充为2的幂次方大小。 底层数据结构： JDK1.8 以后的 HashMap 在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为8）（将链表转换成红黑树前会判断，如果当前数组的长度小于 64，那么会选择先进行数组扩容，而不是转换为红黑树）时，将链表转化为红黑树，以减少搜索时间。Hashtable 没有这样的机制。 ConcurrentHashMap 和 Hashtable 的区别ConcurrentHashMap 和 Hashtable 的区别主要体现在实现线程安全的方式上不同。 底层数据结构： JDK1.7的 ConcurrentHashMap 底层采用 分段的数组+链表 实现，JDK1.8 采用的数据结构跟HashMap1.8的结构一样，数组+链表/红黑二叉树。Hashtable 和 JDK1.8 之前的 HashMap 的底层数据结构类似都是采用 数组+链表 的形式，数组是 HashMap 的主体，链表则是主要为了解决哈希冲突而存在的； 实现线程安全的方式（重要）： ① 在JDK1.7的时候，ConcurrentHashMap（分段锁） 对整个桶数组进行了分割分段(Segment)，每一把锁只锁容器其中一部分数据，多线程访问容器里不同数据段的数据，就不会存在锁竞争，提高并发访问率。 到了 JDK1.8 的时候已经摒弃了Segment的概念，而是直接用 Node 数组+链表+红黑树的数据结构来实现，并发控制使用 synchronized 和 CAS 来操作。（JDK1.6以后 对 synchronized锁做了很多优化） 整个看起来就像是优化过且线程安全的 HashMap，虽然在JDK1.8中还能看到 Segment 的数据结构，但是已经简化了属性，只是为了兼容旧版本；② Hashtable(同一把锁) :使用 synchronized 来保证线程安全，效率非常低下。当一个线程访问同步方法时，其他线程也访问同步方法，可能会进入阻塞或轮询状态，如使用 put 添加元素，另一个线程不能使用 put 添加元素，也不能使用 get，竞争会越来越激烈效率越低。 HashTable: JDK1.7的ConcurrentHashMap： JDK1.8的ConcurrentHashMap（TreeBin: 红黑二叉树节点 Node: 链表节点）： ConcurrentHashMap线程安全的具体实现方式/底层具体实现JDK1.7（上面有示意图）首先将数据分为一段一段的存储，然后给每一段数据配一把锁，当一个线程占用锁访问其中一个段数据时，其他段的数据也能被其他线程访问。 ConcurrentHashMap 是由 Segment 数组结构和 HashEntry 数组结构组成。 Segment 实现了 ReentrantLock,所以 Segment 是一种可重入锁，扮演锁的角色。HashEntry 用于存储键值对数据。 12static class Segment&lt;K,V&gt; extends ReentrantLock implements Serializable &#123;&#125; 一个 ConcurrentHashMap 里包含一个 Segment 数组。Segment 的结构和HashMap类似，是一种数组和链表结构，一个 Segment 包含一个 HashEntry 数组，每个 HashEntry 是一个链表结构的元素，每个 Segment 守护着一个HashEntry数组里的元素，当对 HashEntry 数组的数据进行修改时，必须首先获得对应的 Segment的锁。 JDK1.8 （上面有示意图）ConcurrentHashMap取消了Segment分段锁，采用CAS和synchronized来保证并发安全。数据结构跟HashMap1.8的结构类似，数组+链表/红黑二叉树。Java 8在链表长度超过一定阈值（8）时将链表（寻址时间复杂度为O(N)）转换为红黑树（寻址时间复杂度为O(log(N))） synchronized只锁定当前链表或红黑二叉树的首节点，这样只要hash不冲突，就不会产生并发，效率又提升N倍。 JDK 提供的并发容器总结JDK 提供的这些容器大部分在 java.util.concurrent 包中。 ConcurrentHashMap: 线程安全的 HashMap CopyOnWriteArrayList: 线程安全的 List，在读多写少的场合性能非常好，远远好于 Vector. ConcurrentLinkedQueue: 高效的并发队列，使用链表实现。可以看做一个线程安全的 LinkedList，这是一个非阻塞队列。 BlockingQueue: 这是一个接口，JDK 内部通过链表、数组等方式实现了这个接口。表示阻塞队列，非常适合用于作为数据共享的通道。 ConcurrentSkipListMap: 跳表的实现。这是一个 Map，使用跳表的数据结构进行快速查找。 常见面试题总结1.ArrayList和HashMap扩容机制ArrayList: 初始容量为10，不够用的时候扩容约1.5倍。NewLength=OldLength+OldLength&gt;&gt;1 HashMap: 初始容量为16，添加元素时，如果超过加载因子，则先扩容（新建）一个2倍大小的新hashmap 2.为什么HashMap加载因子是0.75？因为加载因子太小，会浪费空间，rehash次数变多。 加载因子太大，碰撞次数会变多。所以0.75是一个提高空间利用率和减少查询成本的折中。]]></content>
  </entry>
  <entry>
    <title><![CDATA[Java并发2]]></title>
    <url>%2F2020%2F03%2F25%2FJava%E5%B9%B6%E5%8F%912%2F</url>
    <content type="text"><![CDATA[Java中的锁乐观锁总是假设最好的情况，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号机制和CAS算法实现。乐观锁适用于多读的应用类型，这样可以提高吞吐量，像数据库提供的类似于write_condition机制，其实都是提供的乐观锁。在Java中java.util.concurrent.atomic包下面的原子变量类就是使用了乐观锁的一种实现方式CAS实现的。 悲观锁总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会阻塞直到它拿到锁（共享资源每次只给一个线程使用，其它线程阻塞，用完后再把资源转让给其它线程）。传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁。Java中synchronized和ReentrantLock等独占锁就是悲观锁思想的实现。 两种锁的使用场景各有优缺点，乐观锁适用于写比较少的情况下（多读场景），多写的场景下用悲观锁就比较合适。 乐观锁常见的两种实现方式 乐观锁一般会使用版本号机制或CAS算法实现。 1.CAS算法即compare and swap（比较与交换），是一种有名的无锁算法。无锁编程，即不使用锁的情况下实现多线程之间的变量同步，也就是在没有线程被阻塞的情况下实现变量的同步，所以也叫非阻塞同步（Non-blocking Synchronization）。CAS算法涉及到三个操作数 V表示要更新的变量 E表示预期的值 N表示新值 当且仅当 V 的值等于 E时，CAS通过原子方式用新值N来更新V的值，否则不会执行任何操作（比较和替换是一个原子操作）。一般情况下是一个自旋操作，即不断的重试。 2.版本号机制一般是在数据表中加上一个数据版本号version字段，表示数据被修改的次数，当数据被修改时，version值会加一。当线程A要更新数据值时，在读取数据的同时也会读取version值，在提交更新时，若刚才读取到的version值为当前数据库中的version值相等时才更新，否则重试更新操作，直到更新成功。 乐观锁的缺点 ABA 问题是乐观锁一个常见的问题 1 ABA 问题如果一个变量V初次读取的时候是A值，并且在准备赋值的时候检查到它仍然是A值，那我们就能说明它的值没有被其他线程修改过了吗？很明显是不能的，因为在这段时间它的值可能被改为其他值，然后又改回A，那CAS操作就会误认为它从来没有被修改过。这个问题被称为CAS操作的 “ABA”问题。你大爷还是你大爷，你大妈已经不是你大妈了 对于ABA问题，比较有效的方案是引入版本号 2 循环时间长开销大自旋CAS（也就是不成功就一直循环执行直到成功）如果长时间不成功，会给CPU带来非常大的执行开销。 设置自旋CAS的时间域值 3 只能保证一个共享变量的原子操作CAS 只对单个共享变量有效，当操作涉及跨多个共享变量时 CAS 无效。但是从 JDK 1.5开始，提供了AtomicReference类来保证引用对象之间的原子性，你可以把多个变量放在一个对象里来进行 CAS 操作.所以我们可以使用锁或者利用AtomicReference类把多个共享变量合并成一个共享变量来操作。 Atomic 原子类介绍Atomic 翻译成中文是原子的意思。在化学上，我们知道原子是构成一般物质的最小单位，在化学反应中是不可分割的。在我们这里 Atomic 是指一个操作是不可中断的。即使是在多个线程一起执行的时候，一个操作一旦开始，就不会被其他线程干扰。 所以，所谓原子类说简单点就是具有原子/原子操作特征的类。 基本数据类型原子类的优势通过一个简单例子带大家看一下基本数据类型原子类的优势 ①多线程环境不使用原子类保证线程安全（基本数据类型） 1234567891011class Test &#123; private volatile int count = 0; //若要线程安全执行执行count++，需要加锁 public synchronized void increment() &#123; count++; &#125; public int getCount() &#123; return count; &#125;&#125; ②多线程环境使用原子类保证线程安全（基本数据类型） 1234567891011class Test2 &#123; private AtomicInteger count = new AtomicInteger(); public void increment() &#123; count.incrementAndGet(); &#125; //使用AtomicInteger之后，不需要加锁，也可以实现线程安全。 public int getCount() &#123; return count.get(); &#125;&#125; AtomicInteger 线程安全原理简单分析AtomicInteger 类的部分源码： 123456789101112// setup to use Unsafe.compareAndSwapInt for updates（更新操作时提供“比较并替换”的作用）private static final Unsafe unsafe = Unsafe.getUnsafe();private static final long valueOffset;static &#123; try &#123; valueOffset = unsafe.objectFieldOffset (AtomicInteger.class.getDeclaredField("value")); &#125; catch (Exception ex) &#123; throw new Error(ex); &#125;&#125;private volatile int value; AtomicInteger 类主要利用 CAS (compare and swap) + volatile 和 native 方法来保证原子操作，从而避免 synchronized 的高开销，执行效率大为提升。 CAS的原理是拿期望的值和原本的一个值作比较，如果相同则更新成新的值。UnSafe 类的 objectFieldOffset() 方法是一个本地方法，这个方法是用来拿到“原来的值”的内存地址。另外 value 是一个volatile变量，在内存中可见，因此 JVM 可以保证任何时刻任何线程总能拿到该变量的最新值。 synchronized与LockJava中有两种加锁的方式：一种是用synchronized关键字，另一种是用Lock接口的实现类。 形象地说，synchronized关键字是自动档，可以满足一切日常驾驶需求。但是如果你想要玩漂移或者各种骚操作，就需要手动档了——各种Lock的实现类。 synchronized关键字synchronized关键字主要的三种使用方式： synchronized修饰非静态方法（普通方法）时，锁住的是对象的实例，即this对象 synchronized修饰静态方法时，也就是给当前类加锁，会作用于类的所有对象实例，因为静态成员不属于任何一个实例对象，是类成员（ static 表明这是该类的一个静态资源，不管new了多少个对象，只有一份） 所以如果一个线程 A 调用一个实例对象的非静态 synchronized 方法，而线程 B 需要调用这个实例对象所属类的静态 synchronized 方法，是允许的，不会发生互斥现象，因为访问静态 synchronized 方法占用的锁是当前类的锁，而访问非静态 synchronized 方法占用的锁是当前实例对象锁。 synchronized修饰代码块，锁住的是在括号里面的对象。 总结： synchronized 关键字加到 static 静态方法和 synchronized(class)代码块上都是是给 Class 类上锁。synchronized 关键字加到实例方法上是给对象实例上锁。尽量不要使用 synchronized(String a) 因为JVM中，字符串常量池具有缓存功能！(会带来很不好的后果，如synchronized(a)和synchronized(b)，可能a和b指向的是同一个对象。) synchronized 关键字底层原理属于 JVM 层面。 ① synchronized 同步语句块的情况 synchronized 同步语句块的实现使用的是 monitorenter 和 monitorexit 指令，其中 monitorenter 指令指向同步代码块的开始位置，monitorexit 指令则指明同步代码块的结束位置。 当执行 monitorenter 指令时，线程试图获取锁也就是获取 monitor(monitor对象存在于每个Java对象的对象头中，synchronized 锁便是通过这种方式获取锁的，也是为什么Java中任意对象可以作为锁的原因) 的持有权。当计数器为0则可以成功获取，获取后将锁计数器设为1也就是加1。相应的在执行 monitorexit 指令后，将锁计数器设为0，表明锁被释放。如果获取对象锁失败，那当前线程就要阻塞等待，直到锁被另外一个线程释放为止。 ② synchronized 修饰方法的的情况 synchronized 修饰的方法并没有 monitorenter 指令和 monitorexit 指令，取得代之的确实是 ACC_SYNCHRONIZED 标识，该标识指明了该方法是一个同步方法，JVM 通过该 ACC_SYNCHRONIZED 访问标志来辨别一个方法是否声明为同步方法，从而执行相应的同步调用。 JDK1.6 之后的synchronized 关键字底层做了哪些优化，可以详细介绍一下这些优化吗JDK1.6 对锁的实现引入了大量的优化，如偏向锁、轻量级锁、自旋锁、适应性自旋锁、锁消除、锁粗化等技术来减少锁操作的开销。 锁主要存在四种状态，依次是：无锁状态、偏向锁状态、轻量级锁状态、重量级锁状态，他们会随着竞争的激烈而逐渐升级。注意锁可以升级不可降级，这种策略是为了提高获得锁和释放锁的效率。 synchronized锁升级：偏向锁 → 轻量级锁 → 重量级锁偏向锁： 初次执行到synchronized代码块的时候，锁对象变成偏向锁（通过CAS修改对象头里的锁标志位），字面意思是“偏向于第一个获得它的线程”的锁。执行完同步代码块后，线程并不会主动释放偏向锁。当第二次到达同步代码块时，线程会判断此时持有锁的线程是否就是自己（持有锁的线程ID也在对象头里），如果是则正常往下执行。由于之前没有释放锁，这里也就不需要重新加锁。如果自始至终使用锁的线程只有一个，很明显偏向锁几乎没有额外开销，性能极高。 偏向锁，顾名思义，它会偏向于第一个访问锁的线程，如果在运行过程中，同步锁只有一个线程访问，不存在多线程争用的情况，则线程是不需要触发同步的，这种情况下，就会给线程加一个偏向锁。如果在运行过程中，遇到了其他线程抢占锁，则持有偏向锁的线程会被挂起，JVM会消除它身上的偏向锁，将锁恢复到标准的轻量级锁。 轻量级锁： 轻量级锁是由偏向所升级来的，偏向锁运行在一个线程进入同步块的情况下，当第二个线程加入锁争用的时候，偏向锁就会升级为轻量级锁。在轻量级锁状态下继续锁竞争，没有抢到锁的线程将自旋，即不停地循环判断锁是否能够被成功获取。获取锁的操作，其实就是通过CAS修改对象头里的锁标志位。先比较当前锁标志位是否为“释放”，如果是则将其设置为“锁定”，比较并设置是原子性发生的。这就算抢到锁了，然后线程将当前锁的持有者信息修改为自己。 重量级锁 如果锁竞争情况严重，某个达到最大自旋次数的线程，会将轻量级锁升级为重量级锁（依然是CAS修改锁标志位，但不修改持有锁的线程ID）。当后续线程尝试获取锁时，发现被占用的锁是重量级锁，则直接将自己挂起。 自旋锁(spin lock)与互斥量(mutex)的比较 自旋锁是一种非阻塞锁，也就是说，如果某线程需要获取自旋锁，但该锁已经被其他线程占用时，该线程不会被挂起，而是在不断的消耗CPU的时间，不停的试图获取自旋锁。 互斥量是阻塞锁，当某线程无法获取互斥量时，该线程会被直接挂起，该线程不再消耗CPU时间，当其他线程释放互斥量后，操作系统会激活那个被挂起的线程，让其投入运行。 互斥同步对性能最大的影响就是阻塞的实现，因为挂起线程/恢复线程的操作都需要转入内核态中完成（用户态转换到内核态会耗费时间）。一般线程持有锁的时间都不是太长，所以仅仅为了这一点时间去挂起线程/恢复线程是得不偿失的。在 JDK1.6 中引入了自适应的自旋锁。自适应的自旋锁带来的改进就是：自旋的时间（次数）不在固定了，而是和前一次同一个锁上的自旋时间以及锁的拥有者的状态来决定，虚拟机变得越来越“聪明”了。 锁清除 锁消除理解起来很简单，它指的就是虚拟机即使编译器在运行时，如果检测到那些共享数据不可能存在竞争，那么就执行锁消除。锁消除可以节省毫无意义的请求锁的时间（没必要就不要加锁嘛）。 锁粗化 把关联性强的锁操作合并成一个，避免频繁获取锁和释放锁，反而影响性能。 减少锁粒度 它的思想是将物理上的一个锁，拆成逻辑上的多个锁，增加并行度，从而降低锁竞争。它的思想也是用空间来换时间；java中很多数据结构都是采用这种方法提高并发操作的效率：如ConcurrentHashMap Synchronized的实现它有多个队列，当多个线程一起访问某个对象监视器的时候，对象监视器会将这些线程存储在不同的容器中。 Contention List：竞争队列，所有请求锁的线程首先被放在这个竞争队列中； Entry List：Contention List中那些有资格成为候选资源的线程被移动到Entry List中； Wait Set：哪些调用wait方法被阻塞的线程被放置在这里； OnDeck：任意时刻，最多只有一个线程正在竞争锁资源，该线程被成为OnDeck； Owner：当前已经获取到所资源的线程被称为Owner； !Owner：当前释放锁的线程。 Synchronized是非公平锁。 Synchronized在线程进入ContentionList时，等待的线程会先尝试自旋获取锁，如果获取不到就进入ContentionList，这明显对于已经进入队列的线程是不公平的，还有一个不公平的事情就是自旋获取锁的线程还可能直接抢占OnDeck线程的锁资源。 ReentrantLockReentrantLock继承了Lock接口，是一个可重入的独占锁。 需要显示获取和释放锁。 支持公平锁和非公平锁的实现（先来先服务）。 不但提供了synchronized对锁的操作功能，还提供了诸如响应中断，可轮询锁，定时锁等避免多线程死锁。 谈谈 synchronized和ReentrantLock 的区别① 两者都是可重入锁 支持一个线程对同一个资源执行多次加锁操作。 ② synchronized 依赖于 JVM 而 ReentrantLock 依赖于 API ③ ReentrantLock 比 synchronized 增加了一些高级功能 如可以实现公平锁，而synchronized是非公平锁；还可以定时锁，响应中断等。 volatile关键字volatile是轻量级的synchronized，它保证了共享变量的 “可见性”：当一个线程修改一个共享变量时，另一个线程能读到这个修改的值。如果volatile使用得恰当，它比synchronized成本更低，因为它不会引起线程上下文的切换。 原理：修改volatile修饰的变量时。处理器会干两件事 1.）将当前处理器缓存行的数据写回到系统内存。 2.）这个写回内存的操作会使其它CPU里缓存了该内存地址的数据无效。要重新从系统内存读取到缓存。 并发编程的三个重要特性 原子性 : 一个的操作或者多次操作，要么所有的操作全部都得到执行并且不会收到任何因素的干扰而中断，要么所有的操作都执行，要么都不执行。synchronized和Lock可以保证代码片段的原子性。(由于synchronized和Lock能够保证任一时刻只有一个线程执行该代码块，那么自然就不存在原子性问题了，从而保证了原子性。) 可见性 ：当一个变量对共享变量进行了修改，那么另外的线程都是立即可以看到修改后的最新值。volatile 关键字可以保证共享变量的可见性。 有序性 ：代码在执行的过程中的先后顺序，Java 在编译器以及运行期间的优化，代码的执行顺序未必就是编写代码时候的顺序。volatile 关键字可以禁止指令进行重排序优化。 在Java中，对基本数据类型的变量的读取和赋值操作是原子性操作，即这些操作是不可被中断的，要么执行，要么不执行。 1234x = 10; //赋值操作，直接将数值10写入到工作内存，是原子性操作y = x; //实际上包含2个操作，它先要去读取x的值，再将x的值写入工作内存，不是原子性操作x++; //语句3x = x + 1; //语句4 包括3个操作：读取x的值，进行加1操作，写入新的值。 说说 synchronized 关键字和 volatile 关键字的区别volatile关键字能保证数据的可见性，但不能保证数据的原子性。synchronized关键字两者都能保证。 volatile关键字主要用于解决变量在多个线程之间的可见性，而 synchronized关键字解决的是多个线程之间访问资源的同步性。 多线程访问volatile关键字不会发生阻塞，而synchronized关键字可能会发生阻塞 volatile在一定程度上保证有序性：在进行指令优化时，不能将在对volatile变量访问的语句放在其后面执行，也不能把volatile变量后面的语句放到其前面执行。但前面和后面那块可能无序。 使用条件您只能在有限的一些情形下使用 volatile 变量替代锁。要使 volatile 变量提供理想的线程安全，必须同时满足下面两个条件： 对变量的写操作不依赖于当前值。 该变量没有包含在具有其他变量的不变式中。 实际上，这些条件表明，可以被写入 volatile 变量的这些有效值独立于任何程序的状态，包括变量的当前状态。 事实上，我的理解就是上面的2个条件需要保证操作是原子性操作，才能保证使用volatile关键字的程序在并发时能够正确执行。 volatile的适用场景不适用：第一个条件的限制使 volatile 变量不能用作线程安全计数器。虽然增量操作（x++）看上去类似一个单独操作，实际上它是一个由（读取－修改－写入）操作序列组成的组合操作，必须以原子方式执行，而 volatile 不能提供必须的原子特性。实现正确的操作需要使x 的值在操作期间保持不变，而 volatile 变量无法实现这点。 适用：比如实现一个布尔状态标志，用于指示发生了一个重要的一次性事件，例如完成初始化或请求停机。 ThreadLocalThreadLocal简介通常情况下，我们创建的变量是可以被任何一个线程访问并修改的。如果想实现每一个线程都有自己的专属本地变量该如何解决呢？ JDK中提供的ThreadLocal类正是为了解决这样的问题。 ThreadLocal类主要解决的就是让每个线程绑定自己的值，可以将ThreadLocal类形象的比喻成存放数据的盒子，盒子中可以存储每个线程的私有数据。 123ThreadLocal&lt;String&gt; localName = new ThreadLocal();localName.set("小狼");String name = localName.get(); 在线程1中初始化了一个ThreadLocal对象localName，并通过set方法，保存了一个值小狼，同时在线程1中通过localName.get()可以拿到之前设置的值，但是如果在线程2中，拿到的将是一个null。 如果你创建了一个ThreadLocal变量，那么访问这个变量的每个线程都会有这个变量的本地副本，这也是ThreadLocal变量名的由来。他们可以使用 get（） 和 set（） 方法来获取默认值或将其值更改为当前线程所存的副本的值，从而避免了线程安全问题。 原理：每个Thread中都具备一个ThreadLocalMap（ThreadLocalMap并没有实现Map接口，而是自己用数组”实现”了一个Map），而ThreadLocalMap可以存储以ThreadLocal对象(如上，localName)为key ，Object 对象为 value(如上，小狼)的键值对。 内存泄露ThreadLocal可能导致内存泄漏，为什么？ 先看看Entry的实现： 12345678static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; &#123; /** The value associated with this ThreadLocal. */ Object value; Entry(ThreadLocal&lt;?&gt; k, Object v) &#123; super(k); value = v; &#125;&#125; 通过之前的分析已经知道，当使用ThreadLocal保存一个value时，会在ThreadLocalMap中的数组插入一个Entry对象，按理说key-value都应该以强引用保存在Entry对象中，但在ThreadLocalMap的实现中，key被保存到了WeakReference(弱引用)对象中。 这就导致了一个问题，ThreadLocal在没有外部强引用时，发生GC时会被回收，如果创建ThreadLocal的线程一直持续运行，那么这个Entry对象中的value就有可能一直得不到回收，发生内存泄露。 ps: ThreadLocalMap使用ThreadLocal的弱引用作为key，如果一个ThreadLocal没有外部强引用来引用它，那么系统 GC 的时候，这个ThreadLocal势必会被回收，这样一来，ThreadLocalMap中就会出现key为null的Entry，就没有办法访问这些key为null的Entry的value，如果当前线程再迟迟不结束的话，这些key为null的Entry的value就会一直存在一条强引用链：Thread Ref -&gt; Thread -&gt; ThreaLocalMap -&gt; Entry -&gt; value永远无法回收，造成内存泄漏。 解决 既然已经发现有内存泄露的隐患，自然有应对的策略，在调用ThreadLocal的get()、set()可能会清除ThreadLocalMap中key为null的Entry对象，这样对应的value就没有GC Roots可达了，下次GC的时候就可以被回收，当然如果调用remove方法，肯定会删除对应的Entry对象。 如果使用ThreadLocal的set方法之后，没有显示的调用remove方法，就有可能发生内存泄露，所以养成良好的编程习惯十分重要，使用完ThreadLocal之后，记得调用remove方法。 1234567ThreadLocal&lt;String&gt; localName = new ThreadLocal();try &#123; localName.set("小狼"); // 其它业务逻辑&#125; finally &#123; localName.remove();&#125; AQSAbstractQueuedSynchronizer，抽象队列同步器 AQS是一个用来构建锁和同步器的框架，使用AQS能简单且高效地构造出应用广泛的大量的同步器，比如我们提到的ReentrantLock，Semaphore，其他的诸如ReentrantReadWriteLock，SynchronousQueue，FutureTask等等皆是基于AQS的。 给大家画一个图，看一下ReentrantLock和AQS之间的关系。 我们看上图，说白了，ReentrantLock内部包含了一个AQS对象，也就是AbstractQueuedSynchronizer类型的对象。这个AQS对象就是ReentrantLock可以实现加锁和释放锁的关键性的核心组件。 AQS 原理概览AQS核心思想是，如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的工作线程，并且将共享资源设置为锁定状态。如果被请求的共享资源被占用，那么就需要一套线程阻塞等待以及被唤醒时锁分配的机制，这个机制AQS是用CLH队列锁实现的，即将暂时获取不到锁的线程加入到队列中。 好了，现在如果有一个线程过来尝试用ReentrantLock的lock()方法进行加锁，会发生什么事情？ 很简单，这个AQS对象内部有一个核心的变量叫做state，是int类型的，代表了加锁的状态。 1private volatile int state;//共享变量，使用volatile修饰保证线程可见性 初始状态下，这个state的值是0。 另外，这个AQS内部还有一个关键变量，用来记录当前加锁的是哪个线程，初始化状态下，这个变量是null。 接着线程跑过来调用ReentrantLock的lock()方法尝试进行加锁，这个加锁的过程，直接就是用CAS操作将state值从0变为1。如果成功，会设置state=1，代表已加锁。 大家看明白了那个state变量之后，就知道了如何进行可重入加锁！ 其实每次线程1可重入加锁一次，会判断一下当前加锁线程就是自己，那么他自己就可以可重入多次加锁，每次加锁就是把state的值给累加1，别的没啥变化。 AQS维护一个同步队列，线程获取同步状态失败后，CAS加入队列尾部，然后CAS自旋前驱是否是头节点。移出队列的条件是：前驱节点是头节点且成功获取了同步状态。 头节点是获取同步状态成功的节点，首节点的线程在释放同步状态后，将会唤醒后继节点。如果当前节点的前驱为头节点，尝试获取同步状态。 加入队列尾部的过程必须要保证线程安全(CAS)，防止多个线程同时加入出现问题。 AQS定义两种资源共享方式 Exclusive （独占）：只有一个线程能执行，如ReentrantLock。又可分为公平锁和非公平锁： 公平锁：按照线程在队列中的排队顺序，先到者先拿到锁 非公平锁：当线程要获取锁时，无视队列顺序直接去抢锁，谁抢到就是谁的 Share（共享）：多个线程可同时执行，如Semaphore/CountDownLatch。Semaphore、CountDownLatch、 CyclicBarrier、ReadWriteLock 我们都会在后面讲到。 ReentrantReadWriteLock 可以看成是组合式，因为ReentrantReadWriteLock也就是读写锁允许多个线程同时对某一资源进行读。只有一个线程可以写。 AQS 组件总结 Semaphore(信号量)-允许多个线程同时访问： synchronized 和 ReentrantLock 都是一次只允许一个线程访问某个资源，Semaphore(信号量)可以指定多个线程同时访问某个资源。 CountDownLatch （倒计时器）： CountDownLatch是一个同步工具类，用来协调多个线程之间的同步。这个工具通常用来控制线程等待，它可以让某一个线程等待直到倒计时结束，再开始执行。 CountDownLatchCountDownLatch是一个同步工具类，用来协调多个线程之间的同步. 某一线程在开始运行前等待n个线程执行完毕。将CountDownLatch的计数器初始化为new CountDownLatch(n)，每当一个任务线程执行完毕，就将计数器减1 countdownLatch.countDown()，当计数器的值变为0时，在CountDownLatch上await()的线程就会被唤醒。一个典型应用场景就是启动一个服务时，主线程需要等待多个组件加载完毕，之后再继续执行。 CyclicBarrier字面意思是可循环使用的屏障。它要做的事情是，让一组线程到达一个屏障（也可以叫同步点）时被阻塞，直到最后一个线程到达屏障时，屏障才会开门，所有被屏障拦截线程才会继续运行。 CountDownLatch和CyclicBarrier的区别 CountDownLatch的计数器只能使用一次，而CyclicBarrier的计数器可以使用reset()方法重置。 CountDownLatch: 一个线程(或者多个)， 等待另外N个线程完成某个事情之后才能执行。CyclicBrrier: N个线程相互等待，任何一个线程完成之前，所有的线程都必须等待。 常见面试题1.Java的同步方式Synchronized，ReetrantLock，volatile，Atomic原子类]]></content>
  </entry>
  <entry>
    <title><![CDATA[Java并发1]]></title>
    <url>%2F2020%2F03%2F25%2FJava%E5%B9%B6%E5%8F%911%2F</url>
    <content type="text"><![CDATA[说说并发与并行的区别? 并发： 同一时间段，多个任务都在执行 (单位时间内不一定同时执行)； 并行： 单位时间内，多个任务同时执行。 并发、并行、串行、同步、异步 并发：并发编程又叫多线程编程。并发当有多个线程在操作时,如果系统只有一个CPU,则它根本不可能真正同时进行一个以上的线程，它只能把CPU运行时间划分成若干个时间段,再将时间段分配给各个线程执行，在一个时间段的线程代码运行时，其它线程处于挂起状。这种方式我们称之为并发(Concurrent)。 并行 当系统有一个以上CPU时,则线程的操作有可能非并发。当一个CPU执行一个线程时，另一个CPU可以执行另一个线程，两个线程互不抢占CPU资源，可以同时进行，这种方式我们称之为并行(Parallel)。 串行 并行和串行指的是任务的执行方式。串行是指多个任务时，各个任务按顺序执行，完成一个之后才能进行下一个。并行指的是多个任务可以同时执行，异步是多个任务并行的前提条件。 同步、异步 同步： 同步就是发起一个调用后，被调用者未处理完请求之前，调用不返回。 异步： 异步就是发起一个调用后，立刻得到被调用者的回应表示已接收到请求，但是被调用者并没有返回结果，此时我们可以处理其他的请求，被调用者通常依靠事件，回调等机制来通知调用者其返回结果。 同步和异步的区别最大在于异步的话调用者不需要等待处理结果，被调用者会通过回调等机制来通知调用者其返回结果。 指的是能否开启新的线程。同步不能开启新的线程，异步可以。异步：异步和同步是相对的，同步就是顺序执行，执行完一个再执行下一个，需要等待、协调运行。异步就是彼此独立,在等待某事件的过程中继续做自己的事，不需要等待这一事件完成后再工作。线程就是实现异步的一个方式。异步是让调用方法的主线程不需要同步等待另一线程的完成，从而可以让主线程干其它的事情。异步和多线程并不是一个同等关系,异步是最终目的,多线程只是我们实现异步的一种手段。异步是当一个调用请求发送给被调用者,而调用者不用等待其结果的返回而可以做其它的事情。实现异步可以采用多线程技术或则交给另外的进程来处理。 进程和线程的区别1.多进程之间不共享资源，多线程之间共享资源，那么就会存在资源竞争的问题 2.进程是操作系统资源分配的最小单位，线程是CPU调度的最小单位（CPU四核八线程） 3.进程里面默认有一个主线程，进程里面可以有多个线程，线程必须依赖进行而存在，不能独立存在。 举个例子：一个工厂相当于一个进程，一个工人相当于一个线程，一个工厂里面可以存在多个工人。 多进程和多线程的区别 什么是上下文切换?多线程编程中一般线程的个数都大于 CPU 核心的个数，而一个 CPU 核心在任意时刻只能被一个线程使用，为了让这些线程都能得到有效执行，CPU 采取的策略是为每个线程分配时间片并轮转的形式。当一个线程的时间片用完的时候就会重新处于就绪状态让给其他线程使用，这个过程就属于一次上下文切换。 概括来说就是：当前任务在执行完 CPU 时间片切换到另一个任务之前会先保存自己的状态，以便下次再切换回这个任务时，可以再加载这个任务的状态。任务从保存到再加载的过程就是一次上下文切换。 上下文的切换流程如下。 挂起一个进程(线程)，将这个进程在CPU中的状态(上下文信息)存储于内存的PCB(TCB)中。 在PCB中检索下一个进程的上下文并将其在CPU的寄存器中恢复。 跳转到程序计数器所指向的位置(即跳转到进程被中断时的代码行)并恢复该进程。 线程的基本方法线程等待：wait方法 线程睡眠：sleep方法 线程让步：yield方法 调用yield方法会使当前线程让出(释放)CPU执行时间片，与其他线程一起重新竞选CPU时间片 。 一般优先级高的线程更有可能竞选得到。 线程中断：interrupt方法 interrupt方法用于向线程发送一个终止的通知。 如果线程处于被阻塞状态,那么该线程将立即退出被阻塞状态,并且抛出一个InterrupedException异常. 如果线程处于运行状态,那么会将该线程的中断标志设置为true.被设置中断标志的线程将继续正常运行,不受影响. 所以，需要调用interrupt方法的线程配合中断，在正常运行任务时,经常检查本线程的中断标志,如果被设置了中断标志就自行停止线程。 线程加入：join方法 Thread类中的join方法的主要作用就是同步，它可以使得线程之间的并发执行变为串行执行。 即如果在A线程中调用了B线程的join()方法时，表示只有当B线程执行完毕时，A线程才能继续执行。 join方法也可以带参数。如A线程中调用B.join(10)，则表示A线程会等待B线程执行10毫秒，10毫秒过后，A、B线程并发执行。需要注意的是，jdk规定，join(0)的意思不是A线程等待B线程0秒，而是A线程等待B线程无限时间，直到B线程执行完毕，即join(0)等价于join()。 线程唤醒：notify方法 wait()、notify/notifyAll() 方法是Object的本地final方法，无法被重写。 wait()使当前线程阻塞，前提是必须先获得锁，一般配合synchronized 关键字使用，即，一般在synchronized 同步代码块里使用 wait()、notify/notifyAll() 方法。 由于 wait()、notify/notifyAll() 在synchronized 代码块执行，说明当前线程一定是获取了锁的。 notify/notifyAll() 的执行只是唤醒沉睡的线程，而不会立即释放锁。 123456789101112131415161718192021222324252627282930static Object lock = new Object();static boolean flag = true;static class Wait inplements Runnable&#123; public void run()&#123; //加锁，拥有lock的Monitor synchronized (lock)&#123; //当条件不满足的时候，继续wait,同时释放了lock的锁 while(flag)&#123; lock.wait();//会释放锁 &#125; //条件满足，完成工作 //do something &#125; &#125;&#125;static class Notifly inplements Runnable&#123; public void run()&#123; //加锁，拥有lock的Monitor synchronized (lock)&#123; //获取lock的锁，然后进行通知，通知时不会释放lock的锁，直到 //当前线程释放了lock后，wait线程才能起来。 lock.notify(); flag = false; &#125; &#125;&#125;//Wait线程首先获取了lock对象的锁，然后调用对象的wait()方法，放弃了锁并进入了对象的等待队列中，进入等待状态。//由于Wait线程释放了对象的锁，Notify线程获取了对象的锁，并调用对象的notify()方法，将Wait线程从等待队列移至同步队列，此时Wait线程的状态变为阻塞状态。//Notify线程释放锁之后，Wait线程再次获取到锁并开始完成工作。 后台守护进程：setDaemon方法 setDaemon方法用于定义一个守护进程，也叫做“服务进程”，该线程时后台进程，有一个特性，即为用户线程提供公共服务，在没有用户线程时会自动离开。如垃圾回收线程。 说说 sleep() 方法和 wait() 方法区别和共同点? 两者最主要的区别在于：sleep 方法没有释放锁，而 wait 方法释放了锁 。 sleep方法属于Thread类，wait方法属于Object类； sleep方法暂停指定的时间，让出CPU给其它线程，但其监控状态依然保持，在指定的时候过后又会自动恢复运行状态。 调用sleep方法，线程不会释放对象锁；wait() 方法被调用后，会释放锁，线程不会自动苏醒，需要别的线程调用同一个对象上的 notify() 或者 notifyAll() 方法。 为什么我们调用 start() 方法时会执行 run() 方法，为什么我们不能直接调用 run() 方法？new 一个 Thread，线程进入了新建状态;调用 start() 方法，会启动一个线程并使线程进入了就绪状态，当分配到时间片后就可以开始运行了。 start() 会执行线程的相应准备工作，然后自动执行 run() 方法的内容，这是真正的多线程工作。 而直接执行 run() 方法，会把 run 方法当成一个 main 线程下的普通方法去执行，并不会在某个线程中执行它，所以这并不是多线程工作。 总结： 调用 start 方法方可启动线程并使线程进入就绪状态，而 run 方法只是 thread 的一个普通方法调用，还是在主线程里执行。所以run方法不可以手动调用，不然就是普通方法了 终止线程的四种方式1.正常运行结束 指线程体执行完成，线程自动结束。 2.使用退出标志退出线程 可以用volatile关键字定义一个变量，当满足某种条件时，触发关闭线程。 12345678public class ThreadSafe extends Thread&#123; public volatile boolean exit = false; public void run()&#123; while(!exit)&#123; //执行业务逻辑代码 &#125; &#125;&#125; volatile关键字：这个关键字可以使exit线程同步安全，也就是说在同一时间只能有一个线程修改exit的值。 3.使用interrupt方法终止线程 线程处于运行状态时，通过修改中断标志为True，线程配合结束。 线程处于阻塞状态时，捕获InterrupedException异常来结束。 4.使用stop方法终止线程：不安全 已被弃用。不安全，可能会导致数据不一致等问题。 Java线程的创建方式1.继承Thread类 123456public class MyThread extends Thread&#123; private int i=0; @Override public void run()&#123; &#125;&#125; 2.实现Runnable接口 其实Thread类也是实现Runnable接口来的。所以我们可以直接实现Runnable接口，可以避免单继承局限。 123456public class ChildrenClassThread extends SuperClass inplements Runnable&#123; private int i=0; @Override public void run()&#123; &#125;&#125; 3.实现Callable接口 实现Callable接口，并重写call方法。可以实现有返回值的线程。 12345public class CallableThreadTest implements Callable&lt;Integer&gt; &#123; @Override public Integer call() throws Exception &#123; &#125; &#125; 4.基于线程池 线程池线程池的本质就是使用了一个线程安全的工作队列(jobs)连接工作者线程和客户端线程，客户端线程讲任务放入工作队列后便返回，而工作者线程则不断从工作队列中取出工作并执行。当工作队列为空时，所有的工作者线程均等待在工作队列上(jobs.wait())，当有客户端提交一个任务之后会通知任意一个工作者线程（notify），随着大量的任务被提交，更多的工作者线程会被唤醒。 为什么要用线程池？ 池化技术相比大家已经屡见不鲜了，线程池、数据库连接池、Http 连接池等等都是对这个思想的应用。池化技术的思想主要是为了减少每次获取资源的消耗，提高对资源的利用率。 降低资源消耗。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。 提高响应速度。当任务到达时，任务可以不需要等到线程创建就能立即执行。 提高线程的可管理性。线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控。（线程池可以控制线程数，有效的提升服务器的使用资源，避免由于资源不足而发生宕机等问题） 执行execute()方法和submit()方法的区别是什么呢？ execute()方法用于提交不需要返回值的任务，所以无法判断任务是否被线程池执行成功与否； submit()方法用于提交需要返回值的任务。线程池会返回一个 Future 类型的对象，通过这个 Future 对象可以判断任务是否执行成功， 四种线程池及其运用场景 CachedThreadPool创建一个可缓存线程池，如果线程池有可回收线程，可灵活回收空闲线程，若无可回收，则新建线程。（corePoolSize=0, maximumPoolSize=Integer.MAX_VALUE） 不足：这种方式虽然可以根据业务场景自动的扩展线程数来处理我们的业务，但是最多需要多少个线程同时处理缺是我们无法控制的； 优点：如果当第二个任务开始，第一个任务已经执行结束，那么第二个任务会复用第一个任务创建的线程，并不会重新创建新的线程，提高了线程的复用率； FixedThreadPool 创建一个定长线程池，可控制线程最大并发数，超出的线程会在队列中等待。（使用的是无界队列，所以最大线程数不会超过corePoolSize） 优点：两个结果综合说明，FixedThreadPool的线程数是可以进行控制的，因此我们可以通过控制最大线程来使我们的服务器打到最大的使用率，同事又可以保证及时流量突然增大也不会占用服务器过多的资源。 ScheduledThreadPool 创建一个定长线程池，支持定时及周期性任务执行。 SingleThreadExecutor 创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行。(使用无界队列) 如何创建线程池《阿里巴巴Java开发手册》中强制线程池不允许使用 Executors 去创建，而是通过 ThreadPoolExecutor 的方式，这样的处理方式让写的同学更加明确线程池的运行规则，规避资源耗尽的风险 Executors 返回线程池对象的弊端如下： FixedThreadPool 和 SingleThreadExecutor ： 允许请求的队列长度为 Integer.MAX_VALUE ，可能堆积大量的请求，从而导致OOM(out of memory)。 CachedThreadPool 和 ScheduledThreadPool ： 允许创建的线程数量为 Integer.MAX_VALUE ，可能会创建大量线程，从而导致OOM。 方式一：通过构造方法实现 方法二：通过Executor 框架的工具类Executors来实现 略 ThreadPoolExecutor 类分析ThreadPoolExecutor 类中提供的四个构造方法。我们来看最长的那个，其余三个都是在这个构造方法的基础上产生 ThreadPoolExecutor构造函数重要参数分析ThreadPoolExecutor 3 个最重要的参数： corePoolSize : 核心线程数线程数定义了最小可以同时运行的线程数量。 maximumPoolSize : 当队列中存放的任务达到队列容量的时候，当前可以同时运行的线程数量变为最大线程数。 workQueue: 当新任务来的时候会先判断当前运行的线程数量是否达到核心线程数，如果达到的话，新任务就会被存放在队列中。 ThreadPoolExecutor其他常见参数: keepAliveTime:当线程池中的线程数量大于 corePoolSize 的时候，如果这时没有新的任务提交，核心线程外的线程不会立即销毁，而是会等待，直到等待的时间超过了 keepAliveTime才会被回收销毁； unit : keepAliveTime 参数的时间单位。 threadFactory :executor 创建新线程的时候会用到。 handler :饱和策略。关于饱和策略下面单独介绍一下。 线程池核心线程池数量设置cpu密集型的任务 一般设置 线程数 = 核心数N + 1 io密集型的任务 一般设置 线程数 = 核心数N*2 + 1 a）假如是业务时间长集中在IO操作上，也就是IO密集型的任务，因为IO操作并不占用CPU，所以不要让所有的CPU闲下来，可以适当加大线程池中的线程数目，让CPU处理更多的业务 b）假如是业务时间长集中在计算操作上，也就是计算密集型任务，这个就没办法了，线程池中的线程数设置得少一些，减少线程上下文的切换 ThreadPoolExecutor 饱和策略（拒绝策略）定义：如果当前同时运行的线程数量达到最大线程数量并且队列也已经被放满了任时，ThreadPoolTaskExecutor 定义一些策略: ThreadPoolExecutor.AbortPolicy：抛出 RejectedExecutionException来拒绝新任务的处理。 ThreadPoolExecutor.CallerRunsPolicy：调用执行自己的线程运行任务。但是这种策略会降低对于新任务提交速度，影响程序的整体性能。另外，这个策略喜欢增加队列容量。如果您的应用程序可以承受此延迟并且你不能任务丢弃任何一个任务请求的话，你可以选择这个策略。 ThreadPoolExecutor.DiscardPolicy： 不处理新任务，直接丢弃掉。 ThreadPoolExecutor.DiscardOldestPolicy： 此策略将丢弃队列中最早的未处理的任务请求，并尝试提交当前任务。 注意：默认拒绝策略是直接抛出异常。 线程池原理分析 多线程的应用场景，线程池？多线程处理后台任务 多线程异步处理任务 多线程分布式计算 eg：用户发起的实时请求，服务追求响应时间。比如说用户要查看一个商品的信息，那么我们需要将商品维度的一系列信息如商品的价格、优事、库存、图片等等聚合起来，展示给用户，这个响应是越快的越好，用户体验就好。 这一个请求会对应着多个逻辑的处理，这些逻辑之前没有相互依赖关系，那么我们就可以使用线程池中的多个线程去并发的执行，最后再将结果进行合并即可，这样比使用单线程顺序执行的速度快很多的，并且这些任务是不需要进行缓冲的，所以不用设置线程池中的阻塞队列，直接设置尽可能大的核心线程数和最大线程数即可。 线程池的大小设置CPU密集：意思是该任务需要大量的运算，而没有阻塞，CPU一直全速运行。CPU密集型任务只有在真正的多核CPU上才可能得到加速(通过多线程)，现代CPU都是多核的。 IO密集型：即该任务需要大量的IO，即大量的阻塞。例如:数据库插入数据时，此时就存在磁盘IO，将数据插入到数据库中，此时CPU就是处于空闲时间，这段时间就浪费掉了CPU的运算能力。 针对上面的两种类型的任务，应该怎么设置线程池的大小呢? CPU密集型的任务，设置线程池时，尽可能设置少点线程，因为过多线程会产生大量上下文切换，不利于CPU持续进行运算;此时大小设置为CPU核数就好。 IO密集型的任务，设置线程池时，应该尽可能设置多点线程，因为过多的线程使CPU在IO阻塞时，还会调度其它的线程，从而充分利用其运算性能，可以设置为CPU的两倍或更多些。 多进程和多线程的优缺点，应用场景多进程的优点： 1、每个进程相互独立，不影响主程序的稳定性，子进程崩溃没关系；基于这个特性，常常会用多进程来实现守护服务器的功能。 2、通过增加CPU，就可以容易扩充性能； 3、可以尽量减少线程加锁/解锁的影响，极大提高性能，就算是线程运行的模块算法效率低也没关系； 4、每个子进程都有2GB地址空间和相关资源，总体能够达到的性能上限非常大。 多进程的缺点： 0、创建进程的代价非常大，OS要给其分配资源；进程切换消耗大； 1、逻辑控制复杂，需要和主程序交互； 2、需要跨进程边界，如果有大数据量传送，就不太好，适合小数据量传送、密集运算 多进程调度开销比较大； 3、最好是多进程和多线程结合，即根据实际的需要，每个CPU开启一个子进程，这个子进程开启多线程可以为若干同类型的数据进行处理。当然你也可以利用多线程+多CPU+轮询方式来解决问题…… 4、方法和手段是多样的，关键是自己看起来实现方便有能够满足要求，代价也合适。 多线程优点： 0、线程切换比进程切换快 1、无需跨进程边界； 2、程序逻辑和控制方式简单； 3、所有线程可以直接共享内存和变量等；交互数据非常方便； 4、线程方式消耗的总资源比进程方式好。 多线程缺点： 1、每个线程与主程序共用地址空间，受限于2GB地址空间； 2、线程之间的同步和加锁控制比较麻烦； 3、一个线程的崩溃可能影响到整个程序的稳定性； 多核CPU可以同时运行多个线程，进程？一个进程的多个线程可以同时运行吗？]]></content>
  </entry>
  <entry>
    <title><![CDATA[将mask显示在原图]]></title>
    <url>%2F2020%2F03%2F22%2F%E5%B0%86mask%E6%98%BE%E7%A4%BA%E5%9C%A8%E5%8E%9F%E5%9B%BE%2F</url>
    <content type="text"><![CDATA[在深度学习中，如Unet等图像分割生成的mask经常是一个二值化的图像。 为直观表示，可以用如下代码将mask画在原图。 123456789101112131415161718192021222324def draw_mask(img_path,mask_path): # 原图路径,mask路径 image = cv2.imread(img_path) # 原图 mask_2d = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE) # mask灰度图 cv2.imshow("2d", mask_2d) cv2.imshow("iamge",image) cv2.waitKey() # mask_resize = np.ones((h, w), dtype='uint8') * 255 # 如果mask与原图大小有差，需resize # mask_resize[mask_2d[:, :] == 255] = 0 #如果白色是背景，黑色是分割物体，需反转黑白色 # cv2.imshow("mask_resize", mask_resize) # 利用cv2.findContours()函数找到连通域 ret, thresh = cv2.threshold(mask_2d, 128, 255, 0) contours, hier = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE) # 利用cv2.drawContours()画连通域边界 for cnt in contours: cv2.drawContours(image, [cnt], 0, (0, 255, 0), 1) # 打开画了轮廓之后的图像 cv2.imshow('image+mask', image) cv2.waitKey(0) # 保存图像 # cv2.imwrite("show/" + os.path.basename(img_path), image) 原图 mask图 效果]]></content>
  </entry>
  <entry>
    <title><![CDATA[Redis]]></title>
    <url>%2F2020%2F03%2F21%2FRedis%2F</url>
    <content type="text"><![CDATA[Redis简介Redis 是完全开源免费的，使用C语言开发，遵守BSD协议，是一个高性能的key-value数据库。 Redis 与其他 key - value 缓存产品相比有以下三个特点： Redis支持数据的持久化，可以将内存中的数据保存在磁盘中，重启的时候可以再次加载进行使用。 Redis不仅仅支持简单的key-value类型的数据，同时还提供list，set，zset，hash等数据结构的存储。并且提供对他们的原子性操作。 Redis支持数据的备份，即master-slave模式的数据备份。 Redis 和 memcached 的区别对于 redis 和 memcached 我总结了下面四点。现在公司一般都是用 redis 来实现缓存，而且 redis 自身也越来越强大了！ redis支持更丰富的数据类型（支持更复杂的应用场景）：Redis不仅仅支持简单的k/v类型的数据，同时还提供list，set，zset，hash等数据结构的存储。memcache支持简单的数据类型，String。 Redis支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用,而Memecache把数据全部存在内存之中。 集群模式：memcached没有原生的集群模式，需要依靠客户端来实现往集群中分片写入数据；但是 redis 目前是原生支持 cluster 模式的. Memcached是多线程，非阻塞IO复用的网络模型；Redis使用单线程的多路 IO 复用模型。 redis的速度比memcached快很多 Redis应用场景String 缓存功能：String字符串是最常用的数据类型，不仅仅是Redis，各个语言都是最基本类型，因此，利用Redis作为缓存，配合其它数据库作为存储层，利用Redis支持高并发的特点，可以大大加快系统的读写速度、以及降低后端数据库的压力。 计数器：许多系统都会使用Redis作为系统的实时计数器，可以快速实现计数和查询的功能。而且最终的数据结果可以按照特定的时间落地到数据库或者其它存储介质当中进行永久保存。 共享用户Session：用户重新刷新一次界面，可能需要访问一下数据进行重新登录，或者访问页面缓存Cookie，但是可以利用Redis将用户的Session集中管理，在这种模式只需要保证Redis的高可用，每次用户Session的更新和获取都可以快速完成。大大提高效率。 Hash（底层是一个hashtable?）这个是类似 Map 的一种结构，这个一般就是可以将结构化的数据，比如一个对象（前提是这个对象没嵌套其他的对象）给缓存在 Redis 里，然后每次读写缓存的时候，可以就操作 Hash 里的某个字段。 但是这个的场景其实还是多少单一了一些，因为现在很多对象都是比较复杂的，比如你的商品对象可能里面就包含了很多属性，其中也有对象。我自己使用的场景用得不是那么多。 List(底层是一个双向链表)List 是有序列表，这个还是可以玩儿出很多花样的。 比如可以通过 List 存储一些列表型的数据结构，类似粉丝列表、文章的评论列表之类的东西。 比如可以通过 lrange 命令，读取某个闭区间内的元素，可以基于 List 实现分页查询，这个是很棒的一个功能，基于 Redis 实现简单的高性能分页，可以做类似微博那种下拉不断分页的东西，性能高，就一页一页走。 比如可以搞个简单的消息队列，从 List 头怼进去，从 List 屁股那里弄出来。 List本身就是我们在开发过程中比较常用的数据结构了，热点数据更不用说了。 消息队列：Redis的链表结构，可以轻松实现阻塞队列，可以使用左进右出的命令组成来完成队列的设计。比如：数据的生产者可以通过Lpush命令从左边插入数据，多个数据消费者，可以使用BRpop命令阻塞的“抢”列表尾部的数据。 文章列表或者数据分页展示的应用。 比如，我们常用的博客网站的文章列表，当用户量越来越多时，而且每一个用户都有自己的文章列表，而且当文章多时，都需要分页展示，这时可以考虑使用Redis的列表，列表不但有序同时还支持按照范围内获取元素，可以完美解决分页查询功能。大大提高查询效率。 Set（intset(有序，适合容量小)或者hashtable）Set 是无序集合，会自动去重的那种。 直接基于 Set 将系统里需要去重的数据扔进去，自动就给去重了，如果你需要对一些数据进行快速的全局去重，你当然也可以基于 JVM 内存里的 HashSet 进行去重，但是如果你的某个系统部署在多台机器上呢？得基于Redis进行全局的 Set 去重。 可以基于 Set 玩儿交集、并集、差集的操作，比如交集吧，我们可以把两个人的好友列表整一个交集，看看俩人的共同好友是谁？对吧。 反正这些场景比较多，因为对比很快，操作也简单，两个查询一个Set搞定。 Sorted Set：（底层是跳表）Sorted set 是排序的 Set，去重但可以排序，写进去的时候给一个分数，自动根据分数排序。 有序集合的使用场景与集合类似，但是set集合不是自动有序的，而Sorted set可以利用分数进行成员间的排序，而且是插入时就排序好。所以当你需要一个有序且不重复的集合列表时，就可以选择Sorted set数据结构作为选择方案。 排行榜：有序集合经典使用场景。例如视频网站需要对用户上传的视频做排行榜，榜单维护可能是多方面：按照时间、按照播放量、按照获得的赞数等。 用Sorted Sets来做带权重的队列，比如普通消息的score为1，重要消息的score为2，然后工作线程可以选择按score的倒序来获取工作任务。让重要的任务优先执行。 微博热搜榜，就是有个后面的热度值，前面就是名称 跳表：跳表全称为跳跃列表，它允许快速查询，插入和删除一个有序连续元素的数据链表。跳跃列表的平均查找和插入时间复杂度都是O(logn)。快速查询是通过维护一个多层次的链表，且每一层链表中的元素是前一层链表元素的子集。 添加元素时，索引要添加到几层呢？随机函数，选择要添加到K层！ 数据类型String, Hash, List, Set, Zset, Bitmap, HyperLogLog, Geospatial 理解：redis 都是数据结构外面再套一个key, 所以String 就是我们常见的key -val普通形式 redis 过期策略1）定时删除，每个k-v对都有一个定时器（timer)，过期就删。内存友好，CPU不友好 2）惰性删除，过期不管，获取时检查，发现过期才删。CPU友好，内存不友好 3）定期删除，字面意思。（默认100ms） redis 过期策略是：定期删除+惰性删除。所谓定期删除，指的是 redis 默认是每隔 100ms 就随机抽取一些设置了过期时间的 key，检查其是否过期，如果过期就删除。 假设 redis 里放了 10w 个 key，都设置了过期时间，你每隔几百毫秒，就检查 10w 个 key，那 redis 基本上就死了，cpu 负载会很高的，消耗在你的检查过期 key 上了。注意，这里可不是每隔 100ms 就遍历所有的设置过期时间的 key，那样就是一场性能上的灾难。实际上 redis 是每隔 100ms 随机抽取一些 key 来检查和删除的。 但是问题是，定期删除可能会导致很多过期 key 到了时间并没有被删除掉，那咋整呢？所以就是惰性删除了。这就是说，在你获取某个 key 的时候，redis 会检查一下 ，这个 key 如果设置了过期时间那么是否过期了？如果过期了此时就会删除，不会给你返回任何东西。 获取 key 的时候，如果此时 key 已经过期，就删除，不会返回任何东西。 但是实际上这还是有问题的，如果定期删除漏掉了很多过期 key，然后你也没及时去查，也就没走惰性删除，此时会怎么样？如果大量过期 key 堆积在内存里，导致 redis 内存块耗尽了，咋整？答案是：走内存淘汰机制。 内存淘汰机制no-eviction：禁止驱逐数据，也就是说当内存不足以容纳新写入数据时，新写入操作会报错。这个应该没人使用吧 allkeys-lru (least recently used)：当内存不足以容纳新写入数据时，移除最近最少使用的数据（这个是最常用的） volatile-lru：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰 volatile-ttl：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰 volatile-random：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰 allkeys-random：从数据集（server.db[i].dict）中任意选择数据淘汰 4.0版本后增加以下两种： volatile-lfu (least frequently used)：从已设置过期时间的数据集(server.db[i].expires)中挑选最不经常使用的数据淘汰 allkeys-lfu：当内存不足以容纳新写入数据时，在键空间中，移除最不经常使用的key 12A~~A~~A~~A~~A~~A~~A~~A~~A~~A~~~|B~~~~~B~~~~~B~~~~~B~~~~~~~~~~~B| 考虑上面的情况，如果在|处删除，那么A距离的时间最久，但实际上A的使用频率要比B频繁，所以合理的淘汰策略应该是淘汰B。LFU就是为应对这种情况而生的。 redis 持久化机制(怎么保证 redis 挂掉之后再重启数据可以进行恢复)很多时候我们需要持久化数据也就是将内存中的数据写入到硬盘里面，大部分原因是为了之后重用数据（比如重启机器、机器故障之后恢复数据），或者是为了防止系统故障而将数据备份到一个远程位置。 Redis不同于Memcached的很重一点就是，Redis支持持久化，而且支持两种不同的持久化操作。Redis的一种持久化方式叫快照（snapshotting，RDB），另一种方式是只追加文件（append-only file,AOF）。这两种方法各有千秋，下面我会详细这两种持久化方法是什么，怎么用，如何选择适合自己的持久化方法。 快照（snapshotting）持久化（RDB）Redis可以通过创建快照来获得存储在内存里面的数据在某个时间点上的副本。Redis创建快照之后，可以对快照进行备份，可以将快照复制到其他服务器从而创建具有相同数据的服务器副本（Redis主从结构，主要用来提高Redis性能），还可以将快照留在原地以便重启服务器的时候使用。与AOF相比，在恢复大的数据集时会更快。 有两个Redis命令可以用于生成RDB文件，一个是SAVE，另一个是BGSAVE SAVE命令会阻塞Redis服务器进程，直到RDB文件创建完毕。期间服务器不能处理任何命令请求 BGSAVE命令会派生出一个子进程，然后由子进程负责创建RDB文件，服务器进程(父进程)继续处理命令请求 快照持久化是Redis默认采用的持久化方式，在redis.conf配置文件中默认有此下配置： 12345save 900 1 #在900秒(15分钟)之后，如果至少有1个key发生变化，Redis就会自动触发BGSAVE命令创建快照。save 300 10 #在300秒(5分钟)之后，如果至少有10个key发生变化，Redis就会自动触发BGSAVE命令创建快照。save 60 10000#在60秒(1分钟)之后，如果至少有10000个key发生变化，Redis就会自动触发BGSAVE命令创建快照。 AOF（append-only file）持久化以日志的形式记录写操作。 与快照持久化相比，AOF持久化 的实时性更好，因此已成为主流的持久化方案。默认情况下Redis没有开启AOF（append only file）方式的持久化，可以通过appendonly参数开启： 1appendonly yes 开启AOF持久化后每执行一条会更改Redis中的数据的命令，Redis就会将该命令写入硬盘中的AOF文件。AOF文件的保存位置和RDB文件的位置相同，都是通过dir参数设置的，默认的文件名是appendonly.aof。 AOF持久化功能的实现分为命令追加，文件写入，文件同步三个步骤。 文件追加：服务器执行完一个写命令，会将执行的命令以协议格式追加到AOF缓冲区。 AOF文件写入和同步：将AOF缓冲区中的所有内容写入并同步到 AOF 文件中。 在Redis的配置文件中存在三种不同的 AOF 持久化方式，它们分别是： 123appendfsync always #每次有数据修改发生时都会写入AOF文件,这样会严重降低Redis的速度appendfsync everysec #每秒钟同步一次，显示地将多个写命令同步到硬盘appendfsync no #让操作系统决定何时进行同步 为了兼顾数据和写入性能，用户可以考虑 appendfsync everysec选项 ，让Redis每秒同步一次AOF文件，Redis性能几乎没受到任何影响。而且这样即使出现系统崩溃，用户最多只会丢失一秒之内产生的数据。当硬盘忙于执行写入操作的时候，Redis还会优雅的放慢自己的速度以便适应硬盘的最大写入速度。 开启了RDB时，也可以同时开启AOF，但是恢复的时候会从AOF恢复。 优缺点对比： 1.对于同一份数据来说，AOF日志文件通常比RDB数据快照文件更大，恢复速度慢； 2.RDB与AOF相比，在恢复大的数据集时会更快。 3.AOF可以更好的保护数据不丢失。RDB可能会丢失崩溃到上一次快照的数据。 4.RDB在保存的时候需要复制一个副本。如果比较大的话，占内存。 Redis 4.0 对于持久化机制的优化 Redis 4.0 开始支持 RDB 和 AOF 的混合持久化（默认关闭，可以通过配置项 aof-use-rdb-preamble 开启）。 如果把混合持久化打开，AOF 重写的时候就直接把 RDB 的内容写到 AOF 文件开头。这样做的好处是可以结合 RDB 和 AOF 的优点, 快速加载同时避免丢失过多的数据。当然缺点也是有的， AOF 里面的 RDB 部分是压缩格式不再是 AOF 格式，可读性较差。 补充内容：AOF 重写 显然，.aof文件会越来越大，文件大小当达到某个值的时候，触发AOF重写。从Redis数据库遍历数据，得到set命令。重写得到新的aof文件。 AOF重写可以产生一个新的AOF文件，这个新的AOF文件和原有的AOF文件所保存的数据库状态一样，但体积更小。 AOF重写是一个有歧义的名字，该功能是通过读取数据库中的键值对来实现的，程序无须对现有AOF文件进行任何读入、分析或者写入操作。 AOF后台重写执行命令BGREWRITEAOF时，除了创建一个子进程（带有服务器进程的数据副本）来重写AOF文件，还会维护一个AOF重写缓冲区，记录子进程运行期间服务器执行的所有写命令。当子进程完成创建AOF文件后，服务器会将重写缓冲区的内容追加到新AOF文件末尾。完成AOF文件后台重写。 Redis事务DISCARD 取消事务，放弃执行事务块内的所有命令。EXEC 执行所有事务块内的命令。MULTI 标记一个事务块的开始。UNWATCH 取消 WATCH 命令对所有 key 的监视。WATCH key [key …]监视一个(或多个) key ，如果在事务执行之前这个(或这些) key 被其他命令所改动，那么事务将被打断。 在redis中，对于一个存在问题的命令，如果在入队的时候就已经出错，整个事务内的命令将都不会被执行（其后续的命令依然可以入队），如果这个错误命令在入队的时候并没有报错，而是在执行的时候出错了，那么redis默认跳过这个命令执行后续命令，不会回滚（没有原子性）。 Redis的集群模式主从模式（复制） 所有的写请求都被发送到主数据库。在由主数据库将数据同步到从数据库上。从数据库主要用于执行读操作缓解系统的读压力。 SYNC命令非常消耗资源。为了解决旧版复制功能在断线重复制的低效问题，Redis从2.8开始使用PSYNC命令代替SYNC命令。 PSYNC分为完整重同步和部分重同步，完整重同步时PSYNC和SYNC一样，部分重同步则用于处理断线后重复制情况。（如果丢失的命令不是太多，不需要生成RDB文件，更高效，免得复制还存在从数据库的数据） 复制的实现从服务器发送SLAVEOF命令，就可以让一个从服务器复制一个主服务器 SLAVEOF &lt;master_ip&gt; &lt;master_port&gt; 主从模式的优点：1.读写分离，分担master的读压力 2.master和slave之间的同步是非阻塞的，客户端在这期间可以提交查询或更新请求 缺点：1.不具备自动容错与恢复功能，master或slave宕机都可能导致客户端请求失败，需要等待机器重启或手动切换客户端IP才能恢复 2.难以支持在线扩容，Redis的容量受限于单机配置 哨兵模式 哨兵模式基于主从复制模式，只是引入了哨兵来监控与自动处理故障。 其原理是哨兵通过发送命令，等待Redis服务器响应，从而监控运行的多个Redis服务器。 这里的哨兵有两个作用 通过发送命令，让Redis服务器返回监控其运行状态，包括主服务器和从服务器。 当哨兵监测到master宕机，会自动将slave切换成master，然后通过发布订阅模式通知其他的从服务器，修改配置文件，让它们切换主机。（master宕机后重新上线会变成从服务器） 然而一个哨兵进程对Redis服务器进行监控，可能会出现问题，为此，我们可以使用多个哨兵进行监控。各个哨兵之间还会进行监控，这样就形成了多哨兵模式。 哨兵模式优点：1.主从的优点都有 2.master宕机时，可以切换master主机，系统可用性更高 缺点：集群模式哨兵模式基本可以满足一般生产的需求，具备高可用性。但是当数据量过大到一台服务器存放不下的情况时，主从模式或哨兵模式就不能满足需求了，这个时候需要对存储的数据进行分片，将数据存储到多个Redis实例中。cluster模式的出现就是为了解决单机Redis容量有限的问题，将Redis的数据根据一定的规则分配到多台机器。 cluster可以说是sentinel和主从模式的结合体，通过cluster可以实现主从和master重选功能，所以如果配置两个副本三个分片的话，就需要六个Redis实例。因为Redis的数据是根据一定规则分配到cluster的不同机器的，当数据量过大时，可以新增机器进行扩容。 集群模式特点： 无中心架构，所有的节点都是一主一从（也可以是一主多从），其中从不提供服务，仅作为备用（备份） 不支持同时处理多个key（如MSET/MGET），因为redis需要把key均匀分布在各个节点上，并发量很高的情况下同时创建key-value会降低性能并导致不可预测的行为 支持在线增加、删除节点 客户端可以连接任何一个主节点进行读写执行之前这个(或这些) key 被其他命令所改动，那么事务将被打断。 集群模式优点：1.无中心架构，每个节点都是平等的关系，存储的数据各不相同 2.可以动态拓展或删除节点 缺点：不支持同时处理多个key 一致性Hash对于分布式缓存，不同机器上存储不同对象的数据。为了实现这些缓存机器的负载均衡，可以使用m=hash(o) mod n 来定位对象缓存的存储机器：o为对象的名称，n为机器的数量，m为机器的编号。 普通hash在大部分时候都可以工作得很好，然而，当机器需要扩容或者机器出现宕机的情况下，事情就比较棘手了。当机器扩容，需要增加一台缓存机器时，负载均衡器使用的式子变成： m = hash(o) mod (n + 1) ——式子2 当机器宕机，机器数量减少一台时，负载均衡器使用的式子变成： m = hash(o) mod (n - 1) ——式子3 这样的话，大部分的图片计算出来的缓存位置都会改变，造成大面积的缓存失效。可能导致缓存雪崩。 一致性hash算法正是为了解决此类问题的方法，它可以保证当机器增加或者减少时，对缓存访问命中的概率影响减至很小。 一致性hash算法通过一个叫作一致性hash环的数据结构实现。这个环的起点是0，终点是2^32 - 1，并且起点与终点连接，环的中间的整数按逆时针分布，故这个环的整数分布范围是[0, 2^32-1] 一致性hash算法解决了分布式环境下机器增加或者减少时，简单的取模运算无法获取较高命中率的问题。通过虚拟节点的使用，一致性hash算法可以均匀分担机器的负载，使得这一算法更具现实的意义。正因如此，一致性hash算法被广泛应用于分布式系统中。 一致性hash 缓存雪崩和缓存穿透问题解决方案 什么是缓存雪崩？ 简介：缓存同一时间大面积的失效，所以，后面的请求都会落到数据库上，造成数据库短时间内承受大量请求而崩掉。 eg:对于系统 A，假设每天高峰期每秒 5000 个请求，本来缓存在高峰期可以扛住每秒 4000 个请求，但是缓存机器意外发生了全盘宕机。缓存挂了，此时 1 秒 5000 个请求全部落数据库，数据库必然扛不住，它会报一下警，然后就挂了。此时，如果没有采用什么特别的方案来处理这个故障，DBA 很着急，重启数据库，但是数据库立马又被新的流量给打死了。这就是缓存雪崩。 有哪些解决办法？ 事前：尽量保证整个 redis 集群的高可用性，发现机器宕机尽快补上。选择合适的内存淘汰策略。 事中：本地ehcache缓存 + hystrix限流&amp;降级，避免MySQL崩掉 事后：利用 redis 持久化机制保存的数据尽快恢复缓存 什么是缓存穿透？ 缓存穿透说简单点就是大量请求的 key 根本不存在于缓存中，导致请求直接到了数据库上，根本没有经过缓存这一层。举个例子：某个黑客故意制造我们缓存中不存在的 key 发起大量请求，导致大量请求落到数据库。 对于系统A，假设一秒 5000 个请求，结果其中 4000 个请求是黑客发出的恶意攻击。 黑客发出的那 4000 个攻击，缓存中查不到，每次你去数据库里查，也查不到。 举个栗子。数据库 id 是从 1 开始的，结果黑客发过来的请求 id 全部都是负数。这样的话，缓存中不会有，请求每次都“视缓存于无物”，直接查询数据库。这种恶意攻击场景的缓存穿透就会直接把数据库给打死。 有哪些解决办法？ 最基本的就是首先做好参数校验，一些不合法的参数请求直接抛出异常信息返回给客户端。比如查询的数据库 id 不能小于 0、传入的邮箱格式不对的时候直接返回错误消息给客户端等等。 缓存无效 key : 如果缓存和数据库都查不到某个 key 的数据就写一个到 redis 中(可设置为空值)去并设置过期时间，具体命令如下：SET key value EX 10086。这种方式可以解决请求的 key 变化不频繁的情况，如果黑客恶意攻击，每次构建不同的请求key，会导致 redis 中缓存大量无效的 key 。很明显，这种方案并不能从根本上解决此问题。如果非要用这种方式来解决穿透问题的话，尽量将无效的 key 的过期时间设置短一点比如 1 分钟。 布隆过滤器 布隆过滤器是一个非常神奇的数据结构，类似于一个hash set，用于快速判某个元素是否存在于集合中。通过它我们可以非常方便地判断一个给定数据是否存在与海量数据中。我们需要的就是判断 key 是否合法，有没有感觉布隆过滤器就是我们想要找的那个“人”。具体是这样做的：把所有可能存在的请求的值都存放在布隆过滤器中，当用户请求过来，我会先判断用户发来的请求的值是否存在于布隆过滤器中。不存在的话，直接返回请求参数错误信息给客户端，存在的话才会走redis流程。 缓存击穿 缓存击穿，就是说某个 key 非常热点，访问非常频繁，处于集中式高并发访问的情况，当这个 key 在失效的瞬间，大量的请求就击穿了缓存，直接请求数据库，就像是在一道屏障上凿开了一个洞。 解决方式也很简单，可以将热点数据设置为永远不过期；或者基于 redis or zookeeper 实现互斥锁，等待第一个请求构建完缓存之后，再释放锁，进而其它请求才能通过该 key 访问数据（走redis）。 如何解决 Redis 的并发竞争 Key 问题：分布式锁所谓 Redis 的并发竞争 Key 的问题也就是多个系统同时对一个 key 进行写操作，但是最后执行的顺序和我们期望的顺序不同，这样也就导致了结果的不同！ 推荐一种方案：分布式锁（zookeeper 和 redis 都可以实现分布式锁）。（如果不存在 Redis 的并发竞争 Key 问题，不要使用分布式锁，这样会影响性能） Redis实现（setnx）见分布式锁) 第二种方案： 在并发量过大的情况下,可以通过消息中间件进行处理,把并行读写进行串行化。 把Redis.set操作放在队列中使其串行化,必须的一个一个执行。这种方式在一些高并发的场景中算是一种通用的解决方案。 第三种方案：乐观锁 利用watch命令使用CAS。redis中可以使用watch命令会监视给定的key，当exec时候如果监视的key从调用watch后发生过变化，则整个事务会失败。也可以调用watch多次监视多个key。这样就可以对指定的key加乐观锁了。注意watch的key是对整个连接有效的，事务也一样。如果连接断开，监视和事务都会被自动清除。当然了exec，discard，unwatch命令都会清除连接中的所有监视。 缓存淘汰策略在缓存数据过多时需要使用某种淘汰算法决定淘汰哪些数据。常用的有以下几种。 FIFO(First In First Out) : 判断被存储的时间，离目前最远的数据优先被淘汰。 LRU(Least Recently Used) : 判断缓存最近被使用的时间，距离当前时间最远的数据优先被淘汰。 LFU(Least Frequently Used) : 在一段时间内，被使用次数最少的缓存优先被淘汰。 常见面试题redis为啥比mysql快？1）.Redis是基于内存存储的，MySQL是基于磁盘存储的 2）.Redis存储的是k-v格式的数据。时间复杂度是O(1),常数阶，而MySQL引擎的底层实现是B+Tree，时间复杂度是O(logn)，对数阶。Redis会比MySQL快一点点。 3）.MySQL数据存储是存储在表中，查找数据时要先对表进行全局扫描或者根据索引查找，这涉及到磁盘的查找，磁盘查找如果是按条点查找可能会快点，但是顺序查找就比较慢；而Redis不用这么麻烦，本身就是存储在内存中，会根据数据在内存的位置直接取出。 4）.Redis是单线程的多路复用IO，单线程避免了线程切换的开销，而多路复用IO避免了IO等待的开销，在多核处理器下提高处理器的使用效率可以对数据进行分区，然后每个处理器处理不同的数据。 Redis没有直接使用C字符串没有使用C字符串(即以空字符’\0’结尾的字符数组)作为默认的字符串表示，而是使用了SDS。SDS是简单动态字符串(Simple Dynamic String)的缩写。Reidis的SDS在C字符串的基础上加入了free和len字段 RDB和AOF的优缺点RDB持久化 优点：RDB文件紧凑，体积小，网络传输快，适合全量复制；恢复速度比AOF快很多。当然，与AOF相比，RDB最重要的优点之一是对性能的影响相对较小。 缺点：RDB文件的致命缺点在于其数据快照的持久化方式决定了必然做不到实时持久化，而在数据越来越重要的今天，数据的大量丢失很多时候是无法接受的，因此AOF持久化成为主流。此外，RDB文件需要满足特定格式，兼容性差（如老版本的Redis不兼容新版本的RDB文件）。 AOF持久化 与RDB持久化相对应，AOF的优点在于支持秒级持久化、兼容性好，缺点是文件大、恢复速度慢、对性能影响大。 判断key是否存在 删除keyexists key +key名字 del key 手撸一个LRU算法12345678910111213141516171819class LRUcache&lt;K,V&gt; extends LinkedHashMap&lt;K,V&gt; &#123; private final int CACHE_SIZE; /** 传递进来最多能缓存多少数据 @param cacheSize 缓存大小 **/ public LREcache(int cacheSize) &#123; //true 表示让linkedHashMap按照访问顺序来进行排序，最近访问的放在头部，最老访问的放在尾部。 super((int)Math.ceil(cacheSize / 0.75) + 1, 0.75f, true) //Math.ceil()向上取整，加载因子 CACHE_SIZE = cacheSize; &#125; @Override protected boolean removeEldestEntry(Map.entry&lt;K,V&gt; eldest) &#123; //当map中的数据量大于指定的缓存个数的时候，就自动删除最老的数据。 return size() &gt; CACHE_SIZE; &#125;&#125; 如果有大量的key需要设置同一时间过期，一般需要注意什么？如果大量的key过期时间设置的过于集中，到过期的那个时间点，redis可能会出现短暂的卡顿现象。严重的话会出现缓存雪崩，我们一般需要在时间上加一个随机值，使得过期时间分散一些。 布隆过滤器它 实际上 是一个很长的二进制向量和一系列随机映射函数 (哈希函数)，实际上你也可以把它 简单理解 为一个不怎么精确的 set 结构，当你使用它的 contains 方法判断某个对象是否存在时，它可能会误判。但是布隆过滤器也不是特别不精确，只要参数设置的合理，它的精确度可以控制的相对足够精确，只会有小小的误判概率。 当布隆过滤器说某个值存在时，这个值 可能不存在；当它说不存在时，那么 一定不存在。 常用的五种数据结构及其底层结构Redis过期时间是如何实现的？底层有两个dict 一个dict对应key value ， 一个dict对应key expireTime，在查询的时候回去看有无expireTime，过期则删除。 Redis rehash操作 以下是哈希表渐进式 rehash 的详细步骤： 为 ht[1] 分配空间， 让字典同时持有 ht[0] 和 ht[1] 两个哈希表。 在字典中维持一个索引计数器变量 rehashidx ， 并将它的值设置为 0 ， 表示 rehash 工作正式开始。 在 rehash 进行期间， 每次对字典执行添加、删除、查找或者更新操作时， 程序除了执行指定的操作以外， 还会顺带将 ht[0] 哈希表在 rehashidx 索引上的所有键值对 rehash 到 ht[1] ， 当 rehash 工作完成之后， 程序将 rehashidx 属性的值增一。 随着字典操作的不断执行， 最终在某个时间点上， ht[0] 的所有键值对都会被 rehash 至 ht[1] ， 这时程序将 rehashidx 属性的值设为 -1 ， 表示 rehash 操作已完成。 渐进式 rehash 的好处在于它采取分而治之的方式， 将 rehash 键值对所需的计算工作均滩到对字典的每个添加、删除、查找和更新操作上， 从而避免了集中式 rehash 而带来的庞大计算量。 因为在进行渐进式 rehash 的过程中， 字典会同时使用 ht[0] 和 ht[1] 两个哈希表， 所以在渐进式 rehash 进行期间， 字典的删除（delete）、查找（find）、更新（update）等操作会在两个哈希表上进行： 比如说， 要在字典里面查找一个键的话， 程序会先在 ht[0] 里面进行查找， 如果没找到的话， 就会继续到 ht[1] 里面进行查找， 诸如此类。 另外， 在渐进式 rehash 执行期间， 新添加到字典的键值对一律会被保存到 ht[1] 里面， 而 ht[0] 则不再进行任何添加操作： 这一措施保证了 ht[0] 包含的键值对数量会只减不增， 并随着 rehash 操作的执行而最终变成空表。]]></content>
  </entry>
  <entry>
    <title><![CDATA[JVM垃圾回收]]></title>
    <url>%2F2020%2F03%2F20%2FJVM%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%2F</url>
    <content type="text"><![CDATA[揭开 JVM 内存分配与回收的神秘面纱Java 的自动内存管理主要是针对对象内存的回收和对象内存的分配。同时，Java 自动内存管理最核心的功能是 堆 内存中对象的分配与回收。 Java 堆是垃圾收集器管理的主要区域，因此也被称作GC 堆（Garbage Collected Heap）.从垃圾回收的角度，由于现在收集器基本都采用分代垃圾收集算法，所以 Java 堆还可以细分为：新生代和老年代：再细致一点有：Eden 空间、From Survivor、To Survivor 空间等。进一步划分的目的是更好地回收内存，或者更快地分配内存。 堆空间的基本结构 8：1：1：20 上图所示的 eden 区、s0(“From”) 区、s1(“To”) 区都属于新生代，tentired 区属于老年代。大部分情况，对象都会首先在 Eden 区域分配，在一次新生代垃圾回收后，如果对象还存活，则会进入 s1(“To”)，并且对象的年龄还会加 1(Eden 区-&gt;Survivor 区后对象的初始年龄变为 1)，当它的年龄增加到一定程度（默认为 15 岁），就会被晋升到老年代中。对象晋升到老年代的年龄阈值，可以通过参数 -XX:MaxTenuringThreshold 来设置。经过这次GC后，Eden区和”From”区已经被清空。这个时候，”From”和”To”会交换他们的角色，也就是新的”To”就是上次GC前的“From”，新的”From”就是上次GC前的”To”。不管怎样，都会保证名为To的Survivor区域是空的。Minor GC会一直重复这样的过程，直到“To”区被填满，”To”区被填满之后，会将所有对象移动到老年代中。 对象优先在 eden 区分配 目前主流的垃圾收集器都会采用分代回收算法，因此需要将堆内存分为新生代和老年代，这样我们就可以根据各个年代的特点选择合适的垃圾收集算法。 大多数情况下，对象在新生代中 eden 区分配。当 eden 区没有足够空间进行分配时，虚拟机将发起一次 Minor GC.下面我们来进行实际测试以下。 在测试之前我们先来看看 Minor GC 和 Full GC 有什么不同呢？ 新生代 GC（Minor GC）:指发生新生代的的垃圾收集动作，Minor GC 非常频繁，回收速度一般也比较快。 老年代 GC（Major GC/Full GC）:指发生在老年代的 GC，出现了 Major GC 经常会伴随至少一次的 Minor GC（并非绝对），Major GC 的速度一般会比 Minor GC 的慢 10 倍以上。 大对象直接进入老年代 大对象就是需要大量连续内存空间的对象（比如：字符串、数组）。 为什么要这样呢？ 为了避免为大对象分配内存时由于分配担保机制（Eden不够，提前把新生代的对象转移到老年代中去）带来的复制而降低效率。 长期存活的对象将进入老年代 既然虚拟机采用了分代收集的思想来管理内存，那么内存回收时就必须能识别哪些对象应放在新生代，哪些对象应放在老年代中。为了做到这一点，虚拟机给每个对象一个对象年龄（Age）计数器。 如果对象在 Eden 出生并经过第一次 Minor GC 后仍然能够存活，并且能被 Survivor 容纳的话，将被移动到 Survivor 空间中，并将对象年龄设为 1.对象在 Survivor 中每熬过一次 MinorGC,年龄就增加 1 岁，当它的年龄增加到一定程度（默认为 15 岁），就会被晋升到老年代中。对象晋升到老年代的年龄阈值，可以通过参数 -XX:MaxTenuringThreshold 来设置。 大部分情况，对象都会首先在 Eden 区域分配，在一次新生代垃圾回收后，如果对象还存活，则会进入 s0 或者 s1，并且对象的年龄还会加 1(Eden 区-&gt;Survivor 区后对象的初始年龄变为 1)，当它的年龄增加到一定程度（默认为 15 岁），就会被晋升到老年代中。对象晋升到老年代的年龄阈值，可以通过参数 -XX:MaxTenuringThreshold 来设置。 修正：“Hotspot遍历所有对象时，按照年龄从小到大对其所占用的大小进行累积，当累积的某个年龄大小超过了survivor区的一半时，取这个年龄和MaxTenuringThreshold中更小的一个值，作为新的晋升年龄阈值”。 对象已经死亡？堆中几乎放着所有的对象实例，对堆垃圾回收前的第一步就是要判断那些对象已经死亡（即不能再被任何途径使用的对象）。 引用计数法给对象中添加一个引用计数器，每当有一个地方引用它，计数器就加 1；当引用失效，计数器就减 1；任何时候计数器为 0 的对象就是不可能再被使用的。 这个方法实现简单，效率高，但是目前主流的虚拟机中并没有选择这个算法来管理内存，其最主要的原因是它很难解决对象之间相互循环引用的问题。 所谓对象之间的相互引用问题，如下面代码所示：除了对象 objA 和 objB 相互引用着对方之外，这两个对象之间再无任何引用。但是他们因为互相引用对方，导致它们的引用计数器都不为 0，于是引用计数算法无法通知 GC 回收器回收他们。 123456789101112public class ReferenceCountingGc &#123; Object instance = null; public static void main(String[] args) &#123; ReferenceCountingGc objA = new ReferenceCountingGc(); ReferenceCountingGc objB = new ReferenceCountingGc(); objA.instance = objB; objB.instance = objA; objA = null; objB = null; &#125;&#125; 可达性分析算法这个算法的基本思想就是通过一系列的称为 “GC Roots” 的对象作为起点，从这些节点开始向下搜索，节点所走过的路径称为引用链，当一个对象到 GC Roots 没有任何引用链相连的话，则证明此对象是不可用的。 常用的GC Roots: a.虚拟机栈(栈桢中的本地变量表)中的引用的对象 b.方法区中的类静态属性引用的对象 c.方法区中的常量引用的对象 d.本地方法栈中JNI的引用的对象 再谈引用 略 不可达的对象并非“非死不可” 即使在可达性分析法中不可达的对象，也并非是“非死不可”的，这时候它们暂时处于“缓刑阶段”，要真正宣告一个对象死亡，至少要经历两次标记过程；可达性分析法中不可达的对象被第一次标记并且进行一次筛选，筛选的条件是此对象是否有必要执行 finalize 方法。当对象没有覆盖 finalize 方法，或 finalize 方法已经被虚拟机调用过时，虚拟机将这两种情况视为没有必要执行。 被判定为需要执行的对象将会被放在一个队列中进行第二次标记，除非这个对象与引用链上的任何一个对象建立关联，否则就会被真的回收。 回收方法区 如何判断一个常量是废弃常量 运行时常量池主要回收的是废弃的常量。那么，我们如何判断一个常量是废弃常量呢？ 假如在常量池中存在字符串 “abc”，如果当前没有任何 String 对象引用该字符串常量的话，就说明常量 “abc” 就是废弃常量，如果这时发生内存回收的话而且有必要的话，”abc” 就会被系统清理出常量池。 如何判断一个类是无用的类 方法区主要回收的是无用的类，那么如何判断一个类是无用的类的呢？ 判定一个常量是否是“废弃常量”比较简单，而要判定一个类是否是“无用的类”的条件则相对苛刻许多。类需要同时满足下面 3 个条件才能算是 “无用的类” ： 该类所有的实例都已经被回收，也就是 Java 堆中不存在该类的任何实例。 加载该类的 ClassLoader 已经被回收。 该类对应的 java.lang.Class 对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。 虚拟机可以对满足上述 3 个条件的无用类进行回收，这里说的仅仅是“可以”，而并不是和对象一样不使用了就会必然被回收。 垃圾收集算法 标记-清除算法 该算法分为“标记”和“清除”阶段：首先标记出所有需要回收的对象，在标记完成后统一回收所有被标记的对象。它是最基础的收集算法，后续的算法都是对其不足进行改进得到。这种垃圾收集算法会带来两个明显的问题： 效率问题 空间问题（标记清除后会产生大量不连续的碎片） 标记-复制算法（新生代） 为了解决效率问题，“复制”收集算法出现了。它可以将内存分为大小相同的两块，每次使用其中的一块。当这一块的内存使用完后，就将还存活的对象复制到另一块去，然后再把使用的空间一次清理掉。这样就使每次的内存回收都是对内存区间的一半进行回收。 新生代：eden s0 s1 新生代98%的对象都是可被回收的，所以多分了一个eden区，占整个新生代的80%，一直都是可用的。只有10%浪费。 标记-整理算法（老年代） 标记复制算法在对象存活率较高时就要进行较多的复制操作，效率将会降低。所以老年代一般不用标记复制而用标记整理算法。 根据老年代的特点提出的一种标记算法，标记过程仍然与“标记-清除”算法一样，但后续步骤不是直接对可回收对象回收，而是让所有存活的对象向一端移动，然后直接清理掉端边界以外的内存。 分代收集算法 当前虚拟机的垃圾收集都采用分代收集算法，这种算法没有什么新的思想，只是根据对象存活周期的不同将内存分为几块。一般将 java 堆分为新生代和老年代，这样我们就可以根据各个年代的特点选择合适的垃圾收集算法。 比如在新生代中，每次收集都会有大量对象死去，所以可以选择复制算法，只需要付出少量对象的复制成本就可以完成每次垃圾收集。而老年代的对象存活几率是比较高的，而且没有额外的空间对它进行分配担保，所以我们必须选择“标记-清除”或“标记-整理”算法进行垃圾收集。 延伸面试问题： HotSpot 为什么要分为新生代和老年代？ 根据上面的对分代收集算法的介绍回答。 垃圾收集器 如果说收集算法是内存回收的方法论，那么垃圾收集器就是内存回收的具体实现。 虽然我们对各个收集器进行比较，但并非要挑选出一个最好的收集器。因为直到现在为止还没有最好的垃圾收集器出现，更加没有万能的垃圾收集器，我们能做的就是根据具体应用场景选择适合自己的垃圾收集器。试想一下：如果有一种四海之内、任何场景下都适用的完美收集器存在，那么我们的 HotSpot 虚拟机就不会实现那么多不同的垃圾收集器了。 Serial 收集器（新生代）Serial（串行）收集器收集器是最基本、历史最悠久的垃圾收集器了。大家看名字就知道这个收集器是一个单线程收集器了。它的 “单线程” 的意义不仅仅意味着它只会使用一条垃圾收集线程去完成垃圾收集工作，更重要的是它在进行垃圾收集工作的时候必须暂停其他所有的工作线程（ “Stop The World” ），直到它收集结束。 他是新生代收集器，采用标记-复制算法。 虚拟机的设计者们当然知道 Stop The World 带来的不良用户体验，所以在后续的垃圾收集器设计中停顿时间在不断缩短（仍然还有停顿，寻找最优秀的垃圾收集器的过程仍然在继续）。 但是 Serial 收集器有没有优于其他垃圾收集器的地方呢？当然有，它简单而高效（与其他收集器的单线程相比）。Serial 收集器由于没有线程交互的开销，自然可以获得很高的单线程收集效率。Serial 收集器对于运行在 Client 模式下的虚拟机来说是个不错的选择。 ParNew 收集器（新生代）ParNew 收集器其实就是 Serial 收集器的多线程版本，除了使用多线程进行垃圾收集外，其余行为（控制参数、收集算法、回收策略等等）和 Serial 收集器完全一样。也采用标记-复制算法。 它是许多运行在 Server 模式下的虚拟机的首要选择，除了 Serial 收集器外，只有它能与 CMS 收集器（真正意义上的并发收集器，后面会介绍到）配合工作。 并行和并发概念补充： 并行（Parallel） ：指多条垃圾收集线程并行工作，但此时用户线程仍然处于等待状态。 并发（Concurrent）：指用户线程与垃圾收集线程同时执行（但不一定是并行，可能会交替执行），用户程序在继续运行，而垃圾收集器运行在另一个 CPU 上。 Parallel Scavenge 收集器（新生代）Parallel Scavenge 收集器也是使用复制算法的多线程收集器，它看上去几乎和ParNew都一样。多线程。 那么它有什么特别之处呢？ 1234567-XX:+UseParallelGC 使用 Parallel 收集器+ 老年代串行-XX:+UseParallelOldGC 使用 Parallel 收集器+ 老年代并行 Parallel Scavenge 收集器关注点是吞吐量（高效率的利用 CPU）。CMS 等垃圾收集器的关注点更多的是用户线程的停顿时间（提高用户体验）。所谓吞吐量就是 CPU 中用于运行用户代码的时间与 CPU 总消耗时间的比值。 Parallel Scavenge 收集器提供了很多参数供用户找到最合适的停顿时间或最大吞吐量，如果对于收集器运作不太了解的话，手工优化存在困难的话可以选择把内存管理优化交给虚拟机去完成也是一个不错的选择。 Serial Old收集器（老年代）是Serial收集器的老年代版本，同样是单线程，但使用的是标记整理算法。 Parallel Old收集器（老年代）是Parallel Scavenge收集器的老年代版本。基于标记整理算法。 CMS 收集器（老年代）CMS（Concurrent Mark Sweep）收集器是一种以获取最短回收停顿时间为目标的收集器。它非常符合在注重用户体验的应用上使用。 CMS（Concurrent Mark Sweep）收集器是 HotSpot 虚拟机第一款真正意义上的并发收集器，它第一次实现了让垃圾收集线程与用户线程（基本上）同时工作。 从名字中的Mark Sweep这两个词可以看出，CMS 收集器是一种 “标记-清除”算法实现的，它的运作过程相比于前面几种垃圾收集器来说更加复杂一些。整个过程分为四个步骤： 初始标记： 暂停所有的其他线程，并记录下直接与 root 相连的对象，速度很快 ； 并发标记： 同时开启 GC 和用户线程，用一个闭包结构去记录可达对象。但在这个阶段结束，这个闭包结构并不能保证包含当前所有的可达对象。因为用户线程可能会不断的更新引用域，所以 GC 线程无法保证可达性分析的实时性。所以这个算法里会跟踪记录这些发生引用更新的地方。 重新标记： 重新标记阶段就是为了修正并发标记期间因为用户程序继续运行而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段的时间稍长，远远比并发标记阶段时间短 并发清除： 开启用户线程，同时 GC 线程开始对为标记的区域做清扫。 从它的名字就可以看出它是一款优秀的垃圾收集器，主要优点：并发收集、低停顿。但是它有下面三个明显的缺点： 对 CPU 资源敏感；（虽然基本不会导致用户进行停顿，但却因为占用了一部分线程，导致吞吐量降低。） 无法处理浮动垃圾；（并发阶段，用户线程还在进行，会有新的垃圾对象产生。而且需要预留内存给用户线程使用，不能像其它收集器一样等老年代完全满了再进行收集。预留空间不足可能会产生“并发失败”，虚拟机不得不stop the world，进行垃圾回收） 它使用的回收算法-“标记-清除”算法会导致收集结束时会有大量空间碎片产生。 G1 收集器（新生代，老年代）G1 (Garbage-First) 是一款面向服务器的全功能的垃圾收集器,主要针对配备多颗处理器及大容量内存的机器. 以极高概率满足 GC 停顿时间要求的同时,还具备高吞吐量性能特征.从整体上看是基于标记-整理的，但从局部（两个region之间）上看又是基于标记-复制的。 被视为 JDK1.7 中 HotSpot 虚拟机的一个重要进化特征。它具备一下特点： 并行与并发：G1 能充分利用 CPU、多核环境下的硬件优势，使用多个 CPU（CPU 或者 CPU 核心）来缩短 Stop-The-World 停顿时间。部分其他收集器原本需要停顿 Java 线程执行的 GC 动作，G1 收集器仍然可以通过并发的方式让 java 程序继续执行。 分代收集：虽然 G1 可以不需要其他收集器配合就能独立管理整个 GC 堆，但是还是保留了分代的概念。 空间整合：与 CMS 的“标记–清理”算法不同，G1 从整体来看是基于“标记整理”算法实现的收集器；从局部上来看是基于“复制”算法实现的。 可预测的停顿：这是 G1 相对于 CMS 的另一个大优势，降低停顿时间是 G1 和 CMS 共同的关注点，但 G1 除了追求低停顿外，还能建立可预测的停顿时间模型，能让使用者明确指定在一个长度为 M 毫秒的时间片段内。 G1 收集器的运作大致分为以下几个步骤： 初始标记 并发标记 最终标记 筛选回收 G1 收集器在后台维护了一个优先列表，每次根据允许的收集时间，优先选择回收价值最大的 Region(这也就是它的名字 Garbage-First 的由来)。这种使用 Region 划分内存空间以及有优先级的区域回收方式，保证了 G1 收集器在有限时间内可以尽可能高的收集效率（把内存化整为零）。 Minor GC（新生代，包括eden s0 s1）大多数情况下(大对象直接进入老年代)，对象在新生代Eden区中分配。当Eden区没有足够空间进行分配时，虚拟机将发起一次Minor GC Major GC (老年代)Major GC是清理老年代的内存，但是一般情况下都会伴随一次Minor GC，从而变成Full GC 参考javaguide 常见面试题1.有没有排查过内存泄漏，说一下具体步骤1）确定频繁Full GC现象： 通过“虚拟机进程状况工具：jps”找出正在运行的虚拟机进程id， 再利用“虚拟机统计信息监视工具：jstat”监视虚拟机各种运行状态信息，发现fullGC频繁，确认内存泄露。 2） 找出导致频繁Full GC的原因：使用“Java内存影像工具：jmap”生成堆转储快照；使用Java heap分析工具（如MAT），找出内存占用超出预期的嫌疑对象 3）根据情况，分析嫌疑对象和其他对象的引用关系。 4）分析程序的源代码，找出嫌疑对象数量过多的原因。]]></content>
  </entry>
  <entry>
    <title><![CDATA[JVM]]></title>
    <url>%2F2020%2F03%2F19%2FJVM%2F</url>
    <content type="text"><![CDATA[JVM(java virtual machine)JVM的类加载机制 &amp;&amp; 类加载过程Class 文件需要加载到虚拟机中之后才能运行和使用，那么虚拟机是如何加载这些 Class 文件呢？ 加载 通过全类名获取定义此类的二进制字节流(如硬盘——&gt;内存) 将字节流所代表的静态存储结构转换为方法区的运行时数据结构 在内存中生成一个代表该类的Class 对象,作为方法区这些数据的访问入口 连接（Linking） 验证 主要用于确保Class文件的字节流中包含信息符合JVM要求 准备 主要工作实在方法区中为类变量（不包括实例变量，即未被static修饰的变量）分配内存空间，并设置该类变量的初始默认值，即零值。如int : 0, float: 0.0f 注意：声明为final类型的变量，在准备阶段会为该变量赋值。 如： public static final int value=100; 准备阶段将为value赋值为100. 解析 JVM会将常量池中的符号引用替换为直接引用。解析动作主要针对类或接口、字段、类方法、接口方法、方法类型、方法句柄和调用限定符7类符号引用进行。 符号引用就是一组符号来描述目标，可以是任何字面量。直接引用就是直接指向目标的指针、相对偏移量或一个间接定位到目标的句柄。 初始化 初始化阶段就是执行类构造器方法( ) 的过程（不同于类的构造器） 此方法不需定义，是javac编译器自动收集类中静态代码块和类静态变量的赋值操作组成的。 如果没有上述两个。则不会有( )方法调用 JVM规定，只有父类的方法都执行成功后，子类中的该方法才可以被执行。 对于方法的调用，虚拟机会自己确保其在多线程环境中的安全性。因为方法是带锁线程安全，所以在多线程环境下进行类初始化的话可能会引起死锁，并且这种死锁很难被发现。 卸载 JMM Java语言规范中提到过，JVM中存在一个主存区（Main Memory或Java Heap Memory），Java中所有变量都是存在主存中的，对于所有线程进行共享，而每个线程又存在自己的工作内存（Working Memory），工作内存中保存的是主存中某些变量的拷贝，线程对所有变量的操作并非发生在主存区，而是发生在工作内存中，而线程之间是不能直接相互访问，变量在程序中的传递，是依赖主存来完成的。 JVM的运行时内存 程序计数器内存空间小，线程私有。用于存储当前运行线程所执行的字节码的行号指示器。 如果正在执行的是 Native 方法，这个计数器的值则为 (Undefined)。此内存区域是唯一一个在 Java 虚拟机规范中没有规定任何 OutOfMemoryError 情况的区域。 方法区（永久代）属于线程共享内存区域，存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。 方法区和永久代的关系很像 Java 中接口和类的关系，类实现了接口，而永久代就是 HotSpot 虚拟机对虚拟机规范中方法区的一种实现方式。 也就是说，永久代是 HotSpot 的概念，方法区是 Java 虚拟机规范中的定义，是一种规范，而永久代是一种实现，一个是标准一个是实现。 JDK 1.8 的时候，方法区（HotSpot 的永久代）被彻底移除了（JDK1.7 就已经开始了），取而代之是元空间，元空间使用的是直接内存。 元空间的优点：整个永久代有一个 JVM 本身设置固定大小上限，无法进行调整，而元空间使用的是直接内存，受本机可用内存的限制，虽然元空间仍旧可能溢出，但是比原来出现的几率会更小。 运行时常量池运行时常量池是方法区的一部分，用于存放编译期生成的各种字面量和符号引用。 字面量：文本字符串，被声明为final的常量值，基本数据类型的值，其它。 符号应用：类和结构的完全限定名，字段名称和描述符，方法名称和描述符。 既然运行时常量池是方法区的一部分，自然受到方法区内存的限制，当常量池无法再申请到内存时会抛出 OutOfMemoryError 错误。 JDK1.7 及之后版本的 JVM 已经将运行时常量池从方法区中移了出来，在 Java 堆（Heap）中开辟了一块区域存放运行时常量池。 虚拟机栈线程私有，生命周期和线程一致。描述的是 Java 方法执行的内存模型：每个方法在执行时都会床创建一个栈帧(Stack Frame)用于存储局部变量表、操作数栈、动态链接、方法出口等信息。每一个方法从调用直至执行结束，就对应着一个栈帧从虚拟机栈中入栈到出栈的过程。 局部变量表：存放了编译期可知的各种基本类型(boolean、byte、char、short、int、float、long、double)、对象引用(reference 类型)和 returnAddress 类型(指向了一条字节码指令的地址) StackOverFlowError： 若 Java 虚拟机栈的内存大小不允许动态扩展，那么当线程请求栈的深度超过当前 Java 虚拟机栈的最大深度的时候，就抛出 StackOverFlowError 错误。 OutOfMemoryError： 若 Java 虚拟机栈的内存大小允许动态扩展，且当线程请求栈时内存用完了，无法再动态扩展了，此时抛出 OutOfMemoryError 错误。 堆Java 虚拟机所管理的内存中最大的一块，Java 堆是所有线程共享的一块内存区域，在虚拟机启动时创建。此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例以及数组都在这里分配内存。 Java 堆是垃圾收集器管理的主要区域，因此也被称作GC 堆（Garbage Collected Heap） 本地方法栈和虚拟机栈所发挥的作用非常相似，区别是： 虚拟机栈为虚拟机执行 Java 方法 （也就是字节码）服务，而本地方法栈则为虚拟机使用到的 Native 方法服务。 在 HotSpot 虚拟机中和 Java 虚拟机栈合二为一。 本地方法被执行的时候，在本地方法栈也会创建一个栈帧，用于存放该本地方法的局部变量表、操作数栈、动态链接、出口信息。 方法执行完毕后相应的栈帧也会出栈并释放内存空间，也会出现 StackOverFlowError 和 OutOfMemoryError 两种错误。 类加载器JVM 中内置了三个重要的 ClassLoader，除了 BootstrapClassLoader 其他类加载器均由 Java 实现且全部继承自java.lang.ClassLoader： BootstrapClassLoader(启动类加载器) ：最顶层的加载类，由C++实现，负责加载 JAVA_HOME/lib目录下的jar包和类或者或被 -Xbootclasspath参数指定的路径中的所有类。（String类等java核心类库都是使用引导类加载器） ExtensionClassLoader(扩展类加载器) ：主要负责加载目录 JRE_HOME/lib/ext 目录下的jar包和类，或被 java.ext.dirs 系统变量所指定的路径下的jar包。 AppClassLoader(应用程序类加载器) :面向我们用户的加载器，负责加载当前应用classpath下的所有jar包和类。（用户自定义类：默认使用系统类加载器） 除了上述3种类加载器，我们也可以通过继承java.lang.ClassLoader实现自定义类加载器。 为什么要自定义类加载器？ 答：隔离加载类（不同中间件用不同加载器，避免冲突）；修改类加载方式； 扩展加载源；防止源码泄露。 双亲委派机制 双亲委派机制的核心是保障类的唯一性和安全性。 优点： 1.避免类的重复加载。 2.保护程序安全，防止核心API被篡改。（如，自定义类java.lang.String ,他并不会加载这个。因为他会向上委托到引导类加载器，然后加载那个String。自定义java.lang.Str321 也会报错。禁止的包名，防止其破坏引导类加载器） 对象创建过程 类加载检查 虚拟机遇到一条 new 指令时，首先将去检查这个指令的参数是否能在常量池中定位到这个类的符号引用，并且检查这个符号引用代表的类是否已被加载过、解析和初始化过。如果没有，那必须先执行相应的类加载过程。 分配内存 在类加载检查通过后，接下来虚拟机将为新生对象分配内存。对象所需的内存大小在类加载完成后便可确定，为对象分配空间的任务等同于把一块确定大小的内存从 Java 堆中划分出来。分配方式有 “指针碰撞” 和 “空闲列表” 两种，选择那种分配方式由 Java 堆是否规整决定，而 Java 堆是否规整又由所采用的垃圾收集器是否带有压缩整理功能决定。 选择以上两种方式中的哪一种，取决于 Java 堆内存是否规整。而 Java 堆内存是否规整，取决于 GC 收集器的算法是”标记-清除”，还是”标记-整理”（也称作”标记-压缩”），值得注意的是，复制算法内存也是规整的 内存分配并发问题（补充内容，需要掌握） 在创建对象的时候有一个很重要的问题，就是线程安全，因为在实际开发过程中，创建对象是很频繁的事情，作为虚拟机来说，必须要保证线程是安全的，通常来讲，虚拟机采用两种方式来保证线程安全： CAS+失败重试： CAS 是乐观锁的一种实现方式。所谓乐观锁就是，每次不加锁而是假设没有冲突而去完成某项操作，如果因为冲突失败就重试，直到成功为止。虚拟机采用 CAS 配上失败重试的方式保证更新操作的原子性。 TLAB： 为每一个线程预先在 Eden 区分配一块儿内存，JVM 在给线程中的对象分配内存时，首先在 TLAB 分配，当对象大于 TLAB 中的剩余内存或 TLAB 的内存已用尽时，再采用上述的 CAS 进行内存分配 初始化零值 内存分配完成后，虚拟机需要将分配到的内存空间都初始化为零值（不包括对象头），这一步操作保证了对象的实例字段在 Java 代码中可以不赋初始值就直接使用，程序能访问到这些字段的数据类型所对应的零值。 设置对象头 初始化零值完成之后，虚拟机要对对象进行必要的设置，例如这个对象是那个类的实例、如何才能找到类的元数据信息、对象的哈希码、对象的 GC 分代年龄等信息。 这些信息存放在对象头中。 另外，根据虚拟机当前运行状态的不同，如是否启用偏向锁等，对象头会有不同的设置方式。 执行init方法 在上面工作都完成之后，从虚拟机的视角来看，一个新的对象已经产生了，但从 Java 程序的视角来看，对象创建才刚开始，&lt;init&gt; 方法还没有执行，所有的字段都还为零。所以一般来说，执行 new 指令之后会接着执行 &lt;init&gt; 方法，把对象按照程序员的意愿进行初始化，这样一个真正可用的对象才算完全产生出来。 对象的访问定位 建立对象就是为了使用对象，我们的 Java 程序通过栈上的 reference 数据来操作堆上的具体对象。对象的访问方式由虚拟机实现而定，目前主流的访问方式有①使用句柄和②直接指针两种： 句柄： 如果使用句柄的话，那么 Java 堆中将会划分出一块内存来作为句柄池，reference 中存储的就是对象的句柄地址，而句柄中包含了对象实例数据与类型数据各自的具体地址信息； 直接指针： 如果使用直接指针访问，那么 Java 堆对象的布局中就必须考虑如何放置访问类型数据的相关信息，而 reference 中存储的直接就是对象的地址 这两种对象访问方式各有优势。使用句柄来访问的最大好处是 reference 中存储的是稳定的句柄地址，在对象被移动时只会改变句柄中的实例数据指针，而 reference 本身不需要修改。使用直接指针访问方式最大的好处就是速度快，它节省了一次指针定位的时间开销。 String 对象的两种创建方式 12345String str1 = &quot;abcd&quot;;//先检查字符串常量池中有没有&quot;abcd&quot;，如果字符串常量池中没有，则创建一个，然后 str1 指向字符串常量池中的对象，如果有，则直接将 str1 指向&quot;abcd&quot;&quot;；String str2 = new String(&quot;abcd&quot;);//堆中创建一个新的对象String str3 = new String(&quot;abcd&quot;);//堆中创建一个新的对象System.out.println(str1==str2);//falseSystem.out.println(str2==str3);//false 这两种不同的创建方法是有差别的。 第一种方式是在常量池中拿对象； 第二种方式是直接在堆内存空间创建一个新的对象。 记住一点：只要使用 new 方法，便需要创建新的对象。]]></content>
  </entry>
  <entry>
    <title><![CDATA[Mysql回顾]]></title>
    <url>%2F2020%2F03%2F13%2FMysql%E5%9B%9E%E9%A1%BE%2F</url>
    <content type="text"><![CDATA[Mysql服务器的默认端口是3306。 MyISAM和InnoDB区别两者的对比： 是否支持行级锁 : MyISAM 只有表级锁(table-level locking)，而InnoDB 支持行级锁(row-level locking)和表级锁,默认为行级锁。 是否支持事务和崩溃后的安全恢复： MyISAM 强调的是性能，每次查询具有原子性,其执行速度比InnoDB类型更快，但是不提供事务支持。但是InnoDB 提供事务支持事务，外部键等高级数据库功能。 具有事务(commit)、回滚(rollback)和崩溃修复能力(crash recovery capabilities)的事务安全(transaction-safe (ACID compliant))型表。 是否支持外键： MyISAM不支持，而InnoDB支持。 是否支持MVCC ：仅 InnoDB 支持。应对高并发事务, MVCC比单纯的加锁更高效;MVCC只在 READ COMMITTED 和 REPEATABLE READ 两个隔离级别下工作;MVCC可以使用 乐观(optimistic)锁 和 悲观(pessimistic)锁来实现;各数据库中MVCC实现并不统一。 外键：外键用于与另一张表的关联，用于保持数据一致性。外键必须是Unique或者主键。 多版本并发控制（Multi-Version Concurrency Control, MVCC），顾名思义，在并发访问的时候，数据存在版本的概念，可以有效地提升数据库并发能力，常见的数据库如MySQL、MS SQL Server、IBM DB2、Hbase、MongoDB等等都在使用。 简单讲，如果没有MVCC，当想要读取的数据被其他事务用排它锁锁住时，只能互斥等待；而这时MVCC可以通过提供历史版本从而实现读取被锁的数据(的历史版本)，避免了互斥等待。 在 MySQL中，多版本并发控制是 的 InnoDB 存储引擎实现隔离级别的一种具体方式，用于实现提交读和可重复读这两种隔离级别。而未提交读隔离级别总是读取最新的数据行，无需使用 MVCC；可串行化隔离级别需要对所有读取的行都加锁，单纯使用 MVCC 无法实现。 事务**：指的是满足 ACID 特性的一组操作，可以通过 Commit 提交一个事务，也可以使用 Rollback 进行回滚。 ACID 1.原子性（Atomicity）要么都成功，要么都失败,即事务是最小单位，不允许切割 eg: A账户给B账户转账，A扣100元钱，B增加100元钱 2.一致性（Consistency） 数据库在事务执行前后都保持一致性状态。在一致性状态下，所有事务对同一个数据的读取结果都是相同的。 3.隔离性（Isolation） 一个事务所做的修改在最终提交以前，对其它事务是不可见的。 4.持久性（Durability） 一旦事务提交，则其所做的修改将会永远保存到数据库中。即使系统发生崩溃，事务执行的结果也不能丢失。 并发事务带来的问题： 1.脏读 T1 修改一个数据，T2 随后读取这个数据。如果 T1 撤销了这次修改，那么 T2 读取的数据是脏数据。 2.丢失修改 T1，T2,读取到某数据20，T1修改20-1，T2修改20-1，最终19，T1修改被丢失。 3.不可重复读 T2 读取一个数据，T1 对该数据做了修改。如果 T2 再次读取这个数据，此时读取的结果和第一次读取的结果不同。 4.幻读 同不可重复读一样，T2可能增加了几行，T1蒙蔽了，出现了幻觉。 事务的隔离级别 1.READ-UNCOMMITTED(读取未提交)： 最低的隔离级别，允许读取尚未提交的数据变更，可能会导致脏读、幻读或不可重复读。 2.READ-COMMITTED(读取已提交)： 允许读取并发事务已经提交的数据，可以阻止脏读，但是幻读或不可重复读仍有可能发生。**（先读一次，别人提交，再读一次，不一样我擦，不可重复读） 3.REPEATABLE-READ(可重复读)： 对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，可以阻止脏读和不可重复读，但幻读仍有可能发生。（读的时候加锁，别人就改不了了，可自己可能会改） explain:在可重复读中，该sql第一次读取到数据后，就将这些数据加锁（悲观锁），其它事务无法修改这些数据，就可以实现可重复读了。但这种方法却无法锁住insert的数据，所以当事务A先前读取了数据，或者修改了全部数据，事务B还是可以insert数据提交，这时事务A就会发现莫名其妙多了一条之前没有的数据，这就是幻读，不能通过行锁来避免。需要Serializable隔离级别 ，读用读锁，写用写锁，读锁和写锁互斥，这么做可以有效的避免幻读、不可重复读、脏读等问题，但会极大的降低数据库的并发能力。 其实并不是加锁，而是利用MVCC. MySQL默认的隔离级别是可重复读，即：事务A在读到一条数据之后，此时事务B对该数据进行了修改并提交，那么事务A再读该数据，读到的还是原来的内容。 那么MySQL可重复读是如何实现的呢？MVCC 4.SERIALIZABLE(可串行化)： 最高的隔离级别，完全服从ACID的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，该级别可以防止脏读、不可重复读以及幻读。 MySQL InnoDB 存储引擎的默认支持的隔离级别是 REPEATABLE-READ（可重读） 与 SQL 标准不同的地方在于 InnoDB 存储引擎在 REPEATABLE-READ（可重读） 事务隔离级别下使用的是Next-Key Lock 锁算法，因此可以避免幻读的产生。因为隔离级别越低，事务请求的锁越少，所以大部分数据库系统的隔离级别都是 READ-COMMITTED(读取提交内容) ，但是你要知道的是InnoDB 存储引擎默认使用 REPEAaTABLE-READ（可重读） 并不会有任何性能损失。 InnoDB 存储引擎在 分布式事务 的情况下一般会用到 SERIALIZABLE(可串行化) 隔离级别。 锁机制与InnoDB锁算法MyISAM和InnoDB存储引擎使用的锁： MyISAM采用表级锁(table-level locking)。 InnoDB支持行级锁(row-level locking)和表级锁,默认为行级锁 表级锁和行级锁对比： 表级锁： MySQL中锁定 粒度最大 的一种锁，对当前操作的整张表加锁，实现简单，资源消耗也比较少，加锁快，不会出现死锁。其锁定粒度最大，触发锁冲突的概率最高，并发度最低，MyISAM和 InnoDB引擎都支持表级锁。 行级锁： MySQL中锁定 粒度最小 的一种锁，只针对当前操作的行进行加锁。 行级锁能大大减少数据库操作的冲突。其加锁粒度最小，并发度高，但加锁的开销也最大，加锁慢，会出现死锁（why?，如图所示）。 表锁不会发生这种情况，因为表锁是一次性获取所有表的锁，才开始事务。 记录锁（Record Lock）事务加锁后锁住的只是表的某一条记录。 记录锁出现条件：精准条件命中，并且命中的条件字段是唯一索引； 例如：update user_info set name=’张三’ where id=1 ,这里的id是唯一索引。 记录锁的作用：加了记录锁之后可以避免数据在查询的时候被修改的重复读问题，也避免了在修改的事务未提交前被其他事务读取的脏读问题。 间隙锁（Gap Lock）间隙锁出现的条件：范围查询并且查询未命中记录，查询条件必须命中索引、间隙锁只会出现在REPEATABLE_READ（重复读)的事务级别中。 例如：对应上图的表执行select * from user_info where id&gt;1 and id&lt;4(这里的id是唯一索引) ，这个SQL查询不到对应的记录，那么此时会使用间隙锁。 间隙锁作用？ 防止幻读问题，事务并发的时候，如果没有间隙锁，就会发生如下图的问题，在同一个事务里，A事务的两次查询出的结果会不一样。 Next-Key Lock临键锁是INNODB的行锁默认算法，它是记录锁和间隙锁的组合，临键锁会把查询出来的记录锁住，同时也会把该范围查询内的所有间隙空间也会锁住，再之它会把相邻的下一个区间也会锁住。 出现条件：范围查询并命中，查询命中了索引。 临键锁的作用 结合记录锁和间隙锁的特性，临键锁避免了在范围查询时出现脏读、重复读、幻读问题。加了临键锁之后，在范围区间内数据不允许被修改和插入。 大表优化当MySQL单表记录数过大时，数据库的CRUD性能会明显下降，一些常见的优化措施如下： 1. 限定数据的范围务必禁止不带任何限制数据范围条件的查询语句。比如：我们当用户在查询订单历史的时候，我们可以控制在一个月的范围内； 2. 读/写分离经典的数据库拆分方案，主库负责写，从库负责读； 3. 垂直分区根据数据库里面数据表的相关性进行拆分。 例如，用户表中既有用户的登录信息又有用户的基本信息，可以将用户表拆分成两个单独的表，甚至放到单独的库做分库。 简单来说垂直拆分是指数据表列的拆分，把一张列比较多的表拆分为多张表。 如下图所示，这样来说大家应该就更容易理解了。 垂直拆分的优点： 可以使得列数据变小，在查询时减少读取的Block数，减少I/O次数。此外，垂直分区可以简化表的结构，易于维护。 垂直拆分的缺点： 主键会出现冗余，需要管理冗余列，并会引起Join操作，可以通过在应用层进行Join来解决。此外，垂直分区会让事务变得更加复杂； [ 4. 水平分区保持数据表结构不变，通过某种策略存储数据分片。这样每一片数据分散到不同的表或者库中，达到了分布式的目的。 水平拆分可以支撑非常大的数据量。 水平拆分是指数据表行的拆分，表的行数超过200万行时，就会变慢，这时可以把一张的表的数据拆成多张表来存放。举个例子：我们可以将用户信息表拆分成多个用户信息表，这样就可以避免单一表数据量过大对性能造成影响。 水平拆分可以支持非常大的数据量。需要注意的一点是：分表仅仅是解决了单一表数据过大的问题，但由于表的数据还是在同一台机器上，其实对于提升MySQL并发能力没有什么意义，所以 水平拆分最好分库 。 分库分表之后,id 主键如何处理？因为要是分成多个表之后，每个表都是从 1 开始累加，这样是不对的，我们需要一个全局唯一的 id 来支持。 生成全局 id 有下面这几种方式： UUID UUID比较长，是无序的。 Twitter的snowflake算法（雪花算法） ： SnowFlake算法生成id的结果是一个64bit大小的整数。所有生成的id按时间趋势递增整个分布式系统内不会产生重复id 美团的Leaf分布式ID生成系统 ： 索引Mysql索引主要使用的两种数据结构 哈希索引 O(1) 不适合范围查询。如SELECT * FROM tb1 WHERE id &lt; 500，查500次？ InnoDB不支持哈希索引 对于哈希索引来说，底层的数据结构就是哈希表，因此在绝大多数需求为单条记录查询的时候，可以选择哈希索引，查询性能最快；其余大部分场景，建议选择BTree索引。 BTree索引 和 B+Tree索引 1.B树的所有节点既存放 键(key) 也存放 数据(data);而B+树只有叶子节点存放 key 和 data，其他内节点只存放key。（只针对聚集索引，如主键索引。不然data可能存放的是数据的指针或主键） 2.B树的叶子节点都是独立的;B+树的叶子节点有一条引用链指向与它相邻的叶子节点。 3.B树的检索的过程相当于对范围内的每个节点的关键字做二分查找，可能还没有到达叶子节点，检索就结束了。而B+树的检索效率就很稳定了，任何查找都是从根节点到叶子节点的过程，叶子节点的顺序检索很明显（大大提升范围查询的效率）。 PS：每个节点占用一个盘块的磁盘空间，一个节点上有两个升序排序的关键字和三个指向子树根节点的指针，指针存储的是子节点所在磁盘块的地址。 PS：B树结构图中可以看到每个节点不仅包含数据的key值，还有data值。而每一个页的存储空间是有限的，如果data数据较大时将会导致每个节点（即一个页）能存储的key的数量很小，当存储的数据量很大时同样会导致B树的深度增大，增大查询时的I/O次数进而影响查询效率。 备注：B+树的高度在2-3层左右。也就意味着只需要2-3次的IO操作即可。 面试官：为什么MySQL的索引要使用B+树，而不是其它树？比如B树？1、B+树的层级更少：相较于B树B+每个非叶子节点存储的关键字数更多，树的层级更少所以查询数据更快； 2、B+树查询速度更稳定：B+所有关键字数据地址都存在叶子节点上，所以每次查找的次数都相同所以查询速度要比B树更稳定; 3、B+树天然具备排序功能：B+树所有的叶子节点数据构成了一个有序链表，在查询大小区间的数据时候更方便，数据紧密性很高，缓存的命中率也会比B树高。 4、B+树全节点遍历更快：B+树遍历整棵树只需要遍历所有的叶子节点即可，，而不需要像B树一样需要对每一层进行遍历，这有利于数据库做全表扫描。 B树相对于B+树的优点是，如果经常访问的数据离根节点很近，而B树的非叶子节点本身存有关键字其数据的地址，所以这种数据检索的时候会要比B+树快。 聚集索引与非聚集索引聚集索引聚集索引即索引结构和数据一起存放的索引。主键索引属于聚集索引。 在 Mysql 中，InnoDB引擎的表的 .ibd文件就包含了该表的索引和数据，对于 InnoDB 引擎表来说，该表的索引(B+树)的每个非叶子节点存储索引，叶子节点存储索引和索引对应的数据。 聚集索引的优点聚集索引的查询速度非常的快，因为整个B+树本身就是一颗多叉平衡树，叶子节点也都是有序的，定位到索引的节点，就相当于定位到了数据。 聚集索引的缺点 依赖于有序的数据 ：因为B+树是多路平衡树，如果索引的数据不是有序的，那么就需要在插入时排序，如果数据是整型还好，否则类似于字符串或UUID这种又长又难比较的数据，插入或查找的速度肯定比较慢。 更新代价大 ： 如果对索引列的数据被修改时，那么对应的索引也将会被修改， 而且况聚集索引的叶子节点还存放着数据，修改代价肯定是较大的， 所以对于主键索引来说，主键一般都是不可被修改的。 非聚集索引非聚集索引即索引结构和数据分开存放的索引。 二级索引属于非聚集索引。 MYISAM引擎的表的.MYI文件包含了表的索引， 该表的索引(B+树)的每个叶子非叶子节点存储索引， 叶子节点存储索引和索引对应数据的指针，指向.MYD文件的数据。 非聚集索引的叶子节点并不一定存放数据的指针， 因为二级索引的叶子节点就存放的是主键，根据主键再回表查数据。 非聚集索引的优点更新代价比聚集索引要小 。非聚集索引的更新代价就没有聚集索引那么大了，非聚集索引的叶子节点是不存放数据的 非聚集索引的缺点 跟聚集索引一样，非聚集索引也依赖于有序的数据 可能会二次查询(回表) :这应该是非聚集索引最大的缺点了。 当查到索引对应的指针或主键后，可能还需要根据指针或主键再到数据文件或表中查询。 非聚集索引一定回表查询吗(覆盖索引)?非聚集索引不一定回表查询。 试想一种情况，用户准备使用SQL查询用户名，而用户名字段正好建立了索引。 1SELECT name FROM table WHERE username=&apos;guang19&apos;; 那么这个索引的key本身就是name，查到对应的name直接返回就行了，无需回表查询。 即使是MYISAM也是这样，虽然MYISAM的主键索引确实需要回表， 因为它的主键索引的叶子节点存放的是指针。但是如果SQL查的就是主键呢? 1SELECT id FROM table WHERE id=1; 主键索引本身的key就是主键，查到返回就行了。这种情况就称之为覆盖索引了。 覆盖索引介绍什么是覆盖索引如果一个索引包含（或者说覆盖）所有需要查询的字段的值，我们就称之为“覆盖索引”。我们知道InnoDB存储引擎中，如果不是主键索引，叶子节点存储的是主键+列值。最终还是要“回表”，也就是要通过主键再查找一次。这样就会比较慢覆盖索引就是把要查询出的列和索引是对应的，不做回表操作！ 覆盖索引使用实例现在我创建了索引(username,age)，我们执行下面的 sql 语句 1select username , age from user where username = 'Java' and age = 22 在查询数据的时候：要查询出的列在叶子节点都存在！所以，就不用回表。 联合索引最左前缀匹配原则在MySQL建立联合索引时会遵循最左前缀匹配原则。 联合索引的有点 减少开销 建一个联合索引(col1,col2,col3)，实际相当于建了(col1),(col1,col2),(col1,col2,col3)三个索引。每多一个索引，都会增加写操作的开销和磁盘空间的开销。对于大量数据的表，使用联合索引会大大的减少开销！ 覆盖索引 对联合索引(col1,col2,col3)，如果有如下的sql: select col1,col2,col3 from test where col1=1 and col2=2。那么MySQL可以直接通过遍历索引取得数据，而无需回表， 效率高 对col1、col2、col3三列分别创建索引，MySQL只会选择辨识度高的一列作为索引。假设有100w的数据，一个索引筛选出10%的数据，那么可以筛选出10w的数据；对于联合索引而言，可以筛选出100w10%10%*10%=1000条数据。 假设我们创建（col1，col2，col3）这样的一个组合索引，那么相当于对col1列进行排序，也就是我们创建组合索引，以最左边的为准，只要查询条件中带有最左边的列，那么查询就会使用到索引。 最频繁使用的列放在左边；查看列的选择性（即该列的索引值数量与记录数量的比值），比值越高，效果越好； 联合索引表T1如图所示，有字段a,b,c,d,e，其中a是主键，联合索引（b，c，d） InnoDB会使用主键索引在B+树维护索引和数据文件，然后我们创建了一个联合索引（b，c，d）也会生成一个索引树，同样是B+树的结构，只不过它的data部分存储的是联合索引所在行的主键值（上图叶子节点紫色背景部分）。 对于联合索引来说只不过比单值索引多了几列，而这些索引列全都出现在索引树上。对于联合索引，存储引擎会首先根据第一个索引列排序，如上图我们可以单看第一个索引列，横着看，如，1 1 5 12 13….他是单调递增的；如果第一列相等则再根据第二列排序，依次类推就构成了上图的索引树，上图中的b列都等于1时，则根据c排序，此时c列也相等则按d列排序，如：1 1 4 ，1 1 5，c=4在c=5前面，以及13 12 4,13 16 1,13 16 5就可以说明这种情况。 当我们的SQL语言可以应用到索引的时候，比如select * from T1 where b = 12 and c = 14 and d = 3; 也就是T1表中a列为4的这条记录。存储引擎首先从根节点（一般常驻内存）开始查找，第一个索引的第一个索引列为1,12大于1，第二个索引的第一个索引列为56,12小于56，于是从这俩索引的中间读到下一个节点的磁盘文件地址，从磁盘上Load这个节点，通常伴随一次磁盘IO，然后在内存里去查找。当Load叶子节点的第二个节点时又是一次磁盘IO，比较第一个元素，b=12,c=14,d=3完全符合，于是找到该索引下的data元素即ID值，再从主键索引树上找到最终数据。 最左匹配原则之所以会有最左前缀匹配原则和联合索引的索引构建方式及存储结构是有关系的。 首先我们创建的index_bcd(b,c,d)索引，相当于创建了(b)、（b、c）（b、c、d）三个索引，看完下面你就知道为什么相当于创建了三个索引。 我们看，联合索引是首先使用多列索引的第一列构建的索引树，用上面idx_t1_bcd(b,c,d)的例子就是优先使用b列构建，当b列值相等时再以c列排序，若c列的值也相等则以d列排序。我们可以取出索引树的叶子节点看一下。 索引的第一列也就是b列可以说是从左到右单调递增的，但我们看c列和d列并没有这个特性，它们只能在b列值相等的情况下这个小范围内递增，如第一叶子节点的第1、2个元素和第二个叶子节点的后三个元素。 由于联合索引是上述那样的索引构建方式及存储结构，所以联合索引只能从多列索引的第一列开始查找。所以如果你的查找条件不包含b列如（c,d）、(c）、(d)是无法应用缓存的，以及跨列也是无法完全用到索引如(b,d)，只会用到b列索引。 这就像我们的电话本一样，有名和姓以及电话，名和姓就是联合索引。在姓可以以姓的首字母排序，姓的首字母相同的情况下，再以名的首字母排序。 如 12345678M 毛 不易 178******** 马 化腾 183******** 马 云 188********Z 张 杰 189******** 张 靓颖 138******** 张 艺兴 176******** 我们知道名和姓是很快就能够从姓的首字母索引定位到姓，然后定位到名，进而找到电话号码，因为所有的姓从上到下按照既定的规则（首字母排序）是有序的，而名是在姓的首字母一定的条件下也是按照名的首字母排序的，但是整体来看，所有的名放在一起是无序的，所以如果只知道名查找起来就比较慢，因为无法用已排好的结构快速查找。 MySQL查询优化使用 Explain 进行分析Explain 用来分析 SELECT 查询语句，开发人员可以通过分析 Explain 结果来优化查询语句。 比较重要的字段有： select_type : 查询类型，有简单查询、联合查询、子查询等 key : 使用的索引 rows : 扫描的行数 优化数据访问1. 减少请求的数据量 只返回必要的列：最好不要使用 SELECT * 语句。 只返回必要的行：使用 LIMIT 语句来限制返回的数据。 缓存重复查询的数据：使用缓存可以避免在数据库中进行查询，特别在要查询的数据经常被重复查询时，缓存带来的查询性能提升将会是非常明显的。 2. 减少服务器端扫描的行数最有效的方式是使用索引来覆盖查询 重构查询方式1. 切分大查询一个大查询如果一次性执行的话，可能一次锁住很多数据、占满整个事务日志、耗尽系统资源、阻塞很多小的但重要的查询。 2. 分解大连接查询将一个大连接查询分解成对每一个表进行一次单表查询 数据库常问面试题1.三大范式第一范式（1NF）：要求数据库表的每一列都是不可分割的原子数据项。 第二范式（2NF）：在1NF的基础上，非码属性必须完全依赖于候选码（在1NF基础上消除非主属性对主码的部分函数依赖） 第三范式（3NF）：在2NF基础上，任何非主属性不依赖于其它非主属性（在2NF基础上消除传递依赖） 第三范式需要确保数据表中的每一列数据都和主键直接相关，而不能间接相关。 2.内连接 自然连接 外连接 笛卡尔连接数据中的连接join分为内连接、自然连接、外连接，外连接又分为左外连接、右外连接、全外连接。 当然，这些分类都是在连接的基础上，是从两个表中记录的笛卡尔积中选取满足连接的记录。 有如下两个表 他们的笛卡尔积如图。 自然连接（natural join）自然连接是一种特殊的等值连接，他要求两个关系表中进行比较的必须是相同的属性列，无须添加连接条件，并且在结果中消除重复的属性列。sql语句：Select …… from 表1 natural join 表2结果： 内连接（inner join）内连接基本与自然连接相同，不同之处在于自然连接要求是同名属性列的比较，而内连接则不要求两属性列同名，可以用using或on来指定某两列字段相同的连接条件。sql语句：Select …… from 表1 inner join 表 2 on 表1.A=表2.E 如果没有后面的on条件，内连接得到的就是笛卡尔积 结果： 自然连接时某些属性值不同则会导致这些元组会被舍弃，那如何保存这些会被丢失的信息呢，外连接就解决了相应的问题。外连接分为左外连接、右外连接、全外连接。外连接必须用using或on指定连接条件。 左外连接（left outer join)左外连接是在两表进行自然连接，只把左表要舍弃的保留在结果集中，右表对应的列上填null。sql语句：Select …… from 表1 left outer join 表2 on 表1.C=表2.C结果： 右外连接(rignt outer join)右外连接是在两表进行自然连接，只把右表要舍弃的保留在结果集中，左表对应的列上填null。Select …… from 表1 rignt outer join 表2 on 表1.C=表2.C结果： 全外连接(full join)全外连接是在两表进行自然连接，只把左表和右表要舍弃的都保留在结果集中，相对应的列上填null。Select …… from 表1 full join 表2 on 表1.C=表2.C结果： 3.视图4.CHAR和VARCHAR的区别CHAR：表示的是定长的字符串，当你输入小于指定的数目，比如你指定的数目是 char(6)，当你输入小于 6 个字符的时候，char 会在你最后一个字符后面补空值。当你输入超过指定允许最大长度后，MySQL 会报错 VARCHAR：varchar 指的是长度为 n 个字节的可变长度，并且是非Unicode的字符数据。n 的值是介于 1 - 8000 之间的数值。存储大小为实际大小。 使用 char 存储定长的数据非常方便、char 检索效率高，无论你存储的数据是否到了 10 个字节，都要去占用 10 字节的空间 使用 varchar 可以存储变长的数据，但存储效率没有 char 高。 5.谈谈 SQL 优化的经验 查询语句无论是使用哪种判断条件 等于、小于、大于， WHERE 左侧的条件查询字段不要使用函数或者表达式 使用 EXPLAIN 命令优化你的 SELECT 查询，对于复杂、效率低的 sql 语句，我们通常是使用 explain sql 来分析这条 sql 语句，这样方便我们分析，进行优化。 当你的 SELECT 查询语句只需要使用一条记录时，要使用 LIMIT 1 不要直接使用 SELECT *，而应该使用具体需要查询的表字段，因为使用 EXPLAIN 进行分析时，SELECT * 使用的是全表扫描，也就是 type = all。 为搜索字段创建索引 选择合适的字段类型，选择标准是 尽可能小、尽可能定长、尽可能使用整数。 进行水平切割或者垂直分割 水平分割：通过建立结构相同的几张表分别存储数据 垂直分割：将经常一起使用的字段放在一个单独的表中，分割后的表记录之间是一一对应关系。 6.Mysql中有哪几种锁？ MyISAM支持表锁，InnoDB支持表锁和行锁，默认为行锁 表级锁：开销小，加锁快，不会出现死锁。锁定粒度大，发生锁冲突的概率最高，并发量最低 行级锁：开销大，加锁慢，会出现死锁。锁力度小，发生锁冲突的概率小，并发度最高 7.like查询会用到索引吗？分情况：如果是like ‘%keyword’ 这样以%开头则无法使用索引，如果是‘keyword%’则可以使用索引。 索引文件具有 B-Tree 的最左前缀匹配特性，如果左边的值未确定，那么无法使用此索引。 8.InnoDB如何实现事务事务具有ACID四个特性：ACD三个特性是通过Redo log(重做日志)和Undo log(回滚日志)实现的。隔离性是通过锁来实现的。 Undo log: 当事务对数据库进行修改时，InnoDB会生成对应的undo log；如果事务执行失败或调用了rollback，导致事务需要回滚，便可以利用undo log中的信息将数据回滚到修改之前的样子。 undo log属于逻辑日志，它记录的是sql执行相关的信息。当发生回滚时，InnoDB会根据undo log的内容做与之前相反的工作：对于每个insert，回滚时会执行delete；对于每个delete，回滚时会执行insert；对于每个update，回滚时会执行一个相反的update，把数据改回去。 Undo log 的用途 （1）保证事务进行rollback时的原子性和一致性，当事务进行回滚的时候可以用undo log的数据进行恢复。 （2）用于MVCC快照读的数据，在MVCC多版本控制中，通过读取undo log的历史版本数据可以实现不同事务版本号都拥有自己独立的快照数据版本。 Redo log（先写log，再写缓存，保证宕机时，缓存数据丢失也无所谓） 读写数据时，先从Buffer Pool读写（如果没有，磁盘读入放入Buffer Pool），Buffer Pool中修改的数据会定期刷新到磁盘中。 问题：如果MySQL宕机，而此时Buffer Pool中修改的数据还没有刷新到磁盘中，导致数据丢失，事务的持久性无法保证。 于是引入Redo log：当数据修改时，除了修改Buffer Pool中的数据，还会在redo log记录这次操作；当事务提交时，会调用fsync接口对redo log进行刷盘。如果MySQL宕机，重启时可以读取redo log中的数据，对数据库进行恢复。redo log采用的是WAL（Write-ahead logging，预写式日志），所有修改先写入日志，再更新到Buffer Pool，保证了数据不会因MySQL宕机而丢失，从而满足了持久性要求。 9.MVCC是通过什么实现多版本控制的MVCC是在并发访问数据库时，通过对数据做多版本管理，避免因为写锁的阻塞而造成读数据的并发阻塞问题。 通俗的讲就是MVCC通过保存数据的历史版本，根据比较版本号来处理数据的是否显示，从而达到读取数据的时候不需要加锁就可以保证事务隔离性的效果。 基本特征 每行数据都存在一个版本，每次数据更新时都更新该版本。 修改时Copy出当前版本随意修改，各个事务之间无干扰。 保存时比较版本号，如果成功（commit），则覆盖原记录；失败则放弃copy（rollback） 隐藏列 DB_TRX_ID: 记录操作该数据事务的事务ID； DB_ROLL_PTR：指向上一个版本数据在undo log 里的位置指针；可以读取undo log的历史版本数据。 DB_ROW_ID: 隐藏ID ，当创建表没有合适的索引作为聚集索引时，会用该隐藏ID创建聚集索引;（主要是前面两个，这个和MVCC没啥关系） InnoDB存储引擎MVCC的实现策略 在每一行数据中额外保存两个隐藏的列：当前行创建时的版本号和删除时的版本号（可能为空，其实还有一列称为回滚指针，用于事务回滚，不在本文范畴）。这里的版本号并不是实际的时间值，而是系统版本号。每开始新的事务，系统版本号都会自动递增。事务开始时刻的系统版本号会作为事务的版本号，用来和查询每行记录的版本号进行比较。 每个事务又有自己的版本号，这样事务内执行CRUD操作时，就通过版本号的比较来达到数据版本控制的目的。如何解决不可重复读 1.悲观锁：读取到数据后，就将这些数据加锁。其他事务无法修改这些数据，就可以实现可重复读了。无法锁住insert,无法避免幻读。 2.乐观锁：MVCC 10.order by会使用索引吗？不一定。 1、ORDER BY的索引优化。如果一个SQL语句形如：SELECT [column1],[column2],…. FROM [TABLE] ORDER BY [sort];在[sort]这个栏位上建立索引就可以实现利用索引进行order by 优化。 2、WHERE + ORDER BY的索引优化，形如：SELECT [column1],[column2],…. FROM [TABLE] WHERE [columnX] = [value] ORDER BY [sort];建立一个联合索引(columnX,sort)来实现order by 优化。 MySQL Order By不能使用索引来优化排序的情况 1.对不同的索引键做 ORDER BY ：(key1,key2分别建立索引)SELECT * FROM t1 ORDER BY key1, key2; 2.用于搜索记录的索引键和做 ORDER BY 的不是同一个：(key1,key2分别建立索引)SELECT * FROM t1 WHERE key2=constant ORDER BY key1; 特别提示:1&gt;mysql一次查询只能使用一个索引。如果要对多个字段使用索引，建立复合索引。2&gt;在ORDER BY操作中，MySQL只有在排序条件不是一个查询条件表达式的情况下才使用索引。 11.联合索引（A,B) where B=b and A=a会使用索引吗会，MySQL有优化器会自动调整a，b的顺序与索引一致。 12.Mysql编码utf-8和gbk的区别UTF8编码格式很强大，支持所有国家的语言，正是因为它的强大，才会导致它占用的空间大小要比GBK大，对于网站打开速度而言，也是有一定影响的。 GBK编码格式，它的功能少，仅限于中文字符，当然它所占用的空间大小会随着它的功能而减少，打开网页的速度比较快。 UTF8中文占用3个字节，GBK中文占用2个字节，其他的都占一个字节 13.MVCC和锁的关系，为什么有了MVCC还要锁？锁：悲观锁，乐观锁，读写锁。MVCC，大部分都是读操作，不需要加读锁，效率更高。 14.MySQL的主从复制主库将变更写入 binlog 日志，然后从库连接到主库之后，从库有一个 IO 线程，将主库的 binlog 日志拷贝到自己本地，写入一个 relay 中继日志中。接着从库中有一个 SQL 线程会从中继日志读取 binlog，然后执行 binlog 日志中的内容，也就是在自己本地再次执行一遍 SQL，这样就可以保证自己跟主库的数据是一样的。 从库有两个线程：IO线程用来读取主数据库的binlog，SQL线程读取binlog，并执行一遍SQL]]></content>
  </entry>
  <entry>
    <title><![CDATA[相册更新]]></title>
    <url>%2F2019%2F12%2F01%2F%E7%9B%B8%E5%86%8C%E6%9B%B4%E6%96%B0%2F</url>
    <content type="text"><![CDATA[将图片放入photos文件夹下 运行tool.py将相册上传至七牛云photov1 hexo clean hexo d -g 注意：每30天需要将photov1备份到一个新的存储空间，获得30天域名后，修改source/js/src/photo.js的域名]]></content>
  </entry>
  <entry>
    <title><![CDATA[Unet]]></title>
    <url>%2F2019%2F09%2F25%2FUnet%2F</url>
    <content type="text"><![CDATA[论文题目：U-Net: Convolutional Networks for Biomedical Image Segmentation 下载：点击下载 Introduction: 作者提出一个基于FCN改进的U型结构的网络（U-net）和一个依赖strong use of data augmentation的训练策略，可以更充分利用训练样本。 相较于FCN的改进： 1.可以在更少的图片上训练 2.有更精确的分割 与FCN逐点相加不同，U-Net采用将特征在channel维度拼接在一起，形成更“厚”的特征 注：直接复制过来再裁剪到与上采样图片一样大小 该方法允许任意大图片的无缝分割通过一个overlap-tile策略。为了预测框中图像，缺失区域通过镜像输入图像扩张。这种tiling方法对于应用网络到大图像很重要，因为否则结果会被gpu内存限制。为了预测黄色区域的分割，需要蓝色区域作为输入。 数据增强：elastic deformations (弹性形变) 数据增强在训练样本比较少的时候,能够让神经网络学习一些不变性，弹性变换是本文使用的方法。（因为弹性形变是实际细胞中比较常见的一种形变，如果我们能采取数据增强的算法去使网络学习这种形变的不变性，就可以在分割数据集很小的情况下，使网络具有遇见弹性形变还是可以准确的检测出，相当于就是把原图，做了下弹性变形，然后，就相当于扩大了数据集嘛，自然网络就能适应这种弹性变化了，在遇见弹性变形的时候一样可以正确的分类分割） 增加touching cell之间border的权重， 参考： https://blog.csdn.net/jianyuchen23/article/details/79349694]]></content>
  </entry>
  <entry>
    <title><![CDATA[全卷积网络]]></title>
    <url>%2F2019%2F09%2F23%2F%E5%85%A8%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C%2F</url>
    <content type="text"><![CDATA[论文题目：Fully Convolutional Networks for Semantic Segmentation论文下载: 点击下载 Intorduction: FCN毫无疑问是语义分割领域的经典之作，在FCN出现之前，传统的CNN分割是将像素周围一个小区域作为CNN输入，做训练和预测，这样低效且不准确（忽略整体信息）。FCN主要有三点创新： 卷积化：即将传统CNN结构（文中提到的Alexnet、VGG）最后的全连接层改成卷积层，以便进行直接分割，这是十分有创造性的。这样，使得网络可以接受任意大小的图片，并输出和原图一样大小的分割图。只有这样，才能为每个像素做分类。(像素分类使用图像分类模型（如AlexNet VGGNet等pre-trained model）做迁移学习。) 上采样 or 反卷积：由于网络过程中进行了一系列下采样，使得特征层大小减小，了最后得到的预测层和原图一致，需要采用上采样。 并联跳跃结构：想法类似于resnet和inception，在进行分类预测时利用多层信息。 下图是传统分类CNN和FCN的对比，简单的说，FCN与CNN的区别在于FCN把CNN最后的全连接层换成卷积层，输出一张已经label好的图。 框架如如下，采用了skip connection 上图不够清晰，可以看下图 不同层次对比，其中FCN-8s效果最好 不足：对细节不敏感，没有充分考虑像素之间的关系，缺乏空间一致性。]]></content>
  </entry>
  <entry>
    <title><![CDATA[yolo改进]]></title>
    <url>%2F2019%2F09%2F17%2Fyolo%E6%94%B9%E8%BF%9B%2F</url>
    <content type="text"><![CDATA[论文题目：Assisted Excitation of Activations: A Learning Technique to Improve Object Detectors（CVPR2019）论文下载: 点击下载 摘要：在训练过程中，加入定位信息。可是提升yolov2 map 3.8个点， yolov3 map 2.2个点。这个方法适用于大多数single-stage 目标检测器。只改变了训练过程，推断过程没有任何改变。 Introduction:yolo难以解决得两个痛点：a. difficulty in localization原因：因为yolo同时做分类和定位，最后一层卷积层，更多语义信息，对分类有益。但是spatially course for localization.b. 训练时，前景与背景类别不平衡原因：不同于two-stage 检测器，没有预先减少候选框搜索空间到一个受限制的数目。大多数是简单的负样本。 Related Work: 加入辅助信息到CNN，主要分类两类： 1.同时做检测和分割，提升两个任务的表现。 2.只加入segmentation features来提高检测的精度。 本文提出的方法，在训练检测器时加入weak segmentation ground-truth(即bounding box，从而避免单独引入分割标注，更加简单),并没有增加额外的损失函数。 如上图所示，只在训练时增加了一个Assisted Excitation层。 具体过程： 最终期望的生成特征如下，其中alpha是关于时间的函数用于控制训练中的强度衰减，l+1代表第l+1层，式中c为通道数，e是增强特征： bbox内的像素位置为1，生成一个0-1mask。可见只在bbox内的区域做增强： 增强是按照通道去平均等量加上去的（作者的实验证明该效果最好）： 实验结果： ​ 从上左边的图可以看到，AE强化过的网络有全面的提升，其中在大尺度上的提升更加明显，推测原因是：大物体上加了分割强化后能够获得更强的辨认度，小物体由于本身尺度不大所以增加后也不明显。结果而言印证了这种强化的有效性，但是也完全地陷入了小目标检测的弊端了–像素内容少而被忽视。 ​ 右图的信息不太好辨认。先看yolov2的曲线来说，低iou阈值能够得到更高的改进的精度，说明其召回更好了，但是精度一高就趋于重合，改进失效，说明这种增强提高了低质量bbox的精度。再看yolov3，全IoU都有少量的提高，但是不特别大且没有明显的趋势，说明其采用的多尺度预测能一定程度地解决问题，并在其基础上能对全部精度都有增益。]]></content>
  </entry>
  <entry>
    <title><![CDATA[xml转txt]]></title>
    <url>%2F2019%2F05%2F29%2Fxml%E8%BD%ACtxt%2F</url>
    <content type="text"><![CDATA[先操作一波123456789path = &quot;images/&quot;for filenames in os.walk(pathh): filenames = list(filenames) filenames = filenames[2] for filename in filenames: print(filename) with open (&quot;class_train1.txt&quot;,&apos;a&apos;) as f: f.write(path+filename+&apos;\n&apos;) 再操作一波1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677# -*- coding: utf-8 -*-import xml.etree.ElementTree as ETimport pickleimport osfrom os import listdir, getcwdfrom os.path import joinsets = []classes = [&quot;dog&quot;, &quot;person&quot;, &quot;cat&quot;]# 原样保留。size为图片大小# 将ROI的坐标转换为yolo需要的坐标# size是图片的w和h# box里保存的是ROI的坐标（x，y的最大值和最小值）# 返回值为ROI中心点相对于图片大小的比例坐标，和ROI的w、h相对于图片大小的比例def convert(size, box): dw = 1. / (size[0]) dh = 1. / (size[1]) x = (box[0] + box[1]) / 2.0 - 1 y = (box[2] + box[3]) / 2.0 - 1 w = box[1] - box[0] h = box[3] - box[2] x = x * dw w = w * dw y = y * dh h = h * dh return (x, y, w, h)def convert_annotation(image_add): # image_add进来的是带地址的.jpg image_add = os.path.split(image_add)[1] # 截取文件名带后缀 image_add = image_add[0:image_add.find(&apos;.&apos;, 1)] # 删除后缀，现在只有文件名没有后缀 print(image_add) # 现在传进来的只有图片名没有后缀 in_file = open(&apos;xml/&apos; + image_add + &apos;.xml&apos;,encoding=&apos;utf-8&apos;) out_file = open(&apos;hebing2/labels/%s.txt&apos; % (image_add), &apos;w&apos;) tree = ET.parse(in_file) root = tree.getroot() size = root.find(&apos;size&apos;) w = int(size.find(&apos;width&apos;).text) h = int(size.find(&apos;height&apos;).text) # 在一个XML中每个Object的迭代 for obj in root.iter(&apos;object&apos;): # iter()方法可以递归遍历元素/树的所有子元素 # 找到所有的椅子 cls = obj.find(&apos;name&apos;).text # 如果训练标签中的品种不在程序预定品种，或者difficult = 1，跳过此object # cls_id 只等于1 cls_id = 0 xmlbox = obj.find(&apos;bndbox&apos;) # b是每个Object中，一个bndbox上下左右像素的元组 b = (float(xmlbox.find(&apos;xmin&apos;).text), float(xmlbox.find(&apos;xmax&apos;).text), float(xmlbox.find(&apos;ymin&apos;).text), float(xmlbox.find(&apos;ymax&apos;).text)) bb = convert((w, h), b) out_file.write(str(cls_id) + &quot; &quot; + &quot; &quot;.join([str(a) for a in bb]) + &apos;\n&apos;)if not os.path.exists(&apos;hebing2/labels/&apos;): os.makedirs(&apos;hebing2/labels/&apos;)image_adds = open(&quot;class_train1.txt&quot;)for image_add in image_adds: # print(image_add) image_add = image_add.strip() # print (image_add) convert_annotation(image_add) copy from here]]></content>
      <categories>
        <category>code</category>
      </categories>
      <tags>
        <tag>code</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[内镜去黑边]]></title>
    <url>%2F2019%2F05%2F09%2F%E5%86%85%E9%95%9C%E5%8E%BB%E9%BB%91%E8%BE%B9%2F</url>
    <content type="text"><![CDATA[Please enter the password to read the blog. Incorrect Password! No content to display! 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]]></content>
      <categories>
        <category>code</category>
      </categories>
      <tags>
        <tag>code</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[日本胃癌论文总结2]]></title>
    <url>%2F2019%2F05%2F07%2F%E6%97%A5%E6%9C%AC%E8%83%83%E7%99%8C%E8%AE%BA%E6%96%87%E6%80%BB%E7%BB%932%2F</url>
    <content type="text"><![CDATA[论文题目：Automatic detection of early gastric cancer in endoscopic images using a transferring convolutional neural network 摘要： Accuracy :87.6% heat map accuracy: 82.8%网络：GoogLeNet, 22 conv layers, pretrained on ImageNet 方法： 数据集处理 CNN迁移学习 judge normal vs cancer visualization – heat map 数据集处理（most important）总共有926张分辨率为1000*870的图片其中228包含胃癌 训练数据：从228张选出100张，然后对这100张，每张随机裁剪出100张左右224224的胃癌图片，每张都要包含80%病变区域，得到9587张224224的胃癌图片从包含胃癌和不包含胃癌的图片中随机裁剪出9800张224*224不包含胃癌的正常图片 测试数据：在训练数据裁剪未使用的包含和不包含胃癌的图片中，裁剪出4653胃癌图片和4997正常图片 结果]]></content>
  </entry>
  <entry>
    <title><![CDATA[日本胃癌论文总结1]]></title>
    <url>%2F2019%2F05%2F05%2F%E6%97%A5%E6%9C%AC%E8%83%83%E7%99%8C%E8%AE%BA%E6%96%87%E6%80%BB%E7%BB%931%2F</url>
    <content type="text"><![CDATA[论文题目：Application of artificial intelligence using a convolutional neural network for detecting gastric cancer in endoscopic images论文下载: 点击下载 测试集：13584张胃癌图片，包含2639个胃癌病变（经组织学验证）测试集： 2296张胃癌图片，包含69个病人，77个胃癌病变(62 cases had 1 gastric cancer lesion, 6 had 2 lesions, and 1 had 3 lesions)，每个病人18~69张图片。速度： 共用49s 检测2296张图片overall sensitivity： 92.2% （71/77） 71个胃癌病变成功被检测出来positive predictive value： 30.6%=71/（71+161） 161个非癌性病变误检测，过半误检测为胃炎 结果：实验：将训练集resize到300*300,送入网络fine-tune参数，然后检测测试集，检测胃癌病变区域。将其用矩形框框出。 714张图片被诊断出胃癌 714/2639=31.1% 测试集中52个（67.5%）是早期胃癌T1, 25个(32.5%)是advanced cancer T2,T3,T4 平均肿瘤大小是24mm(3到170mm) 思考：准确率该如何计算，如果单看被检测所有的测试集图片，只有不到1/3的图片被检测出有胃癌。但是如果按照检测的胃癌病变，一共有71/77个病变被检测出来！我想了下，主要是因为一个病变包含多张图片，作者认为只要某个病变的一张图片被正确诊断，就认为该病变被成功检测出来。类似于多示例学习。但是这样的话，误诊的也很高，这个161个非癌性病变被误诊是怎么算出来的？？？医生对误诊的区域进行手动分类统计？？？]]></content>
  </entry>
  <entry>
    <title><![CDATA[ObjectDetection]]></title>
    <url>%2F2019%2F04%2F17%2FObjectDetection%2F</url>
    <content type="text"><![CDATA[1.Huang_SpeedAccuracy_Trade-Offs_for_CVPR_2017_paper.pdf点击下载2.Johnson_DenseCap_Fully_Convolutional_CVPR_2016_paper.pdf点击下载3.yolov3点击下载]]></content>
      <categories>
        <category>论文</category>
      </categories>
      <tags>
        <tag>paper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pytorch]]></title>
    <url>%2F2019%2F04%2F11%2Fpytorch%2F</url>
    <content type="text"><![CDATA[损失函数1. CrossEntropylossa.交叉熵损失函数，常用于分类b.用这个loss前面不需要加 softmax层c.该函数限制了target的类型为torch.LongTensor1234567891011import torch as tfrom torch import nnfrom torch.autograd import Variable as V# batch_size=4, 计算每个类别分数（二分类）output = V(t.randn(4,2)) # batch_size * C=(batch_size, C)# target必须是LongTensor!target =V(t.Tensor([1,0,1,1])).long()criterion = nn.CrossEntropyLoss()loss = criterion(output, target)print(&apos;loss&apos;, loss) output: loss tensor(1.0643) 2. toch.nn.MSELoss均方损失函数，类似于nn.L1Loss函数：1234567import torchloss_fn = torch.nn.MSELoss(reduce=False, size_average=False)input = torch.autograd.Variable(torch.randn(3,4))target = torch.autograd.Variable(torch.randn(3,4))loss = loss_fn(input, target)print(input); print(target); print(loss)print(input.size(), target.size(), loss.size()) output:]]></content>
      <categories>
        <category>Pytorch</category>
      </categories>
      <tags>
        <tag>pytorch</tag>
        <tag>summary</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常用总结]]></title>
    <url>%2F2019%2F04%2F10%2F%E5%B8%B8%E7%94%A8%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[ROC曲线根据机器学习中分类器的预测得分对样例(每个样例的阳性概率)进行排序，按照顺序逐个把样本的概率作为阈值thresholds进行预测，计算出FPR和TPR。分别以FPR、TPR为横纵坐标作图即可得到ROC曲线。所以作ROC曲线时，需要先求出FPR和TPR。这两个变量的定义：FPR = TP/(TP+FN) TPR = TP/(TP+FP) 将样本输入分类器，每个样本将得到一个预测得分。我们通过设置不同的截断点，即可截取不同的信息。对应此示例图中，每个阈值的识别结果对应一个点(FPR，TPR)。当阈值取最大时，所有样本都被识别成负样本，对应于坐下角的点(0,0); 当阈值取最小时，所有样本都被识别成正样本，对应于右上角的点(1,1)，随着阈值从最大变化到最小，TP和FP都逐渐大；python中调用ROC12345678910111213141516171819import numpy as npfrom sklearn import metricsimport matplotlib.pyplot as pltfrom sklearn.metrics import auc# 真实标签y_true = np.array([0,0,1,1])print(&apos;y_true: &apos;, y_true)# y_score为预测为阳性的得分（说概率不大准确，因为这个score可以大于1）y_score = np.array([0.1, 0.35, 0.3, 0.8])print(&apos;y_score:&apos;, y_score)fpr, tpr, thresholds = metrics.roc_curve(y_true, y_score, pos_label=1)print(&apos;fpr&apos;, fpr)print(&apos;tpr&apos;, tpr)print(&apos;thresholds&apos;, thresholds)plt.plot(fpr,tpr,marker = &apos;o&apos;)plt.show()AUC = auc(fpr, tpr)print(&apos;AUC&apos;, AUC) 输出：阈值[0]表示没有被预测的实例，并且被任意设置为max(y_score) + 1 极大似然估计]]></content>
      <categories>
        <category>一些总结</category>
      </categories>
      <tags>
        <tag>summary</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[yolo 理论总结]]></title>
    <url>%2F2019%2F04%2F06%2Fyolo%E7%90%86%E8%AE%BA%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[对象识别和定位，可以看成两个任务：找到图片中某个存在对象的区域，然后识别出该区域中具体是哪个对象。 对象识别这件事（一张图片仅包含一个对象，且基本占据图片的整个范围），最近几年基于CNN卷积神经网络的各种方法已经能达到不错的效果了。所以主要需要解决的问题是，对象在哪里。 最简单的想法，就是遍历图片中所有可能的位置，地毯式搜索不同大小，不同宽高比，不同位置的每个区域，逐一检测其中是否存在某个对象，挑选其中概率最大的结果作为输出。显然这种方法效率太低。 RCNN提出候选区(Region Proposals)的方法，先从图片中搜索出一些可能存在对象的候选区（Selective Search），然后对每个候选区进行对象识别。大幅提升了对象识别和定位的效率。总体来说，RCNN系列依然是两阶段处理模式：先提出候选区，再识别候选区中的对象。 yolov1 yolov1详解(非常详细，推荐) 补充：边框回归：对于窗口一般使用四维向量(x,y,w,h)来表示， 分别表示窗口的中心点坐标和宽高。 对于图 2, 红色的框 P 代表原始的Proposal, 绿色的框 G 代表目标的 Ground Truth， 我们的目标是寻找一种关系使得输入原始的窗口 P 经过映射得到一个跟真实窗口 G 更接近的回归窗口G^。 YOLOV1的bounding box并不是Faster RCNN的AnchorFaster RCNN等一些算法采用每个grid中手工设置n个Anchor（先验框，预先设置好位置的bounding box）的设计，每个Anchor有不同的大小和宽高比。YOLO的bounding box看起来很像一个grid中2个Anchor，但它们不是。YOLO并没有预先设置2个bounding box的大小和形状，也没有对每个bounding box分别输出一个对象的预测。它的意思仅仅是对一个对象预测出2个bounding box，选择预测得相对比较准的那个。 Yolov2 yolov2改变：batch normalization,采用了anchor,借鉴Faster RCNN的做法，YOLO2也尝试采用先验框（anchor）。在每个grid预先设定一组不同大小和宽高比的边框，来覆盖整个图像的不同位置和多种尺度，这些先验框作为预定义的候选区在神经网络中将检测其中是否存在对象，以及微调边框的位置。]]></content>
      <categories>
        <category>yolo</category>
      </categories>
      <tags>
        <tag>summary</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[斯坦福皮肤癌论文总结]]></title>
    <url>%2F2019%2F03%2F15%2F%E6%96%AF%E5%9D%A6%E7%A6%8F%E7%9A%AE%E8%82%A4%E7%99%8C%E8%AE%BA%E6%96%87%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[Dermatologist-level classification of skin cancer with deep neural networks背景 以往的皮肤癌分类器往往缺乏好的泛化能力，由于缺少数据和focus on 标准任务，如只对专用医学设备产生的图片进行分类。无法对如手机拍摄的等因为缩放，角度，光线问题的照片进行分类。该文提出一种端对端的CNN，对皮肤癌进行分类。可以达到专家水平甚至更好。 数据 用了129450张图像（比以往的数据集大两个数量级）包含2032种不同的疾病。测试数据是由21位皮肤科专家标注的。 将数据划分： 127,463用于训练和validation 1,942 biopsy-labelled（活检）用于测试 模型GoogLeNet Inception V3 (用2014ImageNet预训练，1.28 million images) 结果蓝色的是CNN,红色的点代表皮肤病专家，绿色的是皮肤病专家的平均水平，可以看出，CNN胜出 在first level nodes（benign lesions, malignant lesions and non-neoplastic lesions)3 class partision 任务中可以达到72.1%的平均准确率，两个皮肤科专家分别达到65.56%和66.0%其次，在second level nodes（9分类）中CNN可以达到55.4%，两个专家分别是53.3和55.0可以看出，用更好的疾病划分方法可以提高准确率 亮点1.一种给疾病分类的算法充分利用如下疾病的树状图分类，好像这个Partition Algorithm 挺好使的看以上结果的时候可以发现，有PA和没有PA，可以提升好几个点，下图是PA具体算法2.本文的训练数据比以往大了两个数量级，数据为王。3.不仅用了专业医学设备产生的图片4.展望手机app端，提升逼格]]></content>
  </entry>
  <entry>
    <title><![CDATA[组会ppt]]></title>
    <url>%2F2019%2F03%2F14%2F%E7%BB%84%E4%BC%9Appt%2F</url>
    <content type="text"><![CDATA[1.2018.3.8 early gastric cancer.ppt点击下载 论文题目：Automatic detection of early gastric cancer in endoscopic images点击下载]]></content>
      <categories>
        <category>PPT</category>
      </categories>
      <tags>
        <tag>PPT</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MIApaper]]></title>
    <url>%2F2018%2F12%2F10%2FMIApaper%2F</url>
    <content type="text"><![CDATA[1.一种基于原型学习的多示例卷积神经网络点击下载2.Deep Multi-instance Networks with Sparse Label Assignment for Whole Mammogram Classification点击下载3.2018.12.12小组会PPT点击下载4.自然语言处理paper reading点击下载5.Prototypical Networks for Few-shot Learning点击下载6.Automatic detection of early gastric cancer in endoscopic images点击下载7.what is this点击下载8.Matching Network点击下载9.斯坦福皮肤癌点击下载10.PathologicalEvidenceExplorationinDeepRetinalImageDiagnosis点击下载11.胃癌+AI整理点击下载]]></content>
      <categories>
        <category>论文</category>
      </categories>
      <tags>
        <tag>paper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[paper]]></title>
    <url>%2F2018%2F11%2F30%2Fpaper%2F</url>
    <content type="text"><![CDATA[paper reading论文下载]]></content>
      <categories>
        <category>论文</category>
      </categories>
      <tags>
        <tag>paper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[test]]></title>
    <url>%2F2018%2F11%2F30%2Ftest%2F</url>
    <content type="text"><![CDATA[this is fucking crazy 你好 今天是周五 明天放假了 还有好多作业 this is a test今天是个好日子]]></content>
  </entry>
</search>
